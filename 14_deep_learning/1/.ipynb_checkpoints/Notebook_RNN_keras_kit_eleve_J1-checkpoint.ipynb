{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Deep Learning Project in Python with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steps we are going to cover:\n",
    "1. Load Data.\n",
    "2. Define Keras Model.\n",
    "3. Compile Keras Model.\n",
    "4. Fit Keras Model.\n",
    "5. Evaluate Keras Model.\n",
    "6. Put It All Together.\n",
    "7. Make Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset and place it in your local working directory, the same location as your python file. Take a look at the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('housepricedata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you can explore the data a little. We have our input features in the first ten columns:\n",
    "\n",
    "- Lot Area (in sq ft)\n",
    "- Overall Quality (scale from 1 to 10)\n",
    "- Overall Condition (scale from 1 to 10)\n",
    "- Total Basement Area (in sq ft)\n",
    "- Number of Full Bathrooms\n",
    "- Number of Half Bathrooms\n",
    "- Number of Bedrooms above ground\n",
    "- Total Number of Rooms above ground\n",
    "- Number of Fireplaces\n",
    "- Garage Area (in sq ft)\n",
    "\n",
    "In our last column, we have the feature that we would like to predict:\n",
    "- Is the house price above the median or not? (1 for yes and 0 for no)\n",
    "\n",
    "Now that we’ve seen what our data looks like, we want to convert it into arrays for our machine to process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into input features (X) and the feature we wish to predict (Y). To do that split, assign the first 10 columns of our array to a variable called X and the last column of our array to a variable called Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:,0:10]\n",
    "Y = dataset[:,10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step in our processing is to make sure that the scale of the input features are similar. Right now, features such as lot area are in the order of the thousands, a score for overall quality is ranged from 1 to 10, and the number of fireplaces tend to be 0, 1 or 2. You will use the 'preprocessing' package from within the sklearn package. Use a function called the min-max scaler (from sklearn import preprocessing.MinMaxScaler()), which scales the dataset so that all the input features lie between 0 and 1 inclusive and take a look at your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std = StandardScaler()\n",
    "X_scaled = std.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_scaled = pd.DataFrame(X_scaled, columns = list(df.columns[0:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are down to our last step in processing the data, which is to split our dataset into a training set, a validation set and a test set.\n",
    "\n",
    "We will use the code from scikit-learn called ‘train_test_split’, which as the name suggests, split our dataset into a training set and a test set. We first import the code we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,Y_train, Y_test = train_test_split(X_scaled,Y, test_size = 0.3, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1022, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, this function only helps us split our dataset into two. Since we want a separate validation set and test set, we can use the same function to do the split again on val_and_test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_val, Y_test, Y_val  = train_test_split(X_test,Y_test,test_size = 0.5, random_state=41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the dimensions you need to get for your train, validation and test datasets: \n",
    "(1022, 10) (219, 10) (219, 10) (1022,) (219,) (219,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Keras Model."
   ]
  },
  {
   "attachments": {
    "ex_rnn_keras.PNG": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we have to do is to set up the architecture. Let’s first think about what kind of neural network architecture we want. Suppose we want this neural network:\n",
    "![ex_rnn_keras.PNG](attachment:ex_rnn_keras.PNG)\n",
    "In words, we want to have these layers:\n",
    "\n",
    "- Hidden layer 1: 12 neurons, ReLU activation\n",
    "- Hidden layer 2: 16 neurons, ReLU activation\n",
    "- Output Layer: 1 neuron, Sigmoid activation\n",
    "    \n",
    "Now, we need to describe this architecture to Keras. We will be using the Sequential model, which means that we merely need to describe the layers above in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "\n",
    "def get_model(k1=12,k2=16, metrics=['accuracy']):\n",
    "\n",
    "    model = Sequential([\n",
    "                        Dense(k1,input_shape=(10,)),\n",
    "                        Activation('relu'),\n",
    "                        Dense(k2),\n",
    "                        Activation('relu'),\n",
    "                        Dense(1),\n",
    "                        Activation('sigmoid')])\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is defined, we can compile it.\n",
    "\n",
    "Compiling the model uses TensorFlow that chooses the best way to represent the network for training and making predictions to run on your hardware, such as CPU or GPU or even distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have defined our model and compiled it ready for efficient computation.\n",
    "\n",
    "Now it is time to execute the model on some data (use 100 iterations and 32 batch size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 12)                132       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                208       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 357\n",
      "Trainable params: 357\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 0s 283us/step - loss: 0.1959 - accuracy: 0.9139 - val_loss: 0.2547 - val_accuracy: 0.8767\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 247us/step - loss: 0.1959 - accuracy: 0.9129 - val_loss: 0.2544 - val_accuracy: 0.8767\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 273us/step - loss: 0.1955 - accuracy: 0.9129 - val_loss: 0.2544 - val_accuracy: 0.8767\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 345us/step - loss: 0.1954 - accuracy: 0.9168 - val_loss: 0.2544 - val_accuracy: 0.8767\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 335us/step - loss: 0.1952 - accuracy: 0.9149 - val_loss: 0.2543 - val_accuracy: 0.8767\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 229us/step - loss: 0.1949 - accuracy: 0.9129 - val_loss: 0.2540 - val_accuracy: 0.8767\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 330us/step - loss: 0.1948 - accuracy: 0.9149 - val_loss: 0.2539 - val_accuracy: 0.8767\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 336us/step - loss: 0.1948 - accuracy: 0.9159 - val_loss: 0.2538 - val_accuracy: 0.8767\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 299us/step - loss: 0.1947 - accuracy: 0.9149 - val_loss: 0.2536 - val_accuracy: 0.8767\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 426us/step - loss: 0.1944 - accuracy: 0.9159 - val_loss: 0.2533 - val_accuracy: 0.8767\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.1944 - accuracy: 0.9139 - val_loss: 0.2533 - val_accuracy: 0.8767\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 209us/step - loss: 0.1941 - accuracy: 0.9149 - val_loss: 0.2532 - val_accuracy: 0.8767\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 231us/step - loss: 0.1939 - accuracy: 0.9139 - val_loss: 0.2531 - val_accuracy: 0.8767\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 210us/step - loss: 0.1937 - accuracy: 0.9139 - val_loss: 0.2530 - val_accuracy: 0.8767\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 189us/step - loss: 0.1937 - accuracy: 0.9149 - val_loss: 0.2529 - val_accuracy: 0.8767\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 195us/step - loss: 0.1935 - accuracy: 0.9139 - val_loss: 0.2528 - val_accuracy: 0.8767\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.1933 - accuracy: 0.9149 - val_loss: 0.2528 - val_accuracy: 0.8767\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.1932 - accuracy: 0.9159 - val_loss: 0.2527 - val_accuracy: 0.8767\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.1929 - accuracy: 0.9149 - val_loss: 0.2526 - val_accuracy: 0.8767\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.1928 - accuracy: 0.9168 - val_loss: 0.2526 - val_accuracy: 0.8767\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 101us/step - loss: 0.1927 - accuracy: 0.9159 - val_loss: 0.2526 - val_accuracy: 0.8767\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.1926 - accuracy: 0.9168 - val_loss: 0.2527 - val_accuracy: 0.8767\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 81us/step - loss: 0.1924 - accuracy: 0.9139 - val_loss: 0.2528 - val_accuracy: 0.8767\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.1924 - accuracy: 0.9149 - val_loss: 0.2526 - val_accuracy: 0.8767\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.1921 - accuracy: 0.9178 - val_loss: 0.2525 - val_accuracy: 0.8858\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.1919 - accuracy: 0.9159 - val_loss: 0.2524 - val_accuracy: 0.8858\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.1918 - accuracy: 0.9159 - val_loss: 0.2523 - val_accuracy: 0.8858\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 402us/step - loss: 0.1918 - accuracy: 0.9168 - val_loss: 0.2520 - val_accuracy: 0.8767\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.1915 - accuracy: 0.9178 - val_loss: 0.2521 - val_accuracy: 0.8767\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.1915 - accuracy: 0.9159 - val_loss: 0.2520 - val_accuracy: 0.8767\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.1913 - accuracy: 0.9168 - val_loss: 0.2522 - val_accuracy: 0.8858\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 240us/step - loss: 0.1913 - accuracy: 0.9188 - val_loss: 0.2520 - val_accuracy: 0.8767\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 409us/step - loss: 0.1911 - accuracy: 0.9188 - val_loss: 0.2519 - val_accuracy: 0.8767\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 299us/step - loss: 0.1911 - accuracy: 0.9168 - val_loss: 0.2519 - val_accuracy: 0.8858\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 324us/step - loss: 0.1909 - accuracy: 0.9168 - val_loss: 0.2517 - val_accuracy: 0.8767\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 301us/step - loss: 0.1908 - accuracy: 0.9168 - val_loss: 0.2519 - val_accuracy: 0.8858\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.1907 - accuracy: 0.9168 - val_loss: 0.2518 - val_accuracy: 0.8767\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.1907 - accuracy: 0.9149 - val_loss: 0.2519 - val_accuracy: 0.8767\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.1904 - accuracy: 0.9178 - val_loss: 0.2518 - val_accuracy: 0.8767\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 231us/step - loss: 0.1902 - accuracy: 0.9188 - val_loss: 0.2519 - val_accuracy: 0.8767\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 322us/step - loss: 0.1902 - accuracy: 0.9188 - val_loss: 0.2521 - val_accuracy: 0.8767\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.1902 - accuracy: 0.9168 - val_loss: 0.2521 - val_accuracy: 0.8813\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.1901 - accuracy: 0.9198 - val_loss: 0.2524 - val_accuracy: 0.8767\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.1899 - accuracy: 0.9188 - val_loss: 0.2525 - val_accuracy: 0.8858\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.1899 - accuracy: 0.9207 - val_loss: 0.2521 - val_accuracy: 0.8858\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 304us/step - loss: 0.1897 - accuracy: 0.9198 - val_loss: 0.2522 - val_accuracy: 0.8813\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 251us/step - loss: 0.1897 - accuracy: 0.9188 - val_loss: 0.2521 - val_accuracy: 0.8904\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.1896 - accuracy: 0.9198 - val_loss: 0.2520 - val_accuracy: 0.8813\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.1895 - accuracy: 0.9198 - val_loss: 0.2524 - val_accuracy: 0.8904\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.1893 - accuracy: 0.9188 - val_loss: 0.2525 - val_accuracy: 0.8904\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 100us/step - loss: 0.1891 - accuracy: 0.9188 - val_loss: 0.2527 - val_accuracy: 0.8858\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.1892 - accuracy: 0.9188 - val_loss: 0.2524 - val_accuracy: 0.8858\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.1890 - accuracy: 0.9188 - val_loss: 0.2522 - val_accuracy: 0.8904\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.1889 - accuracy: 0.9178 - val_loss: 0.2521 - val_accuracy: 0.8813\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.1888 - accuracy: 0.9207 - val_loss: 0.2519 - val_accuracy: 0.8813\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.1887 - accuracy: 0.9188 - val_loss: 0.2521 - val_accuracy: 0.8813\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.1886 - accuracy: 0.9188 - val_loss: 0.2519 - val_accuracy: 0.8813\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.1885 - accuracy: 0.9178 - val_loss: 0.2521 - val_accuracy: 0.8904\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.1885 - accuracy: 0.9207 - val_loss: 0.2520 - val_accuracy: 0.8904\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.1883 - accuracy: 0.9217 - val_loss: 0.2520 - val_accuracy: 0.8813\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - ETA: 0s - loss: 0.1800 - accuracy: 0.92 - 0s 121us/step - loss: 0.1882 - accuracy: 0.9188 - val_loss: 0.2521 - val_accuracy: 0.8813\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.1883 - accuracy: 0.9207 - val_loss: 0.2521 - val_accuracy: 0.8813\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.1881 - accuracy: 0.9207 - val_loss: 0.2520 - val_accuracy: 0.8813\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.1879 - accuracy: 0.9207 - val_loss: 0.2523 - val_accuracy: 0.8813\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.1879 - accuracy: 0.9207 - val_loss: 0.2522 - val_accuracy: 0.8813\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.1877 - accuracy: 0.9217 - val_loss: 0.2520 - val_accuracy: 0.8813\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 175us/step - loss: 0.1876 - accuracy: 0.9198 - val_loss: 0.2521 - val_accuracy: 0.8904\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.1875 - accuracy: 0.9227 - val_loss: 0.2521 - val_accuracy: 0.8813\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.1874 - accuracy: 0.9217 - val_loss: 0.2520 - val_accuracy: 0.8813\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 96us/step - loss: 0.1874 - accuracy: 0.9207 - val_loss: 0.2521 - val_accuracy: 0.8813\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 97us/step - loss: 0.1874 - accuracy: 0.9207 - val_loss: 0.2521 - val_accuracy: 0.8813\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 100us/step - loss: 0.1872 - accuracy: 0.9198 - val_loss: 0.2523 - val_accuracy: 0.8813\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 100us/step - loss: 0.1870 - accuracy: 0.9247 - val_loss: 0.2520 - val_accuracy: 0.8813\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 99us/step - loss: 0.1870 - accuracy: 0.9188 - val_loss: 0.2521 - val_accuracy: 0.8813\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.1869 - accuracy: 0.9198 - val_loss: 0.2522 - val_accuracy: 0.8813\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 185us/step - loss: 0.1868 - accuracy: 0.9217 - val_loss: 0.2522 - val_accuracy: 0.8813\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 222us/step - loss: 0.1866 - accuracy: 0.9217 - val_loss: 0.2522 - val_accuracy: 0.8813\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 302us/step - loss: 0.1866 - accuracy: 0.9198 - val_loss: 0.2525 - val_accuracy: 0.8813\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.1866 - accuracy: 0.9217 - val_loss: 0.2524 - val_accuracy: 0.8813\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 223us/step - loss: 0.1866 - accuracy: 0.9217 - val_loss: 0.2525 - val_accuracy: 0.8813\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 369us/step - loss: 0.1862 - accuracy: 0.9198 - val_loss: 0.2523 - val_accuracy: 0.8813\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.1863 - accuracy: 0.9217 - val_loss: 0.2521 - val_accuracy: 0.8813\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.1861 - accuracy: 0.9198 - val_loss: 0.2518 - val_accuracy: 0.8813\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.1859 - accuracy: 0.9207 - val_loss: 0.2520 - val_accuracy: 0.8813\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.1860 - accuracy: 0.9198 - val_loss: 0.2519 - val_accuracy: 0.8813\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.1860 - accuracy: 0.9188 - val_loss: 0.2521 - val_accuracy: 0.8813\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.1858 - accuracy: 0.9207 - val_loss: 0.2519 - val_accuracy: 0.8813\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.1857 - accuracy: 0.9207 - val_loss: 0.2518 - val_accuracy: 0.8813\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.1857 - accuracy: 0.9207 - val_loss: 0.2520 - val_accuracy: 0.8813\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.1855 - accuracy: 0.9188 - val_loss: 0.2522 - val_accuracy: 0.8813\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 186us/step - loss: 0.1855 - accuracy: 0.9207 - val_loss: 0.2522 - val_accuracy: 0.8813\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.1853 - accuracy: 0.9227 - val_loss: 0.2520 - val_accuracy: 0.8813\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.1852 - accuracy: 0.9227 - val_loss: 0.2518 - val_accuracy: 0.8813\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.1851 - accuracy: 0.9198 - val_loss: 0.2518 - val_accuracy: 0.8813\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.1851 - accuracy: 0.9198 - val_loss: 0.2517 - val_accuracy: 0.8813\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.1852 - accuracy: 0.9198 - val_loss: 0.2519 - val_accuracy: 0.8904\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 245us/step - loss: 0.1850 - accuracy: 0.9198 - val_loss: 0.2521 - val_accuracy: 0.8858\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.1850 - accuracy: 0.9227 - val_loss: 0.2520 - val_accuracy: 0.8904\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.1849 - accuracy: 0.9207 - val_loss: 0.2518 - val_accuracy: 0.8813\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.1847 - accuracy: 0.9207 - val_loss: 0.2520 - val_accuracy: 0.8813\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,Y_train, epochs=100, batch_size=32, validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8812785148620605"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['val_accuracy'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have trained our neural network on the entire dataset and we can evaluate the performance of the network on the same dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(history.history.keys())  \n",
    "\n",
    "\n",
    "\n",
    "plt.figure(1,figsize=(15,10))  \n",
    "\n",
    "# summarize history for accuracy  \n",
    "\n",
    "plt.subplot(211)  \n",
    "plt.plot(history.history['accuracy'])  \n",
    "plt.plot(history.history['val_accuracy'])  \n",
    "plt.title('model accuracy')  \n",
    "plt.ylabel('accuracy')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'val'], loc='upper left')  \n",
    "\n",
    "# summarize history for loss  \n",
    "\n",
    "plt.subplot(212)  \n",
    "plt.plot(history.history['loss'])  \n",
    "plt.plot(history.history['val_loss'])  \n",
    "plt.title('model loss')  \n",
    "plt.ylabel('loss')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'val'], loc='upper left')  \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1 = [2, 6, 10,15,20,30,40,50]\n",
    "k2 = [2, 6, 10,15,20,30,40,50]\n",
    "\n",
    "param_grid = dict(k1=k1, k2=k2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def grid_search(X_train, Y_train, X_val, Y_val, param_grid, get_model_function):\n",
    "    \n",
    "    \n",
    "    results=pd.DataFrame(columns=['Tryout','k1','k2','accuracy'])\n",
    "    i=0\n",
    "    \n",
    "    for k1 in param_grid['k1']:\n",
    "        for k2 in param_grid['k2']:  \n",
    "            model=get_model_function(k1=k1, k2=k2)\n",
    "            history = model.fit(X_train,Y_train, epochs=100, batch_size=32, validation_data=(X_val, Y_val))\n",
    "            results.loc[i]=[i]+[k1]+[k2]+[history.history['val_accuracy'][-1]]\n",
    "            i+=1  \n",
    "            \n",
    "    return resultsi[b], i[a] = i[a], i[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.8005 - accuracy: 0.4256 - val_loss: 0.7713 - val_accuracy: 0.3607\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 1s 525us/step - loss: 0.7473 - accuracy: 0.4374 - val_loss: 0.7340 - val_accuracy: 0.4247\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 387us/step - loss: 0.7160 - accuracy: 0.4687 - val_loss: 0.7101 - val_accuracy: 0.4795\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 275us/step - loss: 0.6948 - accuracy: 0.5039 - val_loss: 0.6929 - val_accuracy: 0.5114\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 291us/step - loss: 0.6789 - accuracy: 0.5440 - val_loss: 0.6789 - val_accuracy: 0.5571\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 206us/step - loss: 0.6650 - accuracy: 0.5763 - val_loss: 0.6660 - val_accuracy: 0.5753\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 191us/step - loss: 0.6513 - accuracy: 0.6076 - val_loss: 0.6530 - val_accuracy: 0.6393\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 336us/step - loss: 0.6372 - accuracy: 0.6458 - val_loss: 0.6392 - val_accuracy: 0.6804\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 315us/step - loss: 0.6223 - accuracy: 0.6732 - val_loss: 0.6250 - val_accuracy: 0.6895\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 270us/step - loss: 0.6064 - accuracy: 0.6908 - val_loss: 0.6100 - val_accuracy: 0.7123\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 311us/step - loss: 0.5898 - accuracy: 0.7133 - val_loss: 0.5947 - val_accuracy: 0.7215\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 233us/step - loss: 0.5728 - accuracy: 0.7358 - val_loss: 0.5792 - val_accuracy: 0.7260\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 292us/step - loss: 0.5559 - accuracy: 0.7505 - val_loss: 0.5640 - val_accuracy: 0.7352\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 227us/step - loss: 0.5393 - accuracy: 0.7740 - val_loss: 0.5492 - val_accuracy: 0.7443\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 437us/step - loss: 0.5233 - accuracy: 0.7935 - val_loss: 0.5354 - val_accuracy: 0.7534\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 430us/step - loss: 0.5082 - accuracy: 0.8043 - val_loss: 0.5225 - val_accuracy: 0.7626\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 319us/step - loss: 0.4942 - accuracy: 0.8190 - val_loss: 0.5106 - val_accuracy: 0.7671\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 323us/step - loss: 0.4813 - accuracy: 0.8337 - val_loss: 0.4998 - val_accuracy: 0.7854\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 200us/step - loss: 0.4693 - accuracy: 0.8415 - val_loss: 0.4899 - val_accuracy: 0.7900\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 292us/step - loss: 0.4581 - accuracy: 0.8552 - val_loss: 0.4806 - val_accuracy: 0.8082\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 247us/step - loss: 0.4476 - accuracy: 0.8630 - val_loss: 0.4720 - val_accuracy: 0.8128\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 232us/step - loss: 0.4378 - accuracy: 0.8640 - val_loss: 0.4637 - val_accuracy: 0.8128\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 221us/step - loss: 0.4287 - accuracy: 0.8679 - val_loss: 0.4557 - val_accuracy: 0.8219\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 250us/step - loss: 0.4201 - accuracy: 0.8689 - val_loss: 0.4479 - val_accuracy: 0.8311\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 233us/step - loss: 0.4119 - accuracy: 0.8738 - val_loss: 0.4406 - val_accuracy: 0.8356\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 302us/step - loss: 0.4041 - accuracy: 0.8738 - val_loss: 0.4338 - val_accuracy: 0.8447\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 295us/step - loss: 0.3968 - accuracy: 0.8728 - val_loss: 0.4273 - val_accuracy: 0.8447\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 313us/step - loss: 0.3900 - accuracy: 0.8757 - val_loss: 0.4212 - val_accuracy: 0.8447\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 276us/step - loss: 0.3835 - accuracy: 0.8767 - val_loss: 0.4157 - val_accuracy: 0.8402\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 338us/step - loss: 0.3776 - accuracy: 0.8796 - val_loss: 0.4108 - val_accuracy: 0.8402\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 250us/step - loss: 0.3721 - accuracy: 0.8845 - val_loss: 0.4062 - val_accuracy: 0.8402\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 292us/step - loss: 0.3668 - accuracy: 0.8875 - val_loss: 0.4017 - val_accuracy: 0.8493\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 231us/step - loss: 0.3620 - accuracy: 0.8875 - val_loss: 0.3975 - val_accuracy: 0.8493\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 256us/step - loss: 0.3574 - accuracy: 0.8865 - val_loss: 0.3935 - val_accuracy: 0.8493\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 332us/step - loss: 0.3531 - accuracy: 0.8894 - val_loss: 0.3896 - val_accuracy: 0.8493\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 245us/step - loss: 0.3490 - accuracy: 0.8894 - val_loss: 0.3857 - val_accuracy: 0.8493\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 189us/step - loss: 0.3449 - accuracy: 0.8894 - val_loss: 0.3821 - val_accuracy: 0.8493\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 248us/step - loss: 0.3410 - accuracy: 0.8894 - val_loss: 0.3786 - val_accuracy: 0.8493\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 168us/step - loss: 0.3369 - accuracy: 0.8894 - val_loss: 0.3752 - val_accuracy: 0.8493\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 182us/step - loss: 0.3328 - accuracy: 0.8904 - val_loss: 0.3720 - val_accuracy: 0.8493\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 187us/step - loss: 0.3287 - accuracy: 0.8885 - val_loss: 0.3691 - val_accuracy: 0.8493\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 199us/step - loss: 0.3248 - accuracy: 0.8894 - val_loss: 0.3662 - val_accuracy: 0.8493\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 188us/step - loss: 0.3212 - accuracy: 0.8914 - val_loss: 0.3635 - val_accuracy: 0.8493\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 172us/step - loss: 0.3177 - accuracy: 0.8933 - val_loss: 0.3608 - val_accuracy: 0.8539\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.3142 - accuracy: 0.8963 - val_loss: 0.3584 - val_accuracy: 0.8539\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 191us/step - loss: 0.3111 - accuracy: 0.8963 - val_loss: 0.3561 - val_accuracy: 0.8539\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 215us/step - loss: 0.3081 - accuracy: 0.8992 - val_loss: 0.3539 - val_accuracy: 0.8539\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 217us/step - loss: 0.3053 - accuracy: 0.9012 - val_loss: 0.3517 - val_accuracy: 0.8539\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.3026 - accuracy: 0.9012 - val_loss: 0.3496 - val_accuracy: 0.8584\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 176us/step - loss: 0.3002 - accuracy: 0.9012 - val_loss: 0.3476 - val_accuracy: 0.8584\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2978 - accuracy: 0.9012 - val_loss: 0.3456 - val_accuracy: 0.8630\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 166us/step - loss: 0.2956 - accuracy: 0.9012 - val_loss: 0.3437 - val_accuracy: 0.8630\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2935 - accuracy: 0.9031 - val_loss: 0.3420 - val_accuracy: 0.8630\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.2915 - accuracy: 0.9041 - val_loss: 0.3403 - val_accuracy: 0.8584\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2895 - accuracy: 0.9041 - val_loss: 0.3386 - val_accuracy: 0.8630\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2878 - accuracy: 0.9041 - val_loss: 0.3372 - val_accuracy: 0.8630\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2860 - accuracy: 0.9051 - val_loss: 0.3356 - val_accuracy: 0.8676\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2843 - accuracy: 0.9051 - val_loss: 0.3342 - val_accuracy: 0.8676\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2828 - accuracy: 0.9051 - val_loss: 0.3329 - val_accuracy: 0.8676\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2813 - accuracy: 0.9061 - val_loss: 0.3317 - val_accuracy: 0.8676\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2798 - accuracy: 0.9031 - val_loss: 0.3307 - val_accuracy: 0.8676\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2783 - accuracy: 0.9041 - val_loss: 0.3294 - val_accuracy: 0.8630\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2767 - accuracy: 0.9041 - val_loss: 0.3279 - val_accuracy: 0.8630\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2753 - accuracy: 0.9041 - val_loss: 0.3264 - val_accuracy: 0.8630\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2737 - accuracy: 0.9031 - val_loss: 0.3251 - val_accuracy: 0.8630\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2724 - accuracy: 0.9031 - val_loss: 0.3239 - val_accuracy: 0.8676\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2710 - accuracy: 0.9051 - val_loss: 0.3225 - val_accuracy: 0.8676\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2697 - accuracy: 0.9051 - val_loss: 0.3211 - val_accuracy: 0.8676\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2685 - accuracy: 0.9022 - val_loss: 0.3198 - val_accuracy: 0.8676\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2673 - accuracy: 0.9051 - val_loss: 0.3186 - val_accuracy: 0.8676\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.2661 - accuracy: 0.9061 - val_loss: 0.3175 - val_accuracy: 0.8630\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.2650 - accuracy: 0.9061 - val_loss: 0.3164 - val_accuracy: 0.8630\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2641 - accuracy: 0.9070 - val_loss: 0.3152 - val_accuracy: 0.8630\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 90us/step - loss: 0.2630 - accuracy: 0.9070 - val_loss: 0.3141 - val_accuracy: 0.8676\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2620 - accuracy: 0.9080 - val_loss: 0.3131 - val_accuracy: 0.8676\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2611 - accuracy: 0.9080 - val_loss: 0.3120 - val_accuracy: 0.8721\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 175us/step - loss: 0.2602 - accuracy: 0.9090 - val_loss: 0.3109 - val_accuracy: 0.8721\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 212us/step - loss: 0.2592 - accuracy: 0.9100 - val_loss: 0.3098 - val_accuracy: 0.8721\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2585 - accuracy: 0.9119 - val_loss: 0.3087 - val_accuracy: 0.8721\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.2575 - accuracy: 0.9119 - val_loss: 0.3076 - val_accuracy: 0.8721\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2567 - accuracy: 0.9090 - val_loss: 0.3067 - val_accuracy: 0.8721\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2560 - accuracy: 0.9110 - val_loss: 0.3057 - val_accuracy: 0.8721\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2552 - accuracy: 0.9110 - val_loss: 0.3049 - val_accuracy: 0.8721\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2545 - accuracy: 0.9090 - val_loss: 0.3040 - val_accuracy: 0.8721\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2537 - accuracy: 0.9110 - val_loss: 0.3032 - val_accuracy: 0.8721\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2530 - accuracy: 0.9070 - val_loss: 0.3023 - val_accuracy: 0.8721\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2524 - accuracy: 0.9090 - val_loss: 0.3015 - val_accuracy: 0.8721\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2517 - accuracy: 0.9080 - val_loss: 0.3007 - val_accuracy: 0.8721\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2510 - accuracy: 0.9080 - val_loss: 0.3000 - val_accuracy: 0.8721\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2504 - accuracy: 0.9090 - val_loss: 0.2994 - val_accuracy: 0.8721\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 263us/step - loss: 0.2498 - accuracy: 0.9090 - val_loss: 0.2987 - val_accuracy: 0.8721\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 398us/step - loss: 0.2493 - accuracy: 0.9080 - val_loss: 0.2979 - val_accuracy: 0.8721\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2486 - accuracy: 0.9080 - val_loss: 0.2974 - val_accuracy: 0.8721\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2481 - accuracy: 0.9070 - val_loss: 0.2967 - val_accuracy: 0.8767\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2475 - accuracy: 0.9080 - val_loss: 0.2961 - val_accuracy: 0.8721\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 350us/step - loss: 0.2468 - accuracy: 0.9080 - val_loss: 0.2955 - val_accuracy: 0.8767\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 215us/step - loss: 0.2464 - accuracy: 0.9070 - val_loss: 0.2948 - val_accuracy: 0.8767\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 189us/step - loss: 0.2458 - accuracy: 0.9080 - val_loss: 0.2943 - val_accuracy: 0.8767\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 173us/step - loss: 0.2454 - accuracy: 0.9080 - val_loss: 0.2937 - val_accuracy: 0.8767\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2449 - accuracy: 0.9061 - val_loss: 0.2931 - val_accuracy: 0.8767\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 870us/step - loss: 0.6444 - accuracy: 0.7094 - val_loss: 0.6366 - val_accuracy: 0.6804\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 194us/step - loss: 0.6317 - accuracy: 0.7006 - val_loss: 0.6239 - val_accuracy: 0.6849\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 180us/step - loss: 0.6193 - accuracy: 0.7065 - val_loss: 0.6112 - val_accuracy: 0.6941\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 174us/step - loss: 0.6066 - accuracy: 0.7114 - val_loss: 0.5984 - val_accuracy: 0.7078\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.5939 - accuracy: 0.7182 - val_loss: 0.5858 - val_accuracy: 0.7078\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 170us/step - loss: 0.5811 - accuracy: 0.7250 - val_loss: 0.5731 - val_accuracy: 0.7260\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.5682 - accuracy: 0.7260 - val_loss: 0.5600 - val_accuracy: 0.7397\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 169us/step - loss: 0.5545 - accuracy: 0.7290 - val_loss: 0.5466 - val_accuracy: 0.7443\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.5405 - accuracy: 0.7358 - val_loss: 0.5329 - val_accuracy: 0.7534\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 200us/step - loss: 0.5266 - accuracy: 0.7495 - val_loss: 0.5191 - val_accuracy: 0.7534\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 176us/step - loss: 0.5125 - accuracy: 0.7583 - val_loss: 0.5053 - val_accuracy: 0.7717\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.4985 - accuracy: 0.7632 - val_loss: 0.4919 - val_accuracy: 0.7717\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.4848 - accuracy: 0.8014 - val_loss: 0.4792 - val_accuracy: 0.7991\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.4716 - accuracy: 0.8180 - val_loss: 0.4672 - val_accuracy: 0.8037\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.4590 - accuracy: 0.8219 - val_loss: 0.4560 - val_accuracy: 0.8219\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.4471 - accuracy: 0.8239 - val_loss: 0.4452 - val_accuracy: 0.8219\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 170us/step - loss: 0.4357 - accuracy: 0.8278 - val_loss: 0.4344 - val_accuracy: 0.8219\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 180us/step - loss: 0.4246 - accuracy: 0.8297 - val_loss: 0.4241 - val_accuracy: 0.8265\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.4141 - accuracy: 0.8327 - val_loss: 0.4146 - val_accuracy: 0.8356\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.4040 - accuracy: 0.8356 - val_loss: 0.4057 - val_accuracy: 0.8356\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.3943 - accuracy: 0.8386 - val_loss: 0.3975 - val_accuracy: 0.8311\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.3852 - accuracy: 0.8415 - val_loss: 0.3900 - val_accuracy: 0.8311\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.3767 - accuracy: 0.8454 - val_loss: 0.3831 - val_accuracy: 0.8311\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.3687 - accuracy: 0.8483 - val_loss: 0.3767 - val_accuracy: 0.8311\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.3612 - accuracy: 0.8513 - val_loss: 0.3707 - val_accuracy: 0.8311\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.3541 - accuracy: 0.8523 - val_loss: 0.3651 - val_accuracy: 0.8219\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.3475 - accuracy: 0.8552 - val_loss: 0.3598 - val_accuracy: 0.8265\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.3411 - accuracy: 0.8611 - val_loss: 0.3548 - val_accuracy: 0.8311\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.3349 - accuracy: 0.8650 - val_loss: 0.3502 - val_accuracy: 0.8311\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.3290 - accuracy: 0.8679 - val_loss: 0.3459 - val_accuracy: 0.8356\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.3236 - accuracy: 0.8738 - val_loss: 0.3420 - val_accuracy: 0.8447\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.3187 - accuracy: 0.8767 - val_loss: 0.3383 - val_accuracy: 0.8447\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.3140 - accuracy: 0.8796 - val_loss: 0.3348 - val_accuracy: 0.8447\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 166us/step - loss: 0.3096 - accuracy: 0.8796 - val_loss: 0.3317 - val_accuracy: 0.8447\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.3056 - accuracy: 0.8836 - val_loss: 0.3287 - val_accuracy: 0.8447\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.3017 - accuracy: 0.8845 - val_loss: 0.3259 - val_accuracy: 0.8447\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 164us/step - loss: 0.2978 - accuracy: 0.8836 - val_loss: 0.3231 - val_accuracy: 0.8584\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.2943 - accuracy: 0.8845 - val_loss: 0.3204 - val_accuracy: 0.8539\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2910 - accuracy: 0.8865 - val_loss: 0.3179 - val_accuracy: 0.8539\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2879 - accuracy: 0.8885 - val_loss: 0.3156 - val_accuracy: 0.8539\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2850 - accuracy: 0.8904 - val_loss: 0.3134 - val_accuracy: 0.8539\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2822 - accuracy: 0.8885 - val_loss: 0.3112 - val_accuracy: 0.8539\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2793 - accuracy: 0.8904 - val_loss: 0.3093 - val_accuracy: 0.8539\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2766 - accuracy: 0.8894 - val_loss: 0.3074 - val_accuracy: 0.8539\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2742 - accuracy: 0.8914 - val_loss: 0.3057 - val_accuracy: 0.8584\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2720 - accuracy: 0.8933 - val_loss: 0.3041 - val_accuracy: 0.8630\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.2699 - accuracy: 0.8943 - val_loss: 0.3027 - val_accuracy: 0.8676\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2680 - accuracy: 0.8943 - val_loss: 0.3012 - val_accuracy: 0.8676\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2662 - accuracy: 0.8963 - val_loss: 0.2998 - val_accuracy: 0.8676\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 269us/step - loss: 0.2644 - accuracy: 0.8963 - val_loss: 0.2984 - val_accuracy: 0.8721\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2627 - accuracy: 0.8953 - val_loss: 0.2972 - val_accuracy: 0.8721\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2610 - accuracy: 0.8973 - val_loss: 0.2962 - val_accuracy: 0.8676\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 214us/step - loss: 0.2594 - accuracy: 0.8963 - val_loss: 0.2951 - val_accuracy: 0.8767\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2580 - accuracy: 0.8973 - val_loss: 0.2941 - val_accuracy: 0.8767\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2567 - accuracy: 0.8963 - val_loss: 0.2932 - val_accuracy: 0.8767\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2554 - accuracy: 0.8963 - val_loss: 0.2925 - val_accuracy: 0.8813\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2542 - accuracy: 0.8973 - val_loss: 0.2918 - val_accuracy: 0.8813\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2531 - accuracy: 0.8973 - val_loss: 0.2909 - val_accuracy: 0.8813\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2520 - accuracy: 0.8973 - val_loss: 0.2902 - val_accuracy: 0.8676\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2509 - accuracy: 0.8953 - val_loss: 0.2894 - val_accuracy: 0.8676\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2500 - accuracy: 0.8963 - val_loss: 0.2887 - val_accuracy: 0.8676\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2490 - accuracy: 0.8953 - val_loss: 0.2880 - val_accuracy: 0.8676\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2481 - accuracy: 0.8963 - val_loss: 0.2874 - val_accuracy: 0.8676\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2472 - accuracy: 0.8953 - val_loss: 0.2868 - val_accuracy: 0.8676\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2463 - accuracy: 0.8953 - val_loss: 0.2863 - val_accuracy: 0.8676\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2456 - accuracy: 0.8953 - val_loss: 0.2858 - val_accuracy: 0.8676\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2447 - accuracy: 0.8953 - val_loss: 0.2853 - val_accuracy: 0.8676\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2439 - accuracy: 0.8953 - val_loss: 0.2847 - val_accuracy: 0.8676\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2432 - accuracy: 0.8953 - val_loss: 0.2841 - val_accuracy: 0.8721\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2424 - accuracy: 0.8953 - val_loss: 0.2836 - val_accuracy: 0.8721\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2417 - accuracy: 0.8953 - val_loss: 0.2831 - val_accuracy: 0.8721\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2410 - accuracy: 0.8963 - val_loss: 0.2826 - val_accuracy: 0.8721\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2404 - accuracy: 0.8973 - val_loss: 0.2821 - val_accuracy: 0.8721\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2396 - accuracy: 0.8992 - val_loss: 0.2817 - val_accuracy: 0.8721\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2390 - accuracy: 0.8992 - val_loss: 0.2811 - val_accuracy: 0.8721\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2384 - accuracy: 0.9002 - val_loss: 0.2807 - val_accuracy: 0.8721\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2378 - accuracy: 0.9022 - val_loss: 0.2802 - val_accuracy: 0.8721\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2372 - accuracy: 0.9012 - val_loss: 0.2798 - val_accuracy: 0.8721\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2366 - accuracy: 0.9022 - val_loss: 0.2795 - val_accuracy: 0.8721\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2361 - accuracy: 0.9022 - val_loss: 0.2791 - val_accuracy: 0.8721\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.2356 - accuracy: 0.9012 - val_loss: 0.2787 - val_accuracy: 0.8721\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2352 - accuracy: 0.9012 - val_loss: 0.2783 - val_accuracy: 0.8721\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.2347 - accuracy: 0.9022 - val_loss: 0.2780 - val_accuracy: 0.8721\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2342 - accuracy: 0.9022 - val_loss: 0.2777 - val_accuracy: 0.8721\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2338 - accuracy: 0.9022 - val_loss: 0.2774 - val_accuracy: 0.8721\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2333 - accuracy: 0.9022 - val_loss: 0.2771 - val_accuracy: 0.8767\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2330 - accuracy: 0.9022 - val_loss: 0.2768 - val_accuracy: 0.8767\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2326 - accuracy: 0.9022 - val_loss: 0.2766 - val_accuracy: 0.8767\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2322 - accuracy: 0.9012 - val_loss: 0.2763 - val_accuracy: 0.8767\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2320 - accuracy: 0.9041 - val_loss: 0.2761 - val_accuracy: 0.8767\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2316 - accuracy: 0.9022 - val_loss: 0.2759 - val_accuracy: 0.8767\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2313 - accuracy: 0.9041 - val_loss: 0.2756 - val_accuracy: 0.8767\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2310 - accuracy: 0.9031 - val_loss: 0.2754 - val_accuracy: 0.8767\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2305 - accuracy: 0.9041 - val_loss: 0.2752 - val_accuracy: 0.8767\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2302 - accuracy: 0.9061 - val_loss: 0.2749 - val_accuracy: 0.8767\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2299 - accuracy: 0.9041 - val_loss: 0.2747 - val_accuracy: 0.8767\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2296 - accuracy: 0.9051 - val_loss: 0.2745 - val_accuracy: 0.8767\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2293 - accuracy: 0.9051 - val_loss: 0.2743 - val_accuracy: 0.8721\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2291 - accuracy: 0.9051 - val_loss: 0.2740 - val_accuracy: 0.8721\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2287 - accuracy: 0.9051 - val_loss: 0.2737 - val_accuracy: 0.8721\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 907us/step - loss: 0.7107 - accuracy: 0.5352 - val_loss: 0.6777 - val_accuracy: 0.6027\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 198us/step - loss: 0.6556 - accuracy: 0.6438 - val_loss: 0.6365 - val_accuracy: 0.7854\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 271us/step - loss: 0.6126 - accuracy: 0.8180 - val_loss: 0.6005 - val_accuracy: 0.8082\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.5744 - accuracy: 0.8327 - val_loss: 0.5666 - val_accuracy: 0.8219\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 166us/step - loss: 0.5387 - accuracy: 0.8425 - val_loss: 0.5351 - val_accuracy: 0.8219\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.5060 - accuracy: 0.8552 - val_loss: 0.5071 - val_accuracy: 0.8265\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.4760 - accuracy: 0.8650 - val_loss: 0.4817 - val_accuracy: 0.8265\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 167us/step - loss: 0.4489 - accuracy: 0.8689 - val_loss: 0.4589 - val_accuracy: 0.8311\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.4245 - accuracy: 0.8708 - val_loss: 0.4387 - val_accuracy: 0.8356\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 181us/step - loss: 0.4030 - accuracy: 0.8757 - val_loss: 0.4213 - val_accuracy: 0.8356\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.3839 - accuracy: 0.8806 - val_loss: 0.4065 - val_accuracy: 0.8402\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.3671 - accuracy: 0.8806 - val_loss: 0.3944 - val_accuracy: 0.8447\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.3529 - accuracy: 0.8845 - val_loss: 0.3842 - val_accuracy: 0.8447\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.3407 - accuracy: 0.8855 - val_loss: 0.3757 - val_accuracy: 0.8493\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.3303 - accuracy: 0.8855 - val_loss: 0.3686 - val_accuracy: 0.8402\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.3216 - accuracy: 0.8855 - val_loss: 0.3627 - val_accuracy: 0.8402\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 167us/step - loss: 0.3140 - accuracy: 0.8855 - val_loss: 0.3579 - val_accuracy: 0.8447\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.3075 - accuracy: 0.8865 - val_loss: 0.3538 - val_accuracy: 0.8356\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.3019 - accuracy: 0.8865 - val_loss: 0.3505 - val_accuracy: 0.8402\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2970 - accuracy: 0.8865 - val_loss: 0.3477 - val_accuracy: 0.8402\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2927 - accuracy: 0.8855 - val_loss: 0.3454 - val_accuracy: 0.8402\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2888 - accuracy: 0.8894 - val_loss: 0.3434 - val_accuracy: 0.8447\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2853 - accuracy: 0.8894 - val_loss: 0.3416 - val_accuracy: 0.8447\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2821 - accuracy: 0.8904 - val_loss: 0.3400 - val_accuracy: 0.8447\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2793 - accuracy: 0.8904 - val_loss: 0.3378 - val_accuracy: 0.8447\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2767 - accuracy: 0.8924 - val_loss: 0.3358 - val_accuracy: 0.8447\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2744 - accuracy: 0.8933 - val_loss: 0.3340 - val_accuracy: 0.8493\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2722 - accuracy: 0.8953 - val_loss: 0.3325 - val_accuracy: 0.8493\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2703 - accuracy: 0.8953 - val_loss: 0.3311 - val_accuracy: 0.8539\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2686 - accuracy: 0.8973 - val_loss: 0.3299 - val_accuracy: 0.8539\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2669 - accuracy: 0.8982 - val_loss: 0.3287 - val_accuracy: 0.8539\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2656 - accuracy: 0.8973 - val_loss: 0.3275 - val_accuracy: 0.8539\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2641 - accuracy: 0.8982 - val_loss: 0.3258 - val_accuracy: 0.8584\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2627 - accuracy: 0.8982 - val_loss: 0.3234 - val_accuracy: 0.8584\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2614 - accuracy: 0.8992 - val_loss: 0.3216 - val_accuracy: 0.8630\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2601 - accuracy: 0.8992 - val_loss: 0.3202 - val_accuracy: 0.8630\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2590 - accuracy: 0.9002 - val_loss: 0.3188 - val_accuracy: 0.8630\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2580 - accuracy: 0.9002 - val_loss: 0.3177 - val_accuracy: 0.8630\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2571 - accuracy: 0.9002 - val_loss: 0.3165 - val_accuracy: 0.8630\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2562 - accuracy: 0.9002 - val_loss: 0.3153 - val_accuracy: 0.8630\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2554 - accuracy: 0.9002 - val_loss: 0.3143 - val_accuracy: 0.8630\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2546 - accuracy: 0.8992 - val_loss: 0.3133 - val_accuracy: 0.8630\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 99us/step - loss: 0.2539 - accuracy: 0.9002 - val_loss: 0.3124 - val_accuracy: 0.8630\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 100us/step - loss: 0.2531 - accuracy: 0.9012 - val_loss: 0.3115 - val_accuracy: 0.8630\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 100us/step - loss: 0.2523 - accuracy: 0.9022 - val_loss: 0.3106 - val_accuracy: 0.8630\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2517 - accuracy: 0.9022 - val_loss: 0.3098 - val_accuracy: 0.8630\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2510 - accuracy: 0.9012 - val_loss: 0.3090 - val_accuracy: 0.8630\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2504 - accuracy: 0.9002 - val_loss: 0.3083 - val_accuracy: 0.8630\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2498 - accuracy: 0.9002 - val_loss: 0.3075 - val_accuracy: 0.8630\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 220us/step - loss: 0.2493 - accuracy: 0.8992 - val_loss: 0.3066 - val_accuracy: 0.8630\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2487 - accuracy: 0.8992 - val_loss: 0.3058 - val_accuracy: 0.8630\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2483 - accuracy: 0.8992 - val_loss: 0.3049 - val_accuracy: 0.8630\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2478 - accuracy: 0.9002 - val_loss: 0.3042 - val_accuracy: 0.8630\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2475 - accuracy: 0.9012 - val_loss: 0.3035 - val_accuracy: 0.8630\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2471 - accuracy: 0.9002 - val_loss: 0.3028 - val_accuracy: 0.8630\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2465 - accuracy: 0.9012 - val_loss: 0.3022 - val_accuracy: 0.8630\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2462 - accuracy: 0.9012 - val_loss: 0.3015 - val_accuracy: 0.8630\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2458 - accuracy: 0.9012 - val_loss: 0.3008 - val_accuracy: 0.8630\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.2454 - accuracy: 0.9012 - val_loss: 0.3001 - val_accuracy: 0.8630\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2450 - accuracy: 0.9012 - val_loss: 0.2996 - val_accuracy: 0.8630\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.2446 - accuracy: 0.9012 - val_loss: 0.2990 - val_accuracy: 0.8630\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 168us/step - loss: 0.2442 - accuracy: 0.9012 - val_loss: 0.2985 - val_accuracy: 0.8630\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 196us/step - loss: 0.2439 - accuracy: 0.9012 - val_loss: 0.2979 - val_accuracy: 0.8630\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2435 - accuracy: 0.9012 - val_loss: 0.2974 - val_accuracy: 0.8630\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2432 - accuracy: 0.9022 - val_loss: 0.2969 - val_accuracy: 0.8584\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2430 - accuracy: 0.9022 - val_loss: 0.2964 - val_accuracy: 0.8584\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2426 - accuracy: 0.9012 - val_loss: 0.2959 - val_accuracy: 0.8584\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2424 - accuracy: 0.9022 - val_loss: 0.2954 - val_accuracy: 0.8584\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.2421 - accuracy: 0.9031 - val_loss: 0.2950 - val_accuracy: 0.8584\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.2418 - accuracy: 0.9031 - val_loss: 0.2945 - val_accuracy: 0.8584\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2415 - accuracy: 0.9031 - val_loss: 0.2941 - val_accuracy: 0.8584\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.2413 - accuracy: 0.9031 - val_loss: 0.2936 - val_accuracy: 0.8584\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 193us/step - loss: 0.2410 - accuracy: 0.9031 - val_loss: 0.2932 - val_accuracy: 0.8584\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 222us/step - loss: 0.2408 - accuracy: 0.9031 - val_loss: 0.2928 - val_accuracy: 0.8584\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2406 - accuracy: 0.9031 - val_loss: 0.2924 - val_accuracy: 0.8584\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2404 - accuracy: 0.9031 - val_loss: 0.2920 - val_accuracy: 0.8584\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 264us/step - loss: 0.2402 - accuracy: 0.9041 - val_loss: 0.2916 - val_accuracy: 0.8584\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 332us/step - loss: 0.2400 - accuracy: 0.9041 - val_loss: 0.2912 - val_accuracy: 0.8584\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 213us/step - loss: 0.2397 - accuracy: 0.9031 - val_loss: 0.2908 - val_accuracy: 0.8584\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2396 - accuracy: 0.9041 - val_loss: 0.2905 - val_accuracy: 0.8584\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 336us/step - loss: 0.2394 - accuracy: 0.9031 - val_loss: 0.2901 - val_accuracy: 0.8584\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 218us/step - loss: 0.2392 - accuracy: 0.9031 - val_loss: 0.2898 - val_accuracy: 0.8584\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 263us/step - loss: 0.2391 - accuracy: 0.9031 - val_loss: 0.2894 - val_accuracy: 0.8584\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 1s 506us/step - loss: 0.2388 - accuracy: 0.9031 - val_loss: 0.2891 - val_accuracy: 0.8584\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.2387 - accuracy: 0.9041 - val_loss: 0.2887 - val_accuracy: 0.8584\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 259us/step - loss: 0.2384 - accuracy: 0.9031 - val_loss: 0.2884 - val_accuracy: 0.8584\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2383 - accuracy: 0.9022 - val_loss: 0.2880 - val_accuracy: 0.8584\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 221us/step - loss: 0.2381 - accuracy: 0.9041 - val_loss: 0.2876 - val_accuracy: 0.8584\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 251us/step - loss: 0.2379 - accuracy: 0.9031 - val_loss: 0.2872 - val_accuracy: 0.8584\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 191us/step - loss: 0.2376 - accuracy: 0.9051 - val_loss: 0.2869 - val_accuracy: 0.8584\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 382us/step - loss: 0.2374 - accuracy: 0.9051 - val_loss: 0.2867 - val_accuracy: 0.8630\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 260us/step - loss: 0.2373 - accuracy: 0.9051 - val_loss: 0.2864 - val_accuracy: 0.8630\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 459us/step - loss: 0.2371 - accuracy: 0.9041 - val_loss: 0.2862 - val_accuracy: 0.8630\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 322us/step - loss: 0.2370 - accuracy: 0.9051 - val_loss: 0.2859 - val_accuracy: 0.8630\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 372us/step - loss: 0.2368 - accuracy: 0.9051 - val_loss: 0.2857 - val_accuracy: 0.8630\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 324us/step - loss: 0.2367 - accuracy: 0.9051 - val_loss: 0.2856 - val_accuracy: 0.8630\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2365 - accuracy: 0.9051 - val_loss: 0.2854 - val_accuracy: 0.8630\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 258us/step - loss: 0.2365 - accuracy: 0.9051 - val_loss: 0.2852 - val_accuracy: 0.8630\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 393us/step - loss: 0.2362 - accuracy: 0.9051 - val_loss: 0.2850 - val_accuracy: 0.8630\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 372us/step - loss: 0.2361 - accuracy: 0.9051 - val_loss: 0.2847 - val_accuracy: 0.8630\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.7257 - accuracy: 0.4697 - val_loss: 0.7255 - val_accuracy: 0.4292\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 346us/step - loss: 0.7132 - accuracy: 0.4843 - val_loss: 0.7152 - val_accuracy: 0.4429\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 212us/step - loss: 0.7051 - accuracy: 0.5020 - val_loss: 0.7084 - val_accuracy: 0.4612\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 271us/step - loss: 0.6994 - accuracy: 0.5274 - val_loss: 0.7036 - val_accuracy: 0.4749\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 237us/step - loss: 0.6951 - accuracy: 0.5382 - val_loss: 0.7001 - val_accuracy: 0.4795\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 215us/step - loss: 0.6916 - accuracy: 0.5489 - val_loss: 0.6974 - val_accuracy: 0.4977\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 278us/step - loss: 0.6886 - accuracy: 0.5656 - val_loss: 0.6950 - val_accuracy: 0.5068\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 287us/step - loss: 0.6856 - accuracy: 0.5773 - val_loss: 0.6927 - val_accuracy: 0.5251\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 220us/step - loss: 0.6826 - accuracy: 0.5930 - val_loss: 0.6904 - val_accuracy: 0.5388\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 184us/step - loss: 0.6791 - accuracy: 0.5998 - val_loss: 0.6877 - val_accuracy: 0.5571\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 262us/step - loss: 0.6752 - accuracy: 0.6135 - val_loss: 0.6845 - val_accuracy: 0.5845\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 337us/step - loss: 0.6706 - accuracy: 0.6311 - val_loss: 0.6808 - val_accuracy: 0.5982\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 232us/step - loss: 0.6652 - accuracy: 0.6429 - val_loss: 0.6764 - val_accuracy: 0.6073\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 326us/step - loss: 0.6591 - accuracy: 0.6605 - val_loss: 0.6712 - val_accuracy: 0.6301\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 336us/step - loss: 0.6519 - accuracy: 0.6732 - val_loss: 0.6651 - val_accuracy: 0.6393\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 199us/step - loss: 0.6440 - accuracy: 0.6810 - val_loss: 0.6579 - val_accuracy: 0.6484\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.6349 - accuracy: 0.6967 - val_loss: 0.6496 - val_accuracy: 0.6667\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 197us/step - loss: 0.6247 - accuracy: 0.7114 - val_loss: 0.6403 - val_accuracy: 0.6895\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 220us/step - loss: 0.6136 - accuracy: 0.7182 - val_loss: 0.6304 - val_accuracy: 0.7032\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 271us/step - loss: 0.6020 - accuracy: 0.7339 - val_loss: 0.6200 - val_accuracy: 0.7123\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 244us/step - loss: 0.5900 - accuracy: 0.7436 - val_loss: 0.6091 - val_accuracy: 0.7260\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 225us/step - loss: 0.5776 - accuracy: 0.7554 - val_loss: 0.5982 - val_accuracy: 0.7306\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 283us/step - loss: 0.5651 - accuracy: 0.7642 - val_loss: 0.5874 - val_accuracy: 0.7397\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.5527 - accuracy: 0.7789 - val_loss: 0.5769 - val_accuracy: 0.7443\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.5403 - accuracy: 0.7867 - val_loss: 0.5665 - val_accuracy: 0.7534\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 171us/step - loss: 0.5284 - accuracy: 0.7955 - val_loss: 0.5564 - val_accuracy: 0.7580\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.5170 - accuracy: 0.8063 - val_loss: 0.5466 - val_accuracy: 0.7580\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.5061 - accuracy: 0.8190 - val_loss: 0.5372 - val_accuracy: 0.7717\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.4956 - accuracy: 0.8209 - val_loss: 0.5281 - val_accuracy: 0.7717\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.4854 - accuracy: 0.8288 - val_loss: 0.5198 - val_accuracy: 0.7763\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.4759 - accuracy: 0.8337 - val_loss: 0.5118 - val_accuracy: 0.7763\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 170us/step - loss: 0.4669 - accuracy: 0.8337 - val_loss: 0.5044 - val_accuracy: 0.7763\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.4583 - accuracy: 0.8415 - val_loss: 0.4974 - val_accuracy: 0.7854\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.4503 - accuracy: 0.8415 - val_loss: 0.4908 - val_accuracy: 0.7900\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.4426 - accuracy: 0.8454 - val_loss: 0.4844 - val_accuracy: 0.7991\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.4354 - accuracy: 0.8562 - val_loss: 0.4784 - val_accuracy: 0.7945\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.4285 - accuracy: 0.8552 - val_loss: 0.4726 - val_accuracy: 0.8082\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.4220 - accuracy: 0.8571 - val_loss: 0.4671 - val_accuracy: 0.8082\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.4158 - accuracy: 0.8601 - val_loss: 0.4617 - val_accuracy: 0.8082\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.4098 - accuracy: 0.8591 - val_loss: 0.4566 - val_accuracy: 0.8128\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.4041 - accuracy: 0.8601 - val_loss: 0.4517 - val_accuracy: 0.8128\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.3987 - accuracy: 0.8620 - val_loss: 0.4470 - val_accuracy: 0.8174\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.3936 - accuracy: 0.8659 - val_loss: 0.4426 - val_accuracy: 0.8219\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.3885 - accuracy: 0.8669 - val_loss: 0.4383 - val_accuracy: 0.8174\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.3836 - accuracy: 0.8708 - val_loss: 0.4342 - val_accuracy: 0.8174\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.3790 - accuracy: 0.8699 - val_loss: 0.4302 - val_accuracy: 0.8219\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.3747 - accuracy: 0.8738 - val_loss: 0.4263 - val_accuracy: 0.8219\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.3704 - accuracy: 0.8767 - val_loss: 0.4227 - val_accuracy: 0.8311\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 100us/step - loss: 0.3665 - accuracy: 0.8767 - val_loss: 0.4193 - val_accuracy: 0.8265\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.3627 - accuracy: 0.8777 - val_loss: 0.4159 - val_accuracy: 0.8311\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.3590 - accuracy: 0.8787 - val_loss: 0.4124 - val_accuracy: 0.8356\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.3554 - accuracy: 0.8787 - val_loss: 0.4091 - val_accuracy: 0.8356\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.3518 - accuracy: 0.8796 - val_loss: 0.4058 - val_accuracy: 0.8219\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.3483 - accuracy: 0.8826 - val_loss: 0.4028 - val_accuracy: 0.8219\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.3450 - accuracy: 0.8806 - val_loss: 0.3999 - val_accuracy: 0.8219\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.3418 - accuracy: 0.8767 - val_loss: 0.3971 - val_accuracy: 0.8219\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.3387 - accuracy: 0.8777 - val_loss: 0.3945 - val_accuracy: 0.8219\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.3357 - accuracy: 0.8806 - val_loss: 0.3920 - val_accuracy: 0.8174\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.3328 - accuracy: 0.8796 - val_loss: 0.3894 - val_accuracy: 0.8219\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.3298 - accuracy: 0.8806 - val_loss: 0.3868 - val_accuracy: 0.8219\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.3271 - accuracy: 0.8826 - val_loss: 0.3843 - val_accuracy: 0.8219\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.3245 - accuracy: 0.8826 - val_loss: 0.3821 - val_accuracy: 0.8265\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.3220 - accuracy: 0.8826 - val_loss: 0.3798 - val_accuracy: 0.8265\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.3196 - accuracy: 0.8845 - val_loss: 0.3777 - val_accuracy: 0.8265\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.3174 - accuracy: 0.8845 - val_loss: 0.3758 - val_accuracy: 0.8265\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.3153 - accuracy: 0.8845 - val_loss: 0.3738 - val_accuracy: 0.8265\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.3133 - accuracy: 0.8836 - val_loss: 0.3719 - val_accuracy: 0.8311\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.3113 - accuracy: 0.8845 - val_loss: 0.3700 - val_accuracy: 0.8356\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.3094 - accuracy: 0.8845 - val_loss: 0.3680 - val_accuracy: 0.8447\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.3074 - accuracy: 0.8836 - val_loss: 0.3663 - val_accuracy: 0.8447\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.3056 - accuracy: 0.8836 - val_loss: 0.3647 - val_accuracy: 0.8447\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.3037 - accuracy: 0.8845 - val_loss: 0.3630 - val_accuracy: 0.8447\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.3019 - accuracy: 0.8855 - val_loss: 0.3614 - val_accuracy: 0.8493\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.3002 - accuracy: 0.8885 - val_loss: 0.3600 - val_accuracy: 0.8493\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.2985 - accuracy: 0.8875 - val_loss: 0.3584 - val_accuracy: 0.8493\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2969 - accuracy: 0.8875 - val_loss: 0.3569 - val_accuracy: 0.8493\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2953 - accuracy: 0.8875 - val_loss: 0.3555 - val_accuracy: 0.8493\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2937 - accuracy: 0.8894 - val_loss: 0.3541 - val_accuracy: 0.8493\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2921 - accuracy: 0.8885 - val_loss: 0.3526 - val_accuracy: 0.8493\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2907 - accuracy: 0.8885 - val_loss: 0.3514 - val_accuracy: 0.8493\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2891 - accuracy: 0.8894 - val_loss: 0.3500 - val_accuracy: 0.8493\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2876 - accuracy: 0.8875 - val_loss: 0.3488 - val_accuracy: 0.8493\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2862 - accuracy: 0.8875 - val_loss: 0.3476 - val_accuracy: 0.8493\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.2847 - accuracy: 0.8894 - val_loss: 0.3465 - val_accuracy: 0.8493\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2835 - accuracy: 0.8904 - val_loss: 0.3455 - val_accuracy: 0.8493\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.2822 - accuracy: 0.8914 - val_loss: 0.3443 - val_accuracy: 0.8493\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2810 - accuracy: 0.8924 - val_loss: 0.3432 - val_accuracy: 0.8493\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2798 - accuracy: 0.8924 - val_loss: 0.3420 - val_accuracy: 0.8493\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2787 - accuracy: 0.8933 - val_loss: 0.3411 - val_accuracy: 0.8493\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2776 - accuracy: 0.8963 - val_loss: 0.3399 - val_accuracy: 0.8493\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2766 - accuracy: 0.8963 - val_loss: 0.3389 - val_accuracy: 0.8493\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2756 - accuracy: 0.8963 - val_loss: 0.3379 - val_accuracy: 0.8493\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2747 - accuracy: 0.8973 - val_loss: 0.3369 - val_accuracy: 0.8493\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 251us/step - loss: 0.2737 - accuracy: 0.8992 - val_loss: 0.3360 - val_accuracy: 0.8493\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2727 - accuracy: 0.8992 - val_loss: 0.3350 - val_accuracy: 0.8493\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.2718 - accuracy: 0.9002 - val_loss: 0.3340 - val_accuracy: 0.8584\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 177us/step - loss: 0.2709 - accuracy: 0.8992 - val_loss: 0.3330 - val_accuracy: 0.8584\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 185us/step - loss: 0.2700 - accuracy: 0.8992 - val_loss: 0.3320 - val_accuracy: 0.8584\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 311us/step - loss: 0.2691 - accuracy: 0.8992 - val_loss: 0.3313 - val_accuracy: 0.8584\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 185us/step - loss: 0.2683 - accuracy: 0.8982 - val_loss: 0.3303 - val_accuracy: 0.8584\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.6513 - accuracy: 0.7241 - val_loss: 0.6536 - val_accuracy: 0.6895\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 250us/step - loss: 0.6391 - accuracy: 0.7260 - val_loss: 0.6435 - val_accuracy: 0.6895\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 236us/step - loss: 0.6273 - accuracy: 0.7309 - val_loss: 0.6336 - val_accuracy: 0.6895\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.6157 - accuracy: 0.7339 - val_loss: 0.6237 - val_accuracy: 0.6986\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.6040 - accuracy: 0.7446 - val_loss: 0.6136 - val_accuracy: 0.6986\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.5921 - accuracy: 0.7524 - val_loss: 0.6032 - val_accuracy: 0.7169\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.5799 - accuracy: 0.7622 - val_loss: 0.5924 - val_accuracy: 0.7306\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 193us/step - loss: 0.5675 - accuracy: 0.7691 - val_loss: 0.5813 - val_accuracy: 0.7352\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 231us/step - loss: 0.5550 - accuracy: 0.7779 - val_loss: 0.5702 - val_accuracy: 0.7397\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 215us/step - loss: 0.5426 - accuracy: 0.7828 - val_loss: 0.5591 - val_accuracy: 0.7717\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.5298 - accuracy: 0.7935 - val_loss: 0.5479 - val_accuracy: 0.7854\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.5166 - accuracy: 0.7975 - val_loss: 0.5363 - val_accuracy: 0.7900\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 220us/step - loss: 0.5032 - accuracy: 0.8072 - val_loss: 0.5250 - val_accuracy: 0.7945\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.4900 - accuracy: 0.8151 - val_loss: 0.5141 - val_accuracy: 0.7991\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 247us/step - loss: 0.4769 - accuracy: 0.8297 - val_loss: 0.5036 - val_accuracy: 0.8128\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 172us/step - loss: 0.4639 - accuracy: 0.8327 - val_loss: 0.4935 - val_accuracy: 0.8082\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 175us/step - loss: 0.4511 - accuracy: 0.8405 - val_loss: 0.4838 - val_accuracy: 0.8082\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 209us/step - loss: 0.4387 - accuracy: 0.8454 - val_loss: 0.4746 - val_accuracy: 0.8037\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 219us/step - loss: 0.4268 - accuracy: 0.8483 - val_loss: 0.4661 - val_accuracy: 0.8082\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.4153 - accuracy: 0.8493 - val_loss: 0.4583 - val_accuracy: 0.8128\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.4043 - accuracy: 0.8562 - val_loss: 0.4509 - val_accuracy: 0.8174\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 216us/step - loss: 0.3940 - accuracy: 0.8581 - val_loss: 0.4442 - val_accuracy: 0.8219\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.3845 - accuracy: 0.8601 - val_loss: 0.4384 - val_accuracy: 0.8219\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 225us/step - loss: 0.3758 - accuracy: 0.8630 - val_loss: 0.4333 - val_accuracy: 0.8219\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 186us/step - loss: 0.3678 - accuracy: 0.8699 - val_loss: 0.4285 - val_accuracy: 0.8174\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.3603 - accuracy: 0.8728 - val_loss: 0.4241 - val_accuracy: 0.8265\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.3533 - accuracy: 0.8757 - val_loss: 0.4205 - val_accuracy: 0.8265\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.3469 - accuracy: 0.8757 - val_loss: 0.4170 - val_accuracy: 0.8311\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 190us/step - loss: 0.3409 - accuracy: 0.8777 - val_loss: 0.4137 - val_accuracy: 0.8311\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 180us/step - loss: 0.3352 - accuracy: 0.8787 - val_loss: 0.4105 - val_accuracy: 0.8311\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 225us/step - loss: 0.3298 - accuracy: 0.8806 - val_loss: 0.4074 - val_accuracy: 0.8311\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 203us/step - loss: 0.3248 - accuracy: 0.8826 - val_loss: 0.4046 - val_accuracy: 0.8311\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.3203 - accuracy: 0.8806 - val_loss: 0.4020 - val_accuracy: 0.8311\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.3161 - accuracy: 0.8826 - val_loss: 0.3996 - val_accuracy: 0.8311\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.3122 - accuracy: 0.8816 - val_loss: 0.3974 - val_accuracy: 0.8311\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.3086 - accuracy: 0.8826 - val_loss: 0.3954 - val_accuracy: 0.8311\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.3052 - accuracy: 0.8826 - val_loss: 0.3936 - val_accuracy: 0.8311\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.3021 - accuracy: 0.8855 - val_loss: 0.3920 - val_accuracy: 0.8311\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2991 - accuracy: 0.8855 - val_loss: 0.3902 - val_accuracy: 0.8311\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2961 - accuracy: 0.8875 - val_loss: 0.3885 - val_accuracy: 0.8311\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2933 - accuracy: 0.8894 - val_loss: 0.3870 - val_accuracy: 0.8356\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2908 - accuracy: 0.8914 - val_loss: 0.3855 - val_accuracy: 0.8356\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2885 - accuracy: 0.8933 - val_loss: 0.3841 - val_accuracy: 0.8356\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2863 - accuracy: 0.8953 - val_loss: 0.3826 - val_accuracy: 0.8402\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2843 - accuracy: 0.8933 - val_loss: 0.3813 - val_accuracy: 0.8402\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2824 - accuracy: 0.8953 - val_loss: 0.3800 - val_accuracy: 0.8447\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2806 - accuracy: 0.8953 - val_loss: 0.3787 - val_accuracy: 0.8447\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2788 - accuracy: 0.8953 - val_loss: 0.3774 - val_accuracy: 0.8447\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2770 - accuracy: 0.8953 - val_loss: 0.3760 - val_accuracy: 0.8402\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2754 - accuracy: 0.8963 - val_loss: 0.3748 - val_accuracy: 0.8402\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2740 - accuracy: 0.8982 - val_loss: 0.3736 - val_accuracy: 0.8402\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2725 - accuracy: 0.8992 - val_loss: 0.3724 - val_accuracy: 0.8402\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2712 - accuracy: 0.9002 - val_loss: 0.3712 - val_accuracy: 0.8402\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2701 - accuracy: 0.8992 - val_loss: 0.3700 - val_accuracy: 0.8356\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2691 - accuracy: 0.9012 - val_loss: 0.3688 - val_accuracy: 0.8356\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2681 - accuracy: 0.9012 - val_loss: 0.3675 - val_accuracy: 0.8356\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2671 - accuracy: 0.9012 - val_loss: 0.3658 - val_accuracy: 0.8356\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2661 - accuracy: 0.8992 - val_loss: 0.3638 - val_accuracy: 0.8356\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.2651 - accuracy: 0.9002 - val_loss: 0.3618 - val_accuracy: 0.8402\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.2640 - accuracy: 0.8992 - val_loss: 0.3596 - val_accuracy: 0.8402\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2631 - accuracy: 0.9002 - val_loss: 0.3576 - val_accuracy: 0.8402\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2622 - accuracy: 0.8992 - val_loss: 0.3555 - val_accuracy: 0.8402\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2614 - accuracy: 0.8982 - val_loss: 0.3536 - val_accuracy: 0.8402\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2605 - accuracy: 0.9002 - val_loss: 0.3517 - val_accuracy: 0.8402\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.2599 - accuracy: 0.8992 - val_loss: 0.3498 - val_accuracy: 0.8402\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2590 - accuracy: 0.8992 - val_loss: 0.3479 - val_accuracy: 0.8402\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2582 - accuracy: 0.8992 - val_loss: 0.3461 - val_accuracy: 0.8402\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2574 - accuracy: 0.9002 - val_loss: 0.3442 - val_accuracy: 0.8402\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2566 - accuracy: 0.9002 - val_loss: 0.3418 - val_accuracy: 0.8402\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2556 - accuracy: 0.9002 - val_loss: 0.3392 - val_accuracy: 0.8402\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2547 - accuracy: 0.9012 - val_loss: 0.3367 - val_accuracy: 0.8447\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2539 - accuracy: 0.9022 - val_loss: 0.3346 - val_accuracy: 0.8447\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2532 - accuracy: 0.9022 - val_loss: 0.3326 - val_accuracy: 0.8447\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.2525 - accuracy: 0.9022 - val_loss: 0.3307 - val_accuracy: 0.8493\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2517 - accuracy: 0.9022 - val_loss: 0.3289 - val_accuracy: 0.8493\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2511 - accuracy: 0.9031 - val_loss: 0.3273 - val_accuracy: 0.8493\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2504 - accuracy: 0.9022 - val_loss: 0.3257 - val_accuracy: 0.8493\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 309us/step - loss: 0.2498 - accuracy: 0.9031 - val_loss: 0.3243 - val_accuracy: 0.8493\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 265us/step - loss: 0.2493 - accuracy: 0.9031 - val_loss: 0.3230 - val_accuracy: 0.8493\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2487 - accuracy: 0.9031 - val_loss: 0.3216 - val_accuracy: 0.8539\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2481 - accuracy: 0.9031 - val_loss: 0.3204 - val_accuracy: 0.8539\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2476 - accuracy: 0.9031 - val_loss: 0.3192 - val_accuracy: 0.8493\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2471 - accuracy: 0.9031 - val_loss: 0.3181 - val_accuracy: 0.8493\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2465 - accuracy: 0.9051 - val_loss: 0.3169 - val_accuracy: 0.8493\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2460 - accuracy: 0.9041 - val_loss: 0.3159 - val_accuracy: 0.8493\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2456 - accuracy: 0.9031 - val_loss: 0.3147 - val_accuracy: 0.8493\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2451 - accuracy: 0.9031 - val_loss: 0.3136 - val_accuracy: 0.8539\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2446 - accuracy: 0.9031 - val_loss: 0.3127 - val_accuracy: 0.8539\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2442 - accuracy: 0.9022 - val_loss: 0.3116 - val_accuracy: 0.8539\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2439 - accuracy: 0.9031 - val_loss: 0.3107 - val_accuracy: 0.8539\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2434 - accuracy: 0.9022 - val_loss: 0.3098 - val_accuracy: 0.8539\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2431 - accuracy: 0.9022 - val_loss: 0.3091 - val_accuracy: 0.8539\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2427 - accuracy: 0.9031 - val_loss: 0.3082 - val_accuracy: 0.8539\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2423 - accuracy: 0.9022 - val_loss: 0.3074 - val_accuracy: 0.8539\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2421 - accuracy: 0.9012 - val_loss: 0.3067 - val_accuracy: 0.8539\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2416 - accuracy: 0.8992 - val_loss: 0.3060 - val_accuracy: 0.8584\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 200us/step - loss: 0.2412 - accuracy: 0.9002 - val_loss: 0.3052 - val_accuracy: 0.8584\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2409 - accuracy: 0.8992 - val_loss: 0.3045 - val_accuracy: 0.8584\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2405 - accuracy: 0.8992 - val_loss: 0.3039 - val_accuracy: 0.8584\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2403 - accuracy: 0.8982 - val_loss: 0.3033 - val_accuracy: 0.8584\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 798us/step - loss: 0.7008 - accuracy: 0.5411 - val_loss: 0.6971 - val_accuracy: 0.5662\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.6849 - accuracy: 0.6233 - val_loss: 0.6838 - val_accuracy: 0.5936\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.6721 - accuracy: 0.6389 - val_loss: 0.6725 - val_accuracy: 0.6301\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.6606 - accuracy: 0.6624 - val_loss: 0.6619 - val_accuracy: 0.6621\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.6493 - accuracy: 0.6840 - val_loss: 0.6512 - val_accuracy: 0.6895\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.6378 - accuracy: 0.6986 - val_loss: 0.6402 - val_accuracy: 0.7078\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.6256 - accuracy: 0.7153 - val_loss: 0.6286 - val_accuracy: 0.7123\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.6128 - accuracy: 0.7250 - val_loss: 0.6162 - val_accuracy: 0.7260\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.5993 - accuracy: 0.7387 - val_loss: 0.6032 - val_accuracy: 0.7352\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.5856 - accuracy: 0.7515 - val_loss: 0.5901 - val_accuracy: 0.7352\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.5717 - accuracy: 0.7652 - val_loss: 0.5771 - val_accuracy: 0.7626\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.5578 - accuracy: 0.7759 - val_loss: 0.5645 - val_accuracy: 0.7671\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.5440 - accuracy: 0.7906 - val_loss: 0.5518 - val_accuracy: 0.7580\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.5303 - accuracy: 0.8023 - val_loss: 0.5394 - val_accuracy: 0.7808\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.5169 - accuracy: 0.8112 - val_loss: 0.5276 - val_accuracy: 0.7854\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.5036 - accuracy: 0.8141 - val_loss: 0.5158 - val_accuracy: 0.7991\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.4908 - accuracy: 0.8200 - val_loss: 0.5044 - val_accuracy: 0.7900\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.4782 - accuracy: 0.8288 - val_loss: 0.4933 - val_accuracy: 0.7945\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.4661 - accuracy: 0.8366 - val_loss: 0.4826 - val_accuracy: 0.7991\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.4542 - accuracy: 0.8356 - val_loss: 0.4722 - val_accuracy: 0.8082\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.4427 - accuracy: 0.8425 - val_loss: 0.4617 - val_accuracy: 0.8174\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.4313 - accuracy: 0.8464 - val_loss: 0.4520 - val_accuracy: 0.8265\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.4208 - accuracy: 0.8571 - val_loss: 0.4434 - val_accuracy: 0.8356\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.4107 - accuracy: 0.8620 - val_loss: 0.4353 - val_accuracy: 0.8447\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 167us/step - loss: 0.4010 - accuracy: 0.8689 - val_loss: 0.4279 - val_accuracy: 0.8493\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.3918 - accuracy: 0.8708 - val_loss: 0.4211 - val_accuracy: 0.8493\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.3833 - accuracy: 0.8787 - val_loss: 0.4149 - val_accuracy: 0.8493\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.3752 - accuracy: 0.8796 - val_loss: 0.4092 - val_accuracy: 0.8493\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.3673 - accuracy: 0.8816 - val_loss: 0.4039 - val_accuracy: 0.8493\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.3598 - accuracy: 0.8816 - val_loss: 0.3987 - val_accuracy: 0.8356\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.3527 - accuracy: 0.8836 - val_loss: 0.3940 - val_accuracy: 0.8265\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.3462 - accuracy: 0.8806 - val_loss: 0.3895 - val_accuracy: 0.8265\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.3402 - accuracy: 0.8855 - val_loss: 0.3853 - val_accuracy: 0.8311\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.3345 - accuracy: 0.8885 - val_loss: 0.3815 - val_accuracy: 0.8356\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.3292 - accuracy: 0.8933 - val_loss: 0.3782 - val_accuracy: 0.8402\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.3246 - accuracy: 0.8953 - val_loss: 0.3752 - val_accuracy: 0.8402\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.3204 - accuracy: 0.8963 - val_loss: 0.3721 - val_accuracy: 0.8447\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.3162 - accuracy: 0.8943 - val_loss: 0.3693 - val_accuracy: 0.8447\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.3126 - accuracy: 0.8943 - val_loss: 0.3668 - val_accuracy: 0.8402\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.3092 - accuracy: 0.8953 - val_loss: 0.3646 - val_accuracy: 0.8447\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.3060 - accuracy: 0.8973 - val_loss: 0.3626 - val_accuracy: 0.8539\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.3033 - accuracy: 0.8963 - val_loss: 0.3609 - val_accuracy: 0.8539\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 185us/step - loss: 0.3006 - accuracy: 0.8963 - val_loss: 0.3595 - val_accuracy: 0.8539\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2980 - accuracy: 0.8953 - val_loss: 0.3581 - val_accuracy: 0.8493\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2957 - accuracy: 0.8953 - val_loss: 0.3570 - val_accuracy: 0.8493\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 176us/step - loss: 0.2936 - accuracy: 0.8933 - val_loss: 0.3559 - val_accuracy: 0.8493\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 180us/step - loss: 0.2916 - accuracy: 0.8933 - val_loss: 0.3549 - val_accuracy: 0.8493\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 199us/step - loss: 0.2899 - accuracy: 0.8933 - val_loss: 0.3541 - val_accuracy: 0.8493\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2881 - accuracy: 0.8933 - val_loss: 0.3533 - val_accuracy: 0.8493\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2865 - accuracy: 0.8943 - val_loss: 0.3525 - val_accuracy: 0.8493\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2850 - accuracy: 0.8943 - val_loss: 0.3518 - val_accuracy: 0.8493\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 200us/step - loss: 0.2836 - accuracy: 0.8933 - val_loss: 0.3513 - val_accuracy: 0.8493\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 360us/step - loss: 0.2825 - accuracy: 0.8933 - val_loss: 0.3506 - val_accuracy: 0.8493\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2812 - accuracy: 0.8943 - val_loss: 0.3501 - val_accuracy: 0.8493\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2803 - accuracy: 0.8953 - val_loss: 0.3496 - val_accuracy: 0.8493\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2792 - accuracy: 0.8953 - val_loss: 0.3490 - val_accuracy: 0.8493\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 273us/step - loss: 0.2780 - accuracy: 0.8953 - val_loss: 0.3484 - val_accuracy: 0.8493\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2770 - accuracy: 0.8963 - val_loss: 0.3476 - val_accuracy: 0.8493\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2760 - accuracy: 0.8973 - val_loss: 0.3467 - val_accuracy: 0.8493\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2746 - accuracy: 0.8963 - val_loss: 0.3459 - val_accuracy: 0.8539\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 315us/step - loss: 0.2735 - accuracy: 0.8973 - val_loss: 0.3448 - val_accuracy: 0.8584\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 169us/step - loss: 0.2724 - accuracy: 0.8953 - val_loss: 0.3440 - val_accuracy: 0.8584\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2714 - accuracy: 0.8963 - val_loss: 0.3429 - val_accuracy: 0.8584\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2703 - accuracy: 0.8963 - val_loss: 0.3419 - val_accuracy: 0.8584\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2694 - accuracy: 0.8982 - val_loss: 0.3407 - val_accuracy: 0.8630\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2686 - accuracy: 0.8963 - val_loss: 0.3398 - val_accuracy: 0.8676\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2678 - accuracy: 0.8973 - val_loss: 0.3389 - val_accuracy: 0.8676\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2669 - accuracy: 0.8973 - val_loss: 0.3381 - val_accuracy: 0.8676\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2663 - accuracy: 0.8992 - val_loss: 0.3372 - val_accuracy: 0.8676\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2654 - accuracy: 0.8982 - val_loss: 0.3365 - val_accuracy: 0.8676\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2648 - accuracy: 0.9002 - val_loss: 0.3358 - val_accuracy: 0.8676\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2642 - accuracy: 0.9002 - val_loss: 0.3349 - val_accuracy: 0.8676\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2636 - accuracy: 0.8982 - val_loss: 0.3343 - val_accuracy: 0.8676\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.2629 - accuracy: 0.8982 - val_loss: 0.3337 - val_accuracy: 0.8676\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2623 - accuracy: 0.8982 - val_loss: 0.3330 - val_accuracy: 0.8676\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2619 - accuracy: 0.9002 - val_loss: 0.3324 - val_accuracy: 0.8721\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 167us/step - loss: 0.2613 - accuracy: 0.9002 - val_loss: 0.3318 - val_accuracy: 0.8721\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.2608 - accuracy: 0.9002 - val_loss: 0.3312 - val_accuracy: 0.8721\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2604 - accuracy: 0.9022 - val_loss: 0.3306 - val_accuracy: 0.8721\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2598 - accuracy: 0.9022 - val_loss: 0.3301 - val_accuracy: 0.8721\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2594 - accuracy: 0.9022 - val_loss: 0.3296 - val_accuracy: 0.8721\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2588 - accuracy: 0.9022 - val_loss: 0.3291 - val_accuracy: 0.8721\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2585 - accuracy: 0.9031 - val_loss: 0.3286 - val_accuracy: 0.8721\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2580 - accuracy: 0.9031 - val_loss: 0.3281 - val_accuracy: 0.8767\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2576 - accuracy: 0.9041 - val_loss: 0.3278 - val_accuracy: 0.8767\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2573 - accuracy: 0.9041 - val_loss: 0.3275 - val_accuracy: 0.8767\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2570 - accuracy: 0.9041 - val_loss: 0.3270 - val_accuracy: 0.8767\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 83us/step - loss: 0.2566 - accuracy: 0.9041 - val_loss: 0.3266 - val_accuracy: 0.8767\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 90us/step - loss: 0.2563 - accuracy: 0.9041 - val_loss: 0.3261 - val_accuracy: 0.8767\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2559 - accuracy: 0.9051 - val_loss: 0.3257 - val_accuracy: 0.8767\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2557 - accuracy: 0.9061 - val_loss: 0.3253 - val_accuracy: 0.8767\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 95us/step - loss: 0.2554 - accuracy: 0.9051 - val_loss: 0.3249 - val_accuracy: 0.8767\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2549 - accuracy: 0.9061 - val_loss: 0.3246 - val_accuracy: 0.8767\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2547 - accuracy: 0.9051 - val_loss: 0.3243 - val_accuracy: 0.8767\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2546 - accuracy: 0.9061 - val_loss: 0.3240 - val_accuracy: 0.8767\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2542 - accuracy: 0.9070 - val_loss: 0.3237 - val_accuracy: 0.8767\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 337us/step - loss: 0.2540 - accuracy: 0.9061 - val_loss: 0.3235 - val_accuracy: 0.8767\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 251us/step - loss: 0.2537 - accuracy: 0.9080 - val_loss: 0.3233 - val_accuracy: 0.8767\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2536 - accuracy: 0.9070 - val_loss: 0.3230 - val_accuracy: 0.8767\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 101us/step - loss: 0.2533 - accuracy: 0.9080 - val_loss: 0.3225 - val_accuracy: 0.8767\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 743us/step - loss: 0.7008 - accuracy: 0.4579 - val_loss: 0.6965 - val_accuracy: 0.4566\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.6925 - accuracy: 0.4609 - val_loss: 0.6895 - val_accuracy: 0.4612\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 276us/step - loss: 0.6862 - accuracy: 0.4618 - val_loss: 0.6837 - val_accuracy: 0.4886\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 362us/step - loss: 0.6809 - accuracy: 0.4706 - val_loss: 0.6784 - val_accuracy: 0.4703\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.6756 - accuracy: 0.5088 - val_loss: 0.6729 - val_accuracy: 0.4886\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 458us/step - loss: 0.6700 - accuracy: 0.6233 - val_loss: 0.6671 - val_accuracy: 0.6256\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 95us/step - loss: 0.6637 - accuracy: 0.6526 - val_loss: 0.6606 - val_accuracy: 0.6438\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 97us/step - loss: 0.6564 - accuracy: 0.6595 - val_loss: 0.6532 - val_accuracy: 0.6621\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.6475 - accuracy: 0.6849 - val_loss: 0.6444 - val_accuracy: 0.6986\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 93us/step - loss: 0.6367 - accuracy: 0.7025 - val_loss: 0.6343 - val_accuracy: 0.7215\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 96us/step - loss: 0.6242 - accuracy: 0.7329 - val_loss: 0.6229 - val_accuracy: 0.7260\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - ETA: 0s - loss: 0.6144 - accuracy: 0.74 - 0s 95us/step - loss: 0.6104 - accuracy: 0.7564 - val_loss: 0.6101 - val_accuracy: 0.7489\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 101us/step - loss: 0.5952 - accuracy: 0.7789 - val_loss: 0.5956 - val_accuracy: 0.7808\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 95us/step - loss: 0.5787 - accuracy: 0.7975 - val_loss: 0.5804 - val_accuracy: 0.8128\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 97us/step - loss: 0.5617 - accuracy: 0.8092 - val_loss: 0.5645 - val_accuracy: 0.8219\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.5448 - accuracy: 0.8160 - val_loss: 0.5491 - val_accuracy: 0.8311\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 97us/step - loss: 0.5282 - accuracy: 0.8297 - val_loss: 0.5340 - val_accuracy: 0.8311\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.5121 - accuracy: 0.8376 - val_loss: 0.5196 - val_accuracy: 0.8311\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.4967 - accuracy: 0.8405 - val_loss: 0.5057 - val_accuracy: 0.8356\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.4821 - accuracy: 0.8464 - val_loss: 0.4928 - val_accuracy: 0.8311\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.4682 - accuracy: 0.8474 - val_loss: 0.4808 - val_accuracy: 0.8311\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 99us/step - loss: 0.4553 - accuracy: 0.8542 - val_loss: 0.4696 - val_accuracy: 0.8402\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.4431 - accuracy: 0.8591 - val_loss: 0.4593 - val_accuracy: 0.8402\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 99us/step - loss: 0.4318 - accuracy: 0.8581 - val_loss: 0.4497 - val_accuracy: 0.8402\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 99us/step - loss: 0.4210 - accuracy: 0.8630 - val_loss: 0.4409 - val_accuracy: 0.8402\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 99us/step - loss: 0.4108 - accuracy: 0.8640 - val_loss: 0.4325 - val_accuracy: 0.8493\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 100us/step - loss: 0.4012 - accuracy: 0.8640 - val_loss: 0.4242 - val_accuracy: 0.8493\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 100us/step - loss: 0.3922 - accuracy: 0.8650 - val_loss: 0.4165 - val_accuracy: 0.8539\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 101us/step - loss: 0.3837 - accuracy: 0.8689 - val_loss: 0.4091 - val_accuracy: 0.8539\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 100us/step - loss: 0.3752 - accuracy: 0.8718 - val_loss: 0.4021 - val_accuracy: 0.8539\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.3671 - accuracy: 0.8718 - val_loss: 0.3957 - val_accuracy: 0.8539\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 96us/step - loss: 0.3594 - accuracy: 0.8728 - val_loss: 0.3897 - val_accuracy: 0.8584\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 99us/step - loss: 0.3522 - accuracy: 0.8767 - val_loss: 0.3841 - val_accuracy: 0.8493\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.3457 - accuracy: 0.8796 - val_loss: 0.3791 - val_accuracy: 0.8493\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 99us/step - loss: 0.3396 - accuracy: 0.8816 - val_loss: 0.3744 - val_accuracy: 0.8493\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.3339 - accuracy: 0.8806 - val_loss: 0.3700 - val_accuracy: 0.8539\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 100us/step - loss: 0.3285 - accuracy: 0.8836 - val_loss: 0.3660 - val_accuracy: 0.8539\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.3235 - accuracy: 0.8865 - val_loss: 0.3625 - val_accuracy: 0.8539\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.3187 - accuracy: 0.8924 - val_loss: 0.3592 - val_accuracy: 0.8584\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.3144 - accuracy: 0.8914 - val_loss: 0.3560 - val_accuracy: 0.8584\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.3103 - accuracy: 0.8943 - val_loss: 0.3530 - val_accuracy: 0.8584\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 177us/step - loss: 0.3065 - accuracy: 0.8953 - val_loss: 0.3502 - val_accuracy: 0.8630\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.3030 - accuracy: 0.8943 - val_loss: 0.3475 - val_accuracy: 0.8630\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 385us/step - loss: 0.2996 - accuracy: 0.8924 - val_loss: 0.3451 - val_accuracy: 0.8630\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2965 - accuracy: 0.8914 - val_loss: 0.3428 - val_accuracy: 0.8630\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2937 - accuracy: 0.8924 - val_loss: 0.3409 - val_accuracy: 0.8630\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2910 - accuracy: 0.8943 - val_loss: 0.3390 - val_accuracy: 0.8584\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2886 - accuracy: 0.8943 - val_loss: 0.3373 - val_accuracy: 0.8630\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 167us/step - loss: 0.2863 - accuracy: 0.8953 - val_loss: 0.3357 - val_accuracy: 0.8630\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2841 - accuracy: 0.8953 - val_loss: 0.3340 - val_accuracy: 0.8630\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 96us/step - loss: 0.2821 - accuracy: 0.8933 - val_loss: 0.3326 - val_accuracy: 0.8676\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 231us/step - loss: 0.2803 - accuracy: 0.8924 - val_loss: 0.3313 - val_accuracy: 0.8676\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 99us/step - loss: 0.2786 - accuracy: 0.8933 - val_loss: 0.3298 - val_accuracy: 0.8676\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2770 - accuracy: 0.8933 - val_loss: 0.3285 - val_accuracy: 0.8676\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2754 - accuracy: 0.8943 - val_loss: 0.3272 - val_accuracy: 0.8676\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.2740 - accuracy: 0.8943 - val_loss: 0.3260 - val_accuracy: 0.8676\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2726 - accuracy: 0.8953 - val_loss: 0.3250 - val_accuracy: 0.8676\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 95us/step - loss: 0.2712 - accuracy: 0.8953 - val_loss: 0.3240 - val_accuracy: 0.8676\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 96us/step - loss: 0.2699 - accuracy: 0.8943 - val_loss: 0.3229 - val_accuracy: 0.8676\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 101us/step - loss: 0.2688 - accuracy: 0.8953 - val_loss: 0.3218 - val_accuracy: 0.8721\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.2676 - accuracy: 0.8943 - val_loss: 0.3207 - val_accuracy: 0.8721\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 96us/step - loss: 0.2666 - accuracy: 0.8943 - val_loss: 0.3197 - val_accuracy: 0.8721\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 99us/step - loss: 0.2656 - accuracy: 0.8943 - val_loss: 0.3188 - val_accuracy: 0.8721\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 99us/step - loss: 0.2646 - accuracy: 0.8943 - val_loss: 0.3180 - val_accuracy: 0.8721\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.2636 - accuracy: 0.8953 - val_loss: 0.3171 - val_accuracy: 0.8721\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 100us/step - loss: 0.2628 - accuracy: 0.8953 - val_loss: 0.3162 - val_accuracy: 0.8721\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 97us/step - loss: 0.2620 - accuracy: 0.8973 - val_loss: 0.3152 - val_accuracy: 0.8676\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 97us/step - loss: 0.2611 - accuracy: 0.8973 - val_loss: 0.3142 - val_accuracy: 0.8676\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.2605 - accuracy: 0.8963 - val_loss: 0.3133 - val_accuracy: 0.8676\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 99us/step - loss: 0.2598 - accuracy: 0.8973 - val_loss: 0.3123 - val_accuracy: 0.8676\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 97us/step - loss: 0.2590 - accuracy: 0.8982 - val_loss: 0.3112 - val_accuracy: 0.8676\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 97us/step - loss: 0.2582 - accuracy: 0.8973 - val_loss: 0.3102 - val_accuracy: 0.8676\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.2574 - accuracy: 0.8982 - val_loss: 0.3091 - val_accuracy: 0.8676\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 90us/step - loss: 0.2569 - accuracy: 0.8992 - val_loss: 0.3082 - val_accuracy: 0.8676\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2562 - accuracy: 0.8982 - val_loss: 0.3074 - val_accuracy: 0.8676\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 291us/step - loss: 0.2555 - accuracy: 0.8992 - val_loss: 0.3065 - val_accuracy: 0.8676\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 469us/step - loss: 0.2548 - accuracy: 0.9002 - val_loss: 0.3057 - val_accuracy: 0.8676\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 171us/step - loss: 0.2542 - accuracy: 0.8992 - val_loss: 0.3048 - val_accuracy: 0.8676\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 285us/step - loss: 0.2537 - accuracy: 0.9002 - val_loss: 0.3038 - val_accuracy: 0.8676\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 225us/step - loss: 0.2531 - accuracy: 0.8992 - val_loss: 0.3029 - val_accuracy: 0.8721\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2525 - accuracy: 0.8982 - val_loss: 0.3018 - val_accuracy: 0.8721\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 269us/step - loss: 0.2518 - accuracy: 0.9002 - val_loss: 0.3009 - val_accuracy: 0.8767\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 439us/step - loss: 0.2513 - accuracy: 0.9002 - val_loss: 0.3000 - val_accuracy: 0.8767\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 320us/step - loss: 0.2508 - accuracy: 0.9002 - val_loss: 0.2992 - val_accuracy: 0.8767\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.2502 - accuracy: 0.8992 - val_loss: 0.2983 - val_accuracy: 0.8767\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2496 - accuracy: 0.9012 - val_loss: 0.2976 - val_accuracy: 0.8767\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2490 - accuracy: 0.9002 - val_loss: 0.2968 - val_accuracy: 0.8767\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2486 - accuracy: 0.9022 - val_loss: 0.2960 - val_accuracy: 0.8721\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2481 - accuracy: 0.9012 - val_loss: 0.2955 - val_accuracy: 0.8767\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 265us/step - loss: 0.2476 - accuracy: 0.9022 - val_loss: 0.2947 - val_accuracy: 0.8721\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 211us/step - loss: 0.2472 - accuracy: 0.9022 - val_loss: 0.2940 - val_accuracy: 0.8721\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.2467 - accuracy: 0.9012 - val_loss: 0.2933 - val_accuracy: 0.8721\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2463 - accuracy: 0.9022 - val_loss: 0.2926 - val_accuracy: 0.8721\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 244us/step - loss: 0.2458 - accuracy: 0.9022 - val_loss: 0.2918 - val_accuracy: 0.8721\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 171us/step - loss: 0.2454 - accuracy: 0.9031 - val_loss: 0.2909 - val_accuracy: 0.8721\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2450 - accuracy: 0.9022 - val_loss: 0.2900 - val_accuracy: 0.8721\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 210us/step - loss: 0.2445 - accuracy: 0.9041 - val_loss: 0.2894 - val_accuracy: 0.8721\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 358us/step - loss: 0.2441 - accuracy: 0.9041 - val_loss: 0.2886 - val_accuracy: 0.8721\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2436 - accuracy: 0.9041 - val_loss: 0.2879 - val_accuracy: 0.8721\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2432 - accuracy: 0.9041 - val_loss: 0.2871 - val_accuracy: 0.8721\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.7506 - accuracy: 0.2407 - val_loss: 0.7116 - val_accuracy: 0.3059\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 200us/step - loss: 0.6887 - accuracy: 0.4442 - val_loss: 0.6765 - val_accuracy: 0.4566\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 193us/step - loss: 0.6527 - accuracy: 0.5068 - val_loss: 0.6545 - val_accuracy: 0.4795\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.6272 - accuracy: 0.6918 - val_loss: 0.6378 - val_accuracy: 0.7169\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.6066 - accuracy: 0.7691 - val_loss: 0.6237 - val_accuracy: 0.7352\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.5886 - accuracy: 0.7808 - val_loss: 0.6106 - val_accuracy: 0.7580\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.5719 - accuracy: 0.7935 - val_loss: 0.5983 - val_accuracy: 0.7717\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.5562 - accuracy: 0.8023 - val_loss: 0.5865 - val_accuracy: 0.7717\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.5416 - accuracy: 0.8160 - val_loss: 0.5751 - val_accuracy: 0.7854\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 1s 500us/step - loss: 0.5276 - accuracy: 0.8200 - val_loss: 0.5637 - val_accuracy: 0.7763\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 281us/step - loss: 0.5143 - accuracy: 0.8239 - val_loss: 0.5526 - val_accuracy: 0.7808\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.5018 - accuracy: 0.8297 - val_loss: 0.5420 - val_accuracy: 0.7900\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 83us/step - loss: 0.4898 - accuracy: 0.8337 - val_loss: 0.5317 - val_accuracy: 0.7854\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 82us/step - loss: 0.4786 - accuracy: 0.8346 - val_loss: 0.5218 - val_accuracy: 0.7808\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 79us/step - loss: 0.4678 - accuracy: 0.8474 - val_loss: 0.5123 - val_accuracy: 0.7763\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 93us/step - loss: 0.4576 - accuracy: 0.8513 - val_loss: 0.5034 - val_accuracy: 0.7900\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.4480 - accuracy: 0.8542 - val_loss: 0.4949 - val_accuracy: 0.7945\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.4390 - accuracy: 0.8571 - val_loss: 0.4870 - val_accuracy: 0.7991\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.4305 - accuracy: 0.8591 - val_loss: 0.4795 - val_accuracy: 0.7991\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.4223 - accuracy: 0.8611 - val_loss: 0.4722 - val_accuracy: 0.7991\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.4146 - accuracy: 0.8630 - val_loss: 0.4652 - val_accuracy: 0.8037\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 90us/step - loss: 0.4073 - accuracy: 0.8679 - val_loss: 0.4585 - val_accuracy: 0.8082\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 99us/step - loss: 0.4003 - accuracy: 0.8699 - val_loss: 0.4522 - val_accuracy: 0.8174\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.3938 - accuracy: 0.8728 - val_loss: 0.4461 - val_accuracy: 0.8174\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.3874 - accuracy: 0.8767 - val_loss: 0.4403 - val_accuracy: 0.8128\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 96us/step - loss: 0.3816 - accuracy: 0.8787 - val_loss: 0.4350 - val_accuracy: 0.8174\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 308us/step - loss: 0.3761 - accuracy: 0.8777 - val_loss: 0.4299 - val_accuracy: 0.8174\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 365us/step - loss: 0.3706 - accuracy: 0.8777 - val_loss: 0.4250 - val_accuracy: 0.8174\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 209us/step - loss: 0.3655 - accuracy: 0.8767 - val_loss: 0.4203 - val_accuracy: 0.8219\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 170us/step - loss: 0.3605 - accuracy: 0.8787 - val_loss: 0.4160 - val_accuracy: 0.8265\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.3560 - accuracy: 0.8787 - val_loss: 0.4120 - val_accuracy: 0.8219\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 306us/step - loss: 0.3517 - accuracy: 0.8787 - val_loss: 0.4082 - val_accuracy: 0.8219\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.3475 - accuracy: 0.8796 - val_loss: 0.4046 - val_accuracy: 0.8311\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 177us/step - loss: 0.3434 - accuracy: 0.8806 - val_loss: 0.4010 - val_accuracy: 0.8311\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.3394 - accuracy: 0.8806 - val_loss: 0.3977 - val_accuracy: 0.8311\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.3356 - accuracy: 0.8816 - val_loss: 0.3945 - val_accuracy: 0.8356\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.3320 - accuracy: 0.8816 - val_loss: 0.3915 - val_accuracy: 0.8356\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 175us/step - loss: 0.3287 - accuracy: 0.8816 - val_loss: 0.3884 - val_accuracy: 0.8447\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.3255 - accuracy: 0.8826 - val_loss: 0.3856 - val_accuracy: 0.8447\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.3225 - accuracy: 0.8826 - val_loss: 0.3827 - val_accuracy: 0.8402\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.3195 - accuracy: 0.8855 - val_loss: 0.3801 - val_accuracy: 0.8493\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.3168 - accuracy: 0.8845 - val_loss: 0.3777 - val_accuracy: 0.8493\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.3142 - accuracy: 0.8836 - val_loss: 0.3754 - val_accuracy: 0.8493\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.3117 - accuracy: 0.8836 - val_loss: 0.3732 - val_accuracy: 0.8539\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.3094 - accuracy: 0.8875 - val_loss: 0.3710 - val_accuracy: 0.8539\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.3072 - accuracy: 0.8865 - val_loss: 0.3691 - val_accuracy: 0.8539\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.3051 - accuracy: 0.8855 - val_loss: 0.3671 - val_accuracy: 0.8539\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.3031 - accuracy: 0.8875 - val_loss: 0.3653 - val_accuracy: 0.8584\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 170us/step - loss: 0.3012 - accuracy: 0.8865 - val_loss: 0.3636 - val_accuracy: 0.8630\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2995 - accuracy: 0.8875 - val_loss: 0.3620 - val_accuracy: 0.8630\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 101us/step - loss: 0.2978 - accuracy: 0.8865 - val_loss: 0.3605 - val_accuracy: 0.8630\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 101us/step - loss: 0.2961 - accuracy: 0.8865 - val_loss: 0.3588 - val_accuracy: 0.8539\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2945 - accuracy: 0.8845 - val_loss: 0.3573 - val_accuracy: 0.8539\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2929 - accuracy: 0.8855 - val_loss: 0.3559 - val_accuracy: 0.8539\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2914 - accuracy: 0.8865 - val_loss: 0.3547 - val_accuracy: 0.8539\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2901 - accuracy: 0.8855 - val_loss: 0.3533 - val_accuracy: 0.8539\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2888 - accuracy: 0.8865 - val_loss: 0.3522 - val_accuracy: 0.8539\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2875 - accuracy: 0.8875 - val_loss: 0.3510 - val_accuracy: 0.8539\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2861 - accuracy: 0.8875 - val_loss: 0.3499 - val_accuracy: 0.8584\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2850 - accuracy: 0.8875 - val_loss: 0.3488 - val_accuracy: 0.8584\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 99us/step - loss: 0.2836 - accuracy: 0.8894 - val_loss: 0.3475 - val_accuracy: 0.8584\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2823 - accuracy: 0.8894 - val_loss: 0.3464 - val_accuracy: 0.8584\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2811 - accuracy: 0.8875 - val_loss: 0.3454 - val_accuracy: 0.8584\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2799 - accuracy: 0.8894 - val_loss: 0.3445 - val_accuracy: 0.8584\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2788 - accuracy: 0.8894 - val_loss: 0.3435 - val_accuracy: 0.8584\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2778 - accuracy: 0.8904 - val_loss: 0.3420 - val_accuracy: 0.8584\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2766 - accuracy: 0.8914 - val_loss: 0.3407 - val_accuracy: 0.8584\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2755 - accuracy: 0.8924 - val_loss: 0.3392 - val_accuracy: 0.8584\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2744 - accuracy: 0.8924 - val_loss: 0.3381 - val_accuracy: 0.8584\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2733 - accuracy: 0.8924 - val_loss: 0.3369 - val_accuracy: 0.8584\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2723 - accuracy: 0.8924 - val_loss: 0.3358 - val_accuracy: 0.8584\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2712 - accuracy: 0.8943 - val_loss: 0.3346 - val_accuracy: 0.8584\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.2702 - accuracy: 0.8953 - val_loss: 0.3333 - val_accuracy: 0.8584\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2693 - accuracy: 0.8943 - val_loss: 0.3322 - val_accuracy: 0.8584\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2682 - accuracy: 0.8933 - val_loss: 0.3310 - val_accuracy: 0.8584\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2673 - accuracy: 0.8943 - val_loss: 0.3299 - val_accuracy: 0.8584\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2663 - accuracy: 0.8943 - val_loss: 0.3286 - val_accuracy: 0.8584\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2653 - accuracy: 0.8953 - val_loss: 0.3273 - val_accuracy: 0.8584\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2644 - accuracy: 0.8963 - val_loss: 0.3259 - val_accuracy: 0.8584\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2636 - accuracy: 0.8953 - val_loss: 0.3248 - val_accuracy: 0.8630\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2628 - accuracy: 0.8953 - val_loss: 0.3236 - val_accuracy: 0.8630\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 101us/step - loss: 0.2620 - accuracy: 0.8963 - val_loss: 0.3225 - val_accuracy: 0.8676\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2613 - accuracy: 0.8963 - val_loss: 0.3212 - val_accuracy: 0.8676\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.2605 - accuracy: 0.8973 - val_loss: 0.3200 - val_accuracy: 0.8630\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2597 - accuracy: 0.8982 - val_loss: 0.3187 - val_accuracy: 0.8721\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2590 - accuracy: 0.8992 - val_loss: 0.3174 - val_accuracy: 0.8721\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 186us/step - loss: 0.2583 - accuracy: 0.8982 - val_loss: 0.3163 - val_accuracy: 0.8721\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2577 - accuracy: 0.8992 - val_loss: 0.3155 - val_accuracy: 0.8721\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2571 - accuracy: 0.9012 - val_loss: 0.3145 - val_accuracy: 0.8721\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2565 - accuracy: 0.9012 - val_loss: 0.3137 - val_accuracy: 0.8721\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2560 - accuracy: 0.9012 - val_loss: 0.3129 - val_accuracy: 0.8721\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2555 - accuracy: 0.9012 - val_loss: 0.3120 - val_accuracy: 0.8721\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2549 - accuracy: 0.9012 - val_loss: 0.3113 - val_accuracy: 0.8721\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2546 - accuracy: 0.9012 - val_loss: 0.3106 - val_accuracy: 0.8721\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2540 - accuracy: 0.9012 - val_loss: 0.3100 - val_accuracy: 0.8721\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2536 - accuracy: 0.9012 - val_loss: 0.3093 - val_accuracy: 0.8721\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2531 - accuracy: 0.9012 - val_loss: 0.3085 - val_accuracy: 0.8721\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2526 - accuracy: 0.9012 - val_loss: 0.3077 - val_accuracy: 0.8721\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 259us/step - loss: 0.2522 - accuracy: 0.9012 - val_loss: 0.3069 - val_accuracy: 0.8721\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 327us/step - loss: 0.2518 - accuracy: 0.9002 - val_loss: 0.3061 - val_accuracy: 0.8721\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.6948 - accuracy: 0.5607 - val_loss: 0.7060 - val_accuracy: 0.5251\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.6762 - accuracy: 0.5802 - val_loss: 0.6884 - val_accuracy: 0.5571\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 180us/step - loss: 0.6613 - accuracy: 0.5969 - val_loss: 0.6736 - val_accuracy: 0.5525\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.6480 - accuracy: 0.6282 - val_loss: 0.6599 - val_accuracy: 0.5982\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 101us/step - loss: 0.6348 - accuracy: 0.6820 - val_loss: 0.6464 - val_accuracy: 0.7306\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 101us/step - loss: 0.6214 - accuracy: 0.7877 - val_loss: 0.6327 - val_accuracy: 0.7854\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.6070 - accuracy: 0.8151 - val_loss: 0.6184 - val_accuracy: 0.7900\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.5919 - accuracy: 0.8180 - val_loss: 0.6035 - val_accuracy: 0.7900\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.5760 - accuracy: 0.8249 - val_loss: 0.5882 - val_accuracy: 0.7945\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 101us/step - loss: 0.5596 - accuracy: 0.8307 - val_loss: 0.5730 - val_accuracy: 0.7991\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.5431 - accuracy: 0.8346 - val_loss: 0.5575 - val_accuracy: 0.8082\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.5264 - accuracy: 0.8395 - val_loss: 0.5425 - val_accuracy: 0.8082\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.5099 - accuracy: 0.8415 - val_loss: 0.5281 - val_accuracy: 0.8219\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 100us/step - loss: 0.4937 - accuracy: 0.8434 - val_loss: 0.5143 - val_accuracy: 0.8311\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.4778 - accuracy: 0.8474 - val_loss: 0.5010 - val_accuracy: 0.8356\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.4626 - accuracy: 0.8493 - val_loss: 0.4886 - val_accuracy: 0.8356\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 96us/step - loss: 0.4481 - accuracy: 0.8523 - val_loss: 0.4766 - val_accuracy: 0.8402\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.4344 - accuracy: 0.8562 - val_loss: 0.4654 - val_accuracy: 0.8356\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 101us/step - loss: 0.4213 - accuracy: 0.8571 - val_loss: 0.4547 - val_accuracy: 0.8402\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.4089 - accuracy: 0.8601 - val_loss: 0.4445 - val_accuracy: 0.8402\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.3973 - accuracy: 0.8620 - val_loss: 0.4349 - val_accuracy: 0.8402\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.3864 - accuracy: 0.8650 - val_loss: 0.4259 - val_accuracy: 0.8447\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.3762 - accuracy: 0.8689 - val_loss: 0.4175 - val_accuracy: 0.8447\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.3669 - accuracy: 0.8748 - val_loss: 0.4098 - val_accuracy: 0.8447\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.3581 - accuracy: 0.8757 - val_loss: 0.4029 - val_accuracy: 0.8447\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.3501 - accuracy: 0.8757 - val_loss: 0.3964 - val_accuracy: 0.8493\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 267us/step - loss: 0.3427 - accuracy: 0.8767 - val_loss: 0.3904 - val_accuracy: 0.8447\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 315us/step - loss: 0.3359 - accuracy: 0.8787 - val_loss: 0.3848 - val_accuracy: 0.8447\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.3295 - accuracy: 0.8816 - val_loss: 0.3797 - val_accuracy: 0.8402\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 101us/step - loss: 0.3236 - accuracy: 0.8836 - val_loss: 0.3750 - val_accuracy: 0.8402\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.3180 - accuracy: 0.8845 - val_loss: 0.3708 - val_accuracy: 0.8402\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 97us/step - loss: 0.3129 - accuracy: 0.8845 - val_loss: 0.3668 - val_accuracy: 0.8402\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.3082 - accuracy: 0.8865 - val_loss: 0.3633 - val_accuracy: 0.8447\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.3036 - accuracy: 0.8885 - val_loss: 0.3599 - val_accuracy: 0.8447\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 96us/step - loss: 0.2995 - accuracy: 0.8894 - val_loss: 0.3567 - val_accuracy: 0.8493\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 94us/step - loss: 0.2955 - accuracy: 0.8904 - val_loss: 0.3538 - val_accuracy: 0.8493\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2919 - accuracy: 0.8904 - val_loss: 0.3512 - val_accuracy: 0.8493\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.2887 - accuracy: 0.8914 - val_loss: 0.3488 - val_accuracy: 0.8493\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 257us/step - loss: 0.2856 - accuracy: 0.8894 - val_loss: 0.3465 - val_accuracy: 0.8493\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2827 - accuracy: 0.8914 - val_loss: 0.3441 - val_accuracy: 0.8493\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2799 - accuracy: 0.8924 - val_loss: 0.3416 - val_accuracy: 0.8493\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 100us/step - loss: 0.2771 - accuracy: 0.8924 - val_loss: 0.3393 - val_accuracy: 0.8539\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 222us/step - loss: 0.2743 - accuracy: 0.8914 - val_loss: 0.3370 - val_accuracy: 0.8584\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.2719 - accuracy: 0.8914 - val_loss: 0.3348 - val_accuracy: 0.8630\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2695 - accuracy: 0.8924 - val_loss: 0.3328 - val_accuracy: 0.8676\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 96us/step - loss: 0.2673 - accuracy: 0.8924 - val_loss: 0.3304 - val_accuracy: 0.8676\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 95us/step - loss: 0.2651 - accuracy: 0.8924 - val_loss: 0.3282 - val_accuracy: 0.8676\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.2631 - accuracy: 0.8933 - val_loss: 0.3258 - val_accuracy: 0.8676\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 97us/step - loss: 0.2612 - accuracy: 0.8904 - val_loss: 0.3240 - val_accuracy: 0.8721\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 97us/step - loss: 0.2594 - accuracy: 0.8924 - val_loss: 0.3221 - val_accuracy: 0.8721\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 100us/step - loss: 0.2577 - accuracy: 0.8933 - val_loss: 0.3202 - val_accuracy: 0.8721\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.2560 - accuracy: 0.8924 - val_loss: 0.3182 - val_accuracy: 0.8721\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 97us/step - loss: 0.2546 - accuracy: 0.8943 - val_loss: 0.3164 - val_accuracy: 0.8721\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 101us/step - loss: 0.2532 - accuracy: 0.8914 - val_loss: 0.3148 - val_accuracy: 0.8721\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.2519 - accuracy: 0.8943 - val_loss: 0.3133 - val_accuracy: 0.8721\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2507 - accuracy: 0.8963 - val_loss: 0.3118 - val_accuracy: 0.8721\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 444us/step - loss: 0.2496 - accuracy: 0.8982 - val_loss: 0.3103 - val_accuracy: 0.8721\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 255us/step - loss: 0.2486 - accuracy: 0.8982 - val_loss: 0.3091 - val_accuracy: 0.8721\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 465us/step - loss: 0.2476 - accuracy: 0.8982 - val_loss: 0.3079 - val_accuracy: 0.8721\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 348us/step - loss: 0.2468 - accuracy: 0.8982 - val_loss: 0.3067 - val_accuracy: 0.8721\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 225us/step - loss: 0.2459 - accuracy: 0.8973 - val_loss: 0.3055 - val_accuracy: 0.8721\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2451 - accuracy: 0.8992 - val_loss: 0.3044 - val_accuracy: 0.8721\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 441us/step - loss: 0.2443 - accuracy: 0.8982 - val_loss: 0.3032 - val_accuracy: 0.8676\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.2434 - accuracy: 0.9012 - val_loss: 0.3020 - val_accuracy: 0.8676\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2427 - accuracy: 0.9012 - val_loss: 0.3009 - val_accuracy: 0.8676\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2419 - accuracy: 0.9031 - val_loss: 0.3001 - val_accuracy: 0.8630\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 100us/step - loss: 0.2412 - accuracy: 0.9012 - val_loss: 0.2992 - val_accuracy: 0.8630\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2405 - accuracy: 0.9031 - val_loss: 0.2982 - val_accuracy: 0.8630\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.2399 - accuracy: 0.9031 - val_loss: 0.2973 - val_accuracy: 0.8630\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.2393 - accuracy: 0.9041 - val_loss: 0.2964 - val_accuracy: 0.8630\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2388 - accuracy: 0.9022 - val_loss: 0.2956 - val_accuracy: 0.8630\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2383 - accuracy: 0.9041 - val_loss: 0.2949 - val_accuracy: 0.8630\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2377 - accuracy: 0.9031 - val_loss: 0.2940 - val_accuracy: 0.8630\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 96us/step - loss: 0.2372 - accuracy: 0.9031 - val_loss: 0.2934 - val_accuracy: 0.8630\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 233us/step - loss: 0.2367 - accuracy: 0.9041 - val_loss: 0.2929 - val_accuracy: 0.8630\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2363 - accuracy: 0.9051 - val_loss: 0.2923 - val_accuracy: 0.8630\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2359 - accuracy: 0.9031 - val_loss: 0.2915 - val_accuracy: 0.8630\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2355 - accuracy: 0.9051 - val_loss: 0.2912 - val_accuracy: 0.8630\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2350 - accuracy: 0.9022 - val_loss: 0.2907 - val_accuracy: 0.8630\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 92us/step - loss: 0.2347 - accuracy: 0.9041 - val_loss: 0.2901 - val_accuracy: 0.8630\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 93us/step - loss: 0.2344 - accuracy: 0.9031 - val_loss: 0.2895 - val_accuracy: 0.8630\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.2340 - accuracy: 0.9031 - val_loss: 0.2889 - val_accuracy: 0.8630\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 97us/step - loss: 0.2336 - accuracy: 0.9031 - val_loss: 0.2883 - val_accuracy: 0.8630\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 97us/step - loss: 0.2332 - accuracy: 0.9031 - val_loss: 0.2878 - val_accuracy: 0.8630\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 97us/step - loss: 0.2330 - accuracy: 0.9041 - val_loss: 0.2872 - val_accuracy: 0.8630\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 97us/step - loss: 0.2326 - accuracy: 0.9041 - val_loss: 0.2865 - val_accuracy: 0.8630\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 97us/step - loss: 0.2322 - accuracy: 0.9041 - val_loss: 0.2861 - val_accuracy: 0.8630\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 88us/step - loss: 0.2320 - accuracy: 0.9041 - val_loss: 0.2854 - val_accuracy: 0.8630\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 97us/step - loss: 0.2317 - accuracy: 0.9041 - val_loss: 0.2848 - val_accuracy: 0.8630\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2314 - accuracy: 0.9051 - val_loss: 0.2844 - val_accuracy: 0.8630\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 93us/step - loss: 0.2311 - accuracy: 0.9031 - val_loss: 0.2838 - val_accuracy: 0.8676\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2308 - accuracy: 0.9041 - val_loss: 0.2833 - val_accuracy: 0.8676\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 100us/step - loss: 0.2305 - accuracy: 0.9031 - val_loss: 0.2828 - val_accuracy: 0.8676\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 212us/step - loss: 0.2302 - accuracy: 0.9041 - val_loss: 0.2823 - val_accuracy: 0.8676\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 230us/step - loss: 0.2300 - accuracy: 0.9041 - val_loss: 0.2820 - val_accuracy: 0.8676\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2297 - accuracy: 0.9051 - val_loss: 0.2814 - val_accuracy: 0.8676\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2295 - accuracy: 0.9051 - val_loss: 0.2810 - val_accuracy: 0.8676\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2292 - accuracy: 0.9041 - val_loss: 0.2807 - val_accuracy: 0.8676\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 99us/step - loss: 0.2289 - accuracy: 0.9051 - val_loss: 0.2802 - val_accuracy: 0.8676\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 100us/step - loss: 0.2288 - accuracy: 0.9031 - val_loss: 0.2799 - val_accuracy: 0.8630\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 854us/step - loss: 0.6512 - accuracy: 0.6438 - val_loss: 0.6630 - val_accuracy: 0.6210\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 94us/step - loss: 0.6344 - accuracy: 0.6967 - val_loss: 0.6490 - val_accuracy: 0.6621\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.6184 - accuracy: 0.7348 - val_loss: 0.6356 - val_accuracy: 0.7169\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.6024 - accuracy: 0.7613 - val_loss: 0.6211 - val_accuracy: 0.7443\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.5855 - accuracy: 0.7710 - val_loss: 0.6062 - val_accuracy: 0.7580\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 251us/step - loss: 0.5680 - accuracy: 0.7828 - val_loss: 0.5906 - val_accuracy: 0.7717\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.5503 - accuracy: 0.7965 - val_loss: 0.5746 - val_accuracy: 0.7900\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.5320 - accuracy: 0.8112 - val_loss: 0.5586 - val_accuracy: 0.8037\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.5135 - accuracy: 0.8288 - val_loss: 0.5428 - val_accuracy: 0.7991\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.4945 - accuracy: 0.8376 - val_loss: 0.5269 - val_accuracy: 0.8128\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.4758 - accuracy: 0.8425 - val_loss: 0.5112 - val_accuracy: 0.8174\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.4574 - accuracy: 0.8454 - val_loss: 0.4961 - val_accuracy: 0.8219\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.4397 - accuracy: 0.8503 - val_loss: 0.4819 - val_accuracy: 0.8265\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.4231 - accuracy: 0.8571 - val_loss: 0.4686 - val_accuracy: 0.8265\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 101us/step - loss: 0.4076 - accuracy: 0.8601 - val_loss: 0.4563 - val_accuracy: 0.8311\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.3933 - accuracy: 0.8630 - val_loss: 0.4450 - val_accuracy: 0.8356\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 191us/step - loss: 0.3801 - accuracy: 0.8669 - val_loss: 0.4348 - val_accuracy: 0.8356\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.3681 - accuracy: 0.8679 - val_loss: 0.4257 - val_accuracy: 0.8402\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.3573 - accuracy: 0.8718 - val_loss: 0.4169 - val_accuracy: 0.8402\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.3475 - accuracy: 0.8748 - val_loss: 0.4092 - val_accuracy: 0.8402\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.3387 - accuracy: 0.8757 - val_loss: 0.4024 - val_accuracy: 0.8493\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.3307 - accuracy: 0.8787 - val_loss: 0.3960 - val_accuracy: 0.8493\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.3235 - accuracy: 0.8806 - val_loss: 0.3903 - val_accuracy: 0.8493\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.3169 - accuracy: 0.8836 - val_loss: 0.3851 - val_accuracy: 0.8584\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.3109 - accuracy: 0.8836 - val_loss: 0.3801 - val_accuracy: 0.8584\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.3053 - accuracy: 0.8865 - val_loss: 0.3756 - val_accuracy: 0.8676\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.3003 - accuracy: 0.8885 - val_loss: 0.3716 - val_accuracy: 0.8676\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2959 - accuracy: 0.8914 - val_loss: 0.3679 - val_accuracy: 0.8676\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2917 - accuracy: 0.8924 - val_loss: 0.3645 - val_accuracy: 0.8676\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2876 - accuracy: 0.8933 - val_loss: 0.3615 - val_accuracy: 0.8721\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2839 - accuracy: 0.8953 - val_loss: 0.3587 - val_accuracy: 0.8721\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2806 - accuracy: 0.8973 - val_loss: 0.3562 - val_accuracy: 0.8767\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2776 - accuracy: 0.9002 - val_loss: 0.3538 - val_accuracy: 0.8767\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2747 - accuracy: 0.9012 - val_loss: 0.3515 - val_accuracy: 0.8721\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2718 - accuracy: 0.8992 - val_loss: 0.3491 - val_accuracy: 0.8676\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2694 - accuracy: 0.9012 - val_loss: 0.3470 - val_accuracy: 0.8676\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2669 - accuracy: 0.8992 - val_loss: 0.3449 - val_accuracy: 0.8676\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.2646 - accuracy: 0.9002 - val_loss: 0.3429 - val_accuracy: 0.8676\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2625 - accuracy: 0.9012 - val_loss: 0.3411 - val_accuracy: 0.8676\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2605 - accuracy: 0.9012 - val_loss: 0.3394 - val_accuracy: 0.8676\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 90us/step - loss: 0.2586 - accuracy: 0.9031 - val_loss: 0.3379 - val_accuracy: 0.8676\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2568 - accuracy: 0.9031 - val_loss: 0.3364 - val_accuracy: 0.8676\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 297us/step - loss: 0.2551 - accuracy: 0.9061 - val_loss: 0.3351 - val_accuracy: 0.8676\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2534 - accuracy: 0.9051 - val_loss: 0.3338 - val_accuracy: 0.8721\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.2519 - accuracy: 0.9051 - val_loss: 0.3327 - val_accuracy: 0.8721\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 101us/step - loss: 0.2505 - accuracy: 0.9061 - val_loss: 0.3314 - val_accuracy: 0.8721\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.2491 - accuracy: 0.9061 - val_loss: 0.3303 - val_accuracy: 0.8721\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 99us/step - loss: 0.2478 - accuracy: 0.9041 - val_loss: 0.3293 - val_accuracy: 0.8721\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 100us/step - loss: 0.2466 - accuracy: 0.9051 - val_loss: 0.3283 - val_accuracy: 0.8721\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.2454 - accuracy: 0.9031 - val_loss: 0.3271 - val_accuracy: 0.8721\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.2446 - accuracy: 0.9070 - val_loss: 0.3260 - val_accuracy: 0.8721\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 311us/step - loss: 0.2435 - accuracy: 0.9051 - val_loss: 0.3249 - val_accuracy: 0.8721\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 296us/step - loss: 0.2425 - accuracy: 0.9061 - val_loss: 0.3237 - val_accuracy: 0.8721\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 307us/step - loss: 0.2416 - accuracy: 0.9051 - val_loss: 0.3225 - val_accuracy: 0.8767\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 194us/step - loss: 0.2408 - accuracy: 0.9051 - val_loss: 0.3214 - val_accuracy: 0.8767\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 269us/step - loss: 0.2400 - accuracy: 0.9051 - val_loss: 0.3202 - val_accuracy: 0.8767\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 241us/step - loss: 0.2392 - accuracy: 0.9051 - val_loss: 0.3191 - val_accuracy: 0.8767\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 227us/step - loss: 0.2384 - accuracy: 0.9051 - val_loss: 0.3181 - val_accuracy: 0.8767\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2376 - accuracy: 0.9061 - val_loss: 0.3170 - val_accuracy: 0.8767\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 181us/step - loss: 0.2370 - accuracy: 0.9051 - val_loss: 0.3160 - val_accuracy: 0.8767\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2361 - accuracy: 0.9061 - val_loss: 0.3150 - val_accuracy: 0.8767\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2354 - accuracy: 0.9061 - val_loss: 0.3139 - val_accuracy: 0.8767\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 309us/step - loss: 0.2348 - accuracy: 0.9061 - val_loss: 0.3129 - val_accuracy: 0.8767\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 1s 490us/step - loss: 0.2341 - accuracy: 0.9061 - val_loss: 0.3122 - val_accuracy: 0.8767\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 168us/step - loss: 0.2335 - accuracy: 0.9070 - val_loss: 0.3112 - val_accuracy: 0.8767\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2328 - accuracy: 0.9061 - val_loss: 0.3102 - val_accuracy: 0.8767\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2321 - accuracy: 0.9070 - val_loss: 0.3092 - val_accuracy: 0.8813\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2316 - accuracy: 0.9070 - val_loss: 0.3082 - val_accuracy: 0.8813\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2309 - accuracy: 0.9080 - val_loss: 0.3073 - val_accuracy: 0.8858\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2303 - accuracy: 0.9090 - val_loss: 0.3064 - val_accuracy: 0.8858\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2296 - accuracy: 0.9080 - val_loss: 0.3055 - val_accuracy: 0.8858\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2290 - accuracy: 0.9090 - val_loss: 0.3047 - val_accuracy: 0.8858\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2286 - accuracy: 0.9080 - val_loss: 0.3041 - val_accuracy: 0.8858\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2280 - accuracy: 0.9080 - val_loss: 0.3034 - val_accuracy: 0.8858\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2276 - accuracy: 0.9080 - val_loss: 0.3028 - val_accuracy: 0.8858\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2272 - accuracy: 0.9090 - val_loss: 0.3022 - val_accuracy: 0.8858\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2266 - accuracy: 0.9080 - val_loss: 0.3016 - val_accuracy: 0.8858\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2262 - accuracy: 0.9070 - val_loss: 0.3011 - val_accuracy: 0.8858\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2257 - accuracy: 0.9080 - val_loss: 0.3005 - val_accuracy: 0.8858\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2253 - accuracy: 0.9080 - val_loss: 0.3001 - val_accuracy: 0.8858\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2249 - accuracy: 0.9080 - val_loss: 0.2995 - val_accuracy: 0.8858\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2245 - accuracy: 0.9080 - val_loss: 0.2990 - val_accuracy: 0.8858\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2241 - accuracy: 0.9090 - val_loss: 0.2985 - val_accuracy: 0.8858\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2238 - accuracy: 0.9090 - val_loss: 0.2980 - val_accuracy: 0.8858\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2235 - accuracy: 0.9090 - val_loss: 0.2976 - val_accuracy: 0.8858\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2231 - accuracy: 0.9090 - val_loss: 0.2972 - val_accuracy: 0.8858\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2228 - accuracy: 0.9070 - val_loss: 0.2967 - val_accuracy: 0.8904\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.2225 - accuracy: 0.9090 - val_loss: 0.2963 - val_accuracy: 0.8904\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2222 - accuracy: 0.9090 - val_loss: 0.2959 - val_accuracy: 0.8904\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 212us/step - loss: 0.2219 - accuracy: 0.9090 - val_loss: 0.2955 - val_accuracy: 0.8904\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 181us/step - loss: 0.2217 - accuracy: 0.9090 - val_loss: 0.2952 - val_accuracy: 0.8904\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2214 - accuracy: 0.9090 - val_loss: 0.2949 - val_accuracy: 0.8904\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2211 - accuracy: 0.9100 - val_loss: 0.2947 - val_accuracy: 0.8858\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2208 - accuracy: 0.9090 - val_loss: 0.2944 - val_accuracy: 0.8858\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2206 - accuracy: 0.9110 - val_loss: 0.2941 - val_accuracy: 0.8858\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2204 - accuracy: 0.9110 - val_loss: 0.2937 - val_accuracy: 0.8813\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2201 - accuracy: 0.9110 - val_loss: 0.2934 - val_accuracy: 0.8813\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2199 - accuracy: 0.9110 - val_loss: 0.2932 - val_accuracy: 0.8813\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2197 - accuracy: 0.9119 - val_loss: 0.2929 - val_accuracy: 0.8813\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2196 - accuracy: 0.9129 - val_loss: 0.2926 - val_accuracy: 0.8813\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 902us/step - loss: 0.6654 - accuracy: 0.5362 - val_loss: 0.6638 - val_accuracy: 0.5434\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.6345 - accuracy: 0.5910 - val_loss: 0.6382 - val_accuracy: 0.6119\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.6072 - accuracy: 0.6595 - val_loss: 0.6153 - val_accuracy: 0.6438\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.5827 - accuracy: 0.7065 - val_loss: 0.5946 - val_accuracy: 0.6758\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.5600 - accuracy: 0.7446 - val_loss: 0.5751 - val_accuracy: 0.7306\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.5384 - accuracy: 0.7691 - val_loss: 0.5565 - val_accuracy: 0.7717\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.5175 - accuracy: 0.7828 - val_loss: 0.5386 - val_accuracy: 0.8082\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 170us/step - loss: 0.4979 - accuracy: 0.8043 - val_loss: 0.5218 - val_accuracy: 0.8265\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.4791 - accuracy: 0.8190 - val_loss: 0.5057 - val_accuracy: 0.8402\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.4607 - accuracy: 0.8268 - val_loss: 0.4904 - val_accuracy: 0.8356\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 214us/step - loss: 0.4432 - accuracy: 0.8444 - val_loss: 0.4761 - val_accuracy: 0.8356\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 448us/step - loss: 0.4268 - accuracy: 0.8513 - val_loss: 0.4628 - val_accuracy: 0.8311\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 1s 634us/step - loss: 0.4114 - accuracy: 0.8552 - val_loss: 0.4507 - val_accuracy: 0.8402\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 449us/step - loss: 0.3971 - accuracy: 0.8591 - val_loss: 0.4400 - val_accuracy: 0.8493\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 196us/step - loss: 0.3839 - accuracy: 0.8669 - val_loss: 0.4305 - val_accuracy: 0.8447\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.3714 - accuracy: 0.8689 - val_loss: 0.4216 - val_accuracy: 0.8402\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.3598 - accuracy: 0.8708 - val_loss: 0.4136 - val_accuracy: 0.8402\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.3493 - accuracy: 0.8718 - val_loss: 0.4067 - val_accuracy: 0.8356\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.3400 - accuracy: 0.8757 - val_loss: 0.4005 - val_accuracy: 0.8311\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.3313 - accuracy: 0.8816 - val_loss: 0.3951 - val_accuracy: 0.8356\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.3238 - accuracy: 0.8875 - val_loss: 0.3906 - val_accuracy: 0.8356\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.3167 - accuracy: 0.8885 - val_loss: 0.3866 - val_accuracy: 0.8356\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.3105 - accuracy: 0.8885 - val_loss: 0.3831 - val_accuracy: 0.8356\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.3049 - accuracy: 0.8894 - val_loss: 0.3799 - val_accuracy: 0.8356\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.3001 - accuracy: 0.8875 - val_loss: 0.3771 - val_accuracy: 0.8356\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2955 - accuracy: 0.8885 - val_loss: 0.3745 - val_accuracy: 0.8356\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2914 - accuracy: 0.8904 - val_loss: 0.3721 - val_accuracy: 0.8356\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2875 - accuracy: 0.8924 - val_loss: 0.3699 - val_accuracy: 0.8356\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2842 - accuracy: 0.8914 - val_loss: 0.3681 - val_accuracy: 0.8402\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2812 - accuracy: 0.8914 - val_loss: 0.3664 - val_accuracy: 0.8402\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2785 - accuracy: 0.8933 - val_loss: 0.3644 - val_accuracy: 0.8402\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2759 - accuracy: 0.8943 - val_loss: 0.3621 - val_accuracy: 0.8402\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2735 - accuracy: 0.8933 - val_loss: 0.3596 - val_accuracy: 0.8402\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 166us/step - loss: 0.2713 - accuracy: 0.8943 - val_loss: 0.3576 - val_accuracy: 0.8447\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2693 - accuracy: 0.8953 - val_loss: 0.3550 - val_accuracy: 0.8447\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2675 - accuracy: 0.8943 - val_loss: 0.3527 - val_accuracy: 0.8447\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2658 - accuracy: 0.8943 - val_loss: 0.3504 - val_accuracy: 0.8447\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2642 - accuracy: 0.8924 - val_loss: 0.3483 - val_accuracy: 0.8447\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2627 - accuracy: 0.8953 - val_loss: 0.3462 - val_accuracy: 0.8447\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2613 - accuracy: 0.8953 - val_loss: 0.3440 - val_accuracy: 0.8493\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2599 - accuracy: 0.8953 - val_loss: 0.3422 - val_accuracy: 0.8493\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2586 - accuracy: 0.8943 - val_loss: 0.3406 - val_accuracy: 0.8493\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2574 - accuracy: 0.8933 - val_loss: 0.3391 - val_accuracy: 0.8539\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2564 - accuracy: 0.8953 - val_loss: 0.3374 - val_accuracy: 0.8539\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.2552 - accuracy: 0.8953 - val_loss: 0.3362 - val_accuracy: 0.8539\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2543 - accuracy: 0.8943 - val_loss: 0.3353 - val_accuracy: 0.8539\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2534 - accuracy: 0.8943 - val_loss: 0.3344 - val_accuracy: 0.8539\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2524 - accuracy: 0.8953 - val_loss: 0.3336 - val_accuracy: 0.8584\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2516 - accuracy: 0.8963 - val_loss: 0.3328 - val_accuracy: 0.8584\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2508 - accuracy: 0.8933 - val_loss: 0.3321 - val_accuracy: 0.8584\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.2500 - accuracy: 0.8963 - val_loss: 0.3314 - val_accuracy: 0.8584\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2493 - accuracy: 0.8963 - val_loss: 0.3308 - val_accuracy: 0.8584\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2484 - accuracy: 0.8982 - val_loss: 0.3302 - val_accuracy: 0.8584\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2477 - accuracy: 0.8982 - val_loss: 0.3296 - val_accuracy: 0.8584\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2470 - accuracy: 0.8982 - val_loss: 0.3290 - val_accuracy: 0.8539\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 178us/step - loss: 0.2463 - accuracy: 0.8992 - val_loss: 0.3284 - val_accuracy: 0.8539\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2456 - accuracy: 0.8973 - val_loss: 0.3278 - val_accuracy: 0.8539\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2449 - accuracy: 0.8992 - val_loss: 0.3273 - val_accuracy: 0.8539\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2442 - accuracy: 0.8982 - val_loss: 0.3267 - val_accuracy: 0.8539\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2436 - accuracy: 0.8982 - val_loss: 0.3261 - val_accuracy: 0.8539\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.2429 - accuracy: 0.8992 - val_loss: 0.3255 - val_accuracy: 0.8539\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2424 - accuracy: 0.8982 - val_loss: 0.3250 - val_accuracy: 0.8539\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 198us/step - loss: 0.2418 - accuracy: 0.8992 - val_loss: 0.3245 - val_accuracy: 0.8539\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 185us/step - loss: 0.2413 - accuracy: 0.8982 - val_loss: 0.3240 - val_accuracy: 0.8539\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 252us/step - loss: 0.2406 - accuracy: 0.9002 - val_loss: 0.3235 - val_accuracy: 0.8539\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 330us/step - loss: 0.2401 - accuracy: 0.9002 - val_loss: 0.3231 - val_accuracy: 0.8539\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 166us/step - loss: 0.2396 - accuracy: 0.8982 - val_loss: 0.3226 - val_accuracy: 0.8539\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 233us/step - loss: 0.2391 - accuracy: 0.8992 - val_loss: 0.3222 - val_accuracy: 0.8539\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 227us/step - loss: 0.2386 - accuracy: 0.9002 - val_loss: 0.3218 - val_accuracy: 0.8539\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 254us/step - loss: 0.2381 - accuracy: 0.9012 - val_loss: 0.3214 - val_accuracy: 0.8493\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 425us/step - loss: 0.2375 - accuracy: 0.9012 - val_loss: 0.3210 - val_accuracy: 0.8493\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 442us/step - loss: 0.2371 - accuracy: 0.8992 - val_loss: 0.3205 - val_accuracy: 0.8493\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 300us/step - loss: 0.2366 - accuracy: 0.9002 - val_loss: 0.3200 - val_accuracy: 0.8493\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 364us/step - loss: 0.2361 - accuracy: 0.8992 - val_loss: 0.3195 - val_accuracy: 0.8493\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 301us/step - loss: 0.2357 - accuracy: 0.9022 - val_loss: 0.3192 - val_accuracy: 0.8493\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 319us/step - loss: 0.2354 - accuracy: 0.9002 - val_loss: 0.3187 - val_accuracy: 0.8493\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 1s 547us/step - loss: 0.2348 - accuracy: 0.9022 - val_loss: 0.3186 - val_accuracy: 0.8493\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 374us/step - loss: 0.2344 - accuracy: 0.9012 - val_loss: 0.3182 - val_accuracy: 0.8539\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 236us/step - loss: 0.2340 - accuracy: 0.9022 - val_loss: 0.3179 - val_accuracy: 0.8539\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 200us/step - loss: 0.2337 - accuracy: 0.9012 - val_loss: 0.3177 - val_accuracy: 0.8539\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 188us/step - loss: 0.2334 - accuracy: 0.9022 - val_loss: 0.3174 - val_accuracy: 0.8539\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 225us/step - loss: 0.2330 - accuracy: 0.9022 - val_loss: 0.3172 - val_accuracy: 0.8539\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 171us/step - loss: 0.2326 - accuracy: 0.9031 - val_loss: 0.3169 - val_accuracy: 0.8539\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 278us/step - loss: 0.2323 - accuracy: 0.9031 - val_loss: 0.3168 - val_accuracy: 0.8539\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 216us/step - loss: 0.2320 - accuracy: 0.9031 - val_loss: 0.3166 - val_accuracy: 0.8539\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 195us/step - loss: 0.2316 - accuracy: 0.9041 - val_loss: 0.3163 - val_accuracy: 0.8539\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 171us/step - loss: 0.2314 - accuracy: 0.9041 - val_loss: 0.3161 - val_accuracy: 0.8539\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 445us/step - loss: 0.2310 - accuracy: 0.9041 - val_loss: 0.3160 - val_accuracy: 0.8539\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 264us/step - loss: 0.2309 - accuracy: 0.9041 - val_loss: 0.3157 - val_accuracy: 0.8539\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 235us/step - loss: 0.2305 - accuracy: 0.9041 - val_loss: 0.3155 - val_accuracy: 0.8539\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 217us/step - loss: 0.2302 - accuracy: 0.9051 - val_loss: 0.3151 - val_accuracy: 0.8539\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 183us/step - loss: 0.2300 - accuracy: 0.9041 - val_loss: 0.3149 - val_accuracy: 0.8539\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 239us/step - loss: 0.2296 - accuracy: 0.9051 - val_loss: 0.3147 - val_accuracy: 0.8539\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 286us/step - loss: 0.2293 - accuracy: 0.9061 - val_loss: 0.3145 - val_accuracy: 0.8539\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 221us/step - loss: 0.2289 - accuracy: 0.9051 - val_loss: 0.3144 - val_accuracy: 0.8539\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 258us/step - loss: 0.2287 - accuracy: 0.9061 - val_loss: 0.3141 - val_accuracy: 0.8539\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 227us/step - loss: 0.2282 - accuracy: 0.9051 - val_loss: 0.3139 - val_accuracy: 0.8539\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 205us/step - loss: 0.2279 - accuracy: 0.9051 - val_loss: 0.3136 - val_accuracy: 0.8539\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 229us/step - loss: 0.2277 - accuracy: 0.9061 - val_loss: 0.3134 - val_accuracy: 0.8539\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 227us/step - loss: 0.2273 - accuracy: 0.9061 - val_loss: 0.3134 - val_accuracy: 0.8539\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 1s 936us/step - loss: 0.6751 - accuracy: 0.6252 - val_loss: 0.6550 - val_accuracy: 0.6256\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.6387 - accuracy: 0.6820 - val_loss: 0.6298 - val_accuracy: 0.7032\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.6120 - accuracy: 0.7202 - val_loss: 0.6086 - val_accuracy: 0.7443\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.5887 - accuracy: 0.7524 - val_loss: 0.5891 - val_accuracy: 0.7580\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.5675 - accuracy: 0.7691 - val_loss: 0.5710 - val_accuracy: 0.7763\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.5478 - accuracy: 0.7838 - val_loss: 0.5537 - val_accuracy: 0.7808\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.5290 - accuracy: 0.7975 - val_loss: 0.5372 - val_accuracy: 0.7945\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.5111 - accuracy: 0.8112 - val_loss: 0.5213 - val_accuracy: 0.8128\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.4935 - accuracy: 0.8209 - val_loss: 0.5057 - val_accuracy: 0.8265\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.4763 - accuracy: 0.8327 - val_loss: 0.4904 - val_accuracy: 0.8174\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.4596 - accuracy: 0.8405 - val_loss: 0.4755 - val_accuracy: 0.8174\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.4434 - accuracy: 0.8483 - val_loss: 0.4613 - val_accuracy: 0.8174\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.4278 - accuracy: 0.8542 - val_loss: 0.4479 - val_accuracy: 0.8219\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.4130 - accuracy: 0.8562 - val_loss: 0.4354 - val_accuracy: 0.8265\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.3990 - accuracy: 0.8650 - val_loss: 0.4239 - val_accuracy: 0.8447\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.3855 - accuracy: 0.8728 - val_loss: 0.4134 - val_accuracy: 0.8447\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.3729 - accuracy: 0.8757 - val_loss: 0.4039 - val_accuracy: 0.8493\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.3613 - accuracy: 0.8826 - val_loss: 0.3954 - val_accuracy: 0.8493\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.3507 - accuracy: 0.8845 - val_loss: 0.3880 - val_accuracy: 0.8493\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.3412 - accuracy: 0.8845 - val_loss: 0.3813 - val_accuracy: 0.8493\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.3325 - accuracy: 0.8845 - val_loss: 0.3754 - val_accuracy: 0.8493\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.3247 - accuracy: 0.8845 - val_loss: 0.3702 - val_accuracy: 0.8493\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.3176 - accuracy: 0.8855 - val_loss: 0.3656 - val_accuracy: 0.8493\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.3109 - accuracy: 0.8865 - val_loss: 0.3616 - val_accuracy: 0.8493\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.3051 - accuracy: 0.8865 - val_loss: 0.3580 - val_accuracy: 0.8584\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2997 - accuracy: 0.8855 - val_loss: 0.3549 - val_accuracy: 0.8584\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2949 - accuracy: 0.8845 - val_loss: 0.3523 - val_accuracy: 0.8584\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2905 - accuracy: 0.8885 - val_loss: 0.3500 - val_accuracy: 0.8584\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 188us/step - loss: 0.2865 - accuracy: 0.8894 - val_loss: 0.3478 - val_accuracy: 0.8584\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2828 - accuracy: 0.8924 - val_loss: 0.3458 - val_accuracy: 0.8539\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 166us/step - loss: 0.2795 - accuracy: 0.8933 - val_loss: 0.3440 - val_accuracy: 0.8539\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 168us/step - loss: 0.2763 - accuracy: 0.8982 - val_loss: 0.3424 - val_accuracy: 0.8584\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.2734 - accuracy: 0.9012 - val_loss: 0.3410 - val_accuracy: 0.8584\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2707 - accuracy: 0.9022 - val_loss: 0.3396 - val_accuracy: 0.8584\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2682 - accuracy: 0.9031 - val_loss: 0.3381 - val_accuracy: 0.8539\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.2658 - accuracy: 0.9012 - val_loss: 0.3367 - val_accuracy: 0.8539\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2636 - accuracy: 0.9022 - val_loss: 0.3354 - val_accuracy: 0.8539\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 179us/step - loss: 0.2617 - accuracy: 0.9022 - val_loss: 0.3343 - val_accuracy: 0.8539\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2598 - accuracy: 0.9012 - val_loss: 0.3332 - val_accuracy: 0.8539\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2581 - accuracy: 0.9041 - val_loss: 0.3321 - val_accuracy: 0.8539\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 219us/step - loss: 0.2564 - accuracy: 0.9022 - val_loss: 0.3311 - val_accuracy: 0.8539\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 174us/step - loss: 0.2549 - accuracy: 0.9031 - val_loss: 0.3301 - val_accuracy: 0.8539\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2535 - accuracy: 0.9031 - val_loss: 0.3291 - val_accuracy: 0.8539\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2521 - accuracy: 0.9031 - val_loss: 0.3281 - val_accuracy: 0.8539\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2507 - accuracy: 0.9031 - val_loss: 0.3271 - val_accuracy: 0.8539\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2495 - accuracy: 0.9031 - val_loss: 0.3262 - val_accuracy: 0.8584\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2483 - accuracy: 0.9041 - val_loss: 0.3252 - val_accuracy: 0.8584\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2470 - accuracy: 0.9041 - val_loss: 0.3243 - val_accuracy: 0.8630\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2459 - accuracy: 0.9051 - val_loss: 0.3233 - val_accuracy: 0.8630\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2450 - accuracy: 0.9041 - val_loss: 0.3225 - val_accuracy: 0.8630\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2440 - accuracy: 0.9041 - val_loss: 0.3215 - val_accuracy: 0.8630\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2430 - accuracy: 0.9041 - val_loss: 0.3207 - val_accuracy: 0.8630\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.2421 - accuracy: 0.9051 - val_loss: 0.3199 - val_accuracy: 0.8630\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 175us/step - loss: 0.2413 - accuracy: 0.9051 - val_loss: 0.3191 - val_accuracy: 0.8630\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2404 - accuracy: 0.9051 - val_loss: 0.3183 - val_accuracy: 0.8630\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 168us/step - loss: 0.2396 - accuracy: 0.9051 - val_loss: 0.3176 - val_accuracy: 0.8630\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2389 - accuracy: 0.9061 - val_loss: 0.3168 - val_accuracy: 0.8630\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2381 - accuracy: 0.9051 - val_loss: 0.3161 - val_accuracy: 0.8584\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2376 - accuracy: 0.9070 - val_loss: 0.3154 - val_accuracy: 0.8630\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2367 - accuracy: 0.9080 - val_loss: 0.3146 - val_accuracy: 0.8676\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2361 - accuracy: 0.9070 - val_loss: 0.3139 - val_accuracy: 0.8676\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2355 - accuracy: 0.9080 - val_loss: 0.3133 - val_accuracy: 0.8676\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2350 - accuracy: 0.9080 - val_loss: 0.3126 - val_accuracy: 0.8676\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2344 - accuracy: 0.9070 - val_loss: 0.3118 - val_accuracy: 0.8676\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2338 - accuracy: 0.9100 - val_loss: 0.3111 - val_accuracy: 0.8676\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2333 - accuracy: 0.9070 - val_loss: 0.3104 - val_accuracy: 0.8721\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.2328 - accuracy: 0.9090 - val_loss: 0.3098 - val_accuracy: 0.8676\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2322 - accuracy: 0.9090 - val_loss: 0.3093 - val_accuracy: 0.8630\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 168us/step - loss: 0.2318 - accuracy: 0.9090 - val_loss: 0.3087 - val_accuracy: 0.8676\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 167us/step - loss: 0.2314 - accuracy: 0.9080 - val_loss: 0.3082 - val_accuracy: 0.8676\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 164us/step - loss: 0.2309 - accuracy: 0.9080 - val_loss: 0.3077 - val_accuracy: 0.8721\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.2304 - accuracy: 0.9080 - val_loss: 0.3072 - val_accuracy: 0.8721\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2300 - accuracy: 0.9090 - val_loss: 0.3068 - val_accuracy: 0.8721\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2296 - accuracy: 0.9090 - val_loss: 0.3063 - val_accuracy: 0.8721\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2291 - accuracy: 0.9090 - val_loss: 0.3057 - val_accuracy: 0.8676\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2287 - accuracy: 0.9100 - val_loss: 0.3052 - val_accuracy: 0.8721\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.2284 - accuracy: 0.9119 - val_loss: 0.3047 - val_accuracy: 0.8767\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2279 - accuracy: 0.9090 - val_loss: 0.3041 - val_accuracy: 0.8767\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2276 - accuracy: 0.9129 - val_loss: 0.3037 - val_accuracy: 0.8767\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2273 - accuracy: 0.9129 - val_loss: 0.3032 - val_accuracy: 0.8767\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2269 - accuracy: 0.9149 - val_loss: 0.3027 - val_accuracy: 0.8721\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2265 - accuracy: 0.9159 - val_loss: 0.3022 - val_accuracy: 0.8721\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.2262 - accuracy: 0.9149 - val_loss: 0.3018 - val_accuracy: 0.8721\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2258 - accuracy: 0.9159 - val_loss: 0.3014 - val_accuracy: 0.8721\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2255 - accuracy: 0.9149 - val_loss: 0.3009 - val_accuracy: 0.8721\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2252 - accuracy: 0.9168 - val_loss: 0.3004 - val_accuracy: 0.8721\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2247 - accuracy: 0.9188 - val_loss: 0.2999 - val_accuracy: 0.8767\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2244 - accuracy: 0.9168 - val_loss: 0.2994 - val_accuracy: 0.8767\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2240 - accuracy: 0.9188 - val_loss: 0.2990 - val_accuracy: 0.8767\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2237 - accuracy: 0.9188 - val_loss: 0.2987 - val_accuracy: 0.8767\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2234 - accuracy: 0.9178 - val_loss: 0.2983 - val_accuracy: 0.8767\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2231 - accuracy: 0.9178 - val_loss: 0.2980 - val_accuracy: 0.8767\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2227 - accuracy: 0.9188 - val_loss: 0.2977 - val_accuracy: 0.8767\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2225 - accuracy: 0.9188 - val_loss: 0.2972 - val_accuracy: 0.8767\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2222 - accuracy: 0.9188 - val_loss: 0.2969 - val_accuracy: 0.8813\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2218 - accuracy: 0.9188 - val_loss: 0.2965 - val_accuracy: 0.8813\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 167us/step - loss: 0.2216 - accuracy: 0.9198 - val_loss: 0.2962 - val_accuracy: 0.8813\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2214 - accuracy: 0.9178 - val_loss: 0.2959 - val_accuracy: 0.8813\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2211 - accuracy: 0.9188 - val_loss: 0.2955 - val_accuracy: 0.8858\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2208 - accuracy: 0.9178 - val_loss: 0.2952 - val_accuracy: 0.8858\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 791us/step - loss: 0.8744 - accuracy: 0.5323 - val_loss: 0.7572 - val_accuracy: 0.5616\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.6779 - accuracy: 0.6331 - val_loss: 0.6595 - val_accuracy: 0.6758\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.5858 - accuracy: 0.7603 - val_loss: 0.6075 - val_accuracy: 0.8037\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.5287 - accuracy: 0.8317 - val_loss: 0.5719 - val_accuracy: 0.8037\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.4871 - accuracy: 0.8415 - val_loss: 0.5446 - val_accuracy: 0.8082\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 164us/step - loss: 0.4540 - accuracy: 0.8464 - val_loss: 0.5217 - val_accuracy: 0.8128\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 180us/step - loss: 0.4269 - accuracy: 0.8552 - val_loss: 0.5029 - val_accuracy: 0.8128\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 169us/step - loss: 0.4049 - accuracy: 0.8611 - val_loss: 0.4871 - val_accuracy: 0.8174\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 166us/step - loss: 0.3867 - accuracy: 0.8659 - val_loss: 0.4735 - val_accuracy: 0.8265\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 171us/step - loss: 0.3715 - accuracy: 0.8679 - val_loss: 0.4615 - val_accuracy: 0.8311\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 205us/step - loss: 0.3586 - accuracy: 0.8708 - val_loss: 0.4506 - val_accuracy: 0.8311\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.3475 - accuracy: 0.8738 - val_loss: 0.4410 - val_accuracy: 0.8311\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.3380 - accuracy: 0.8757 - val_loss: 0.4325 - val_accuracy: 0.8311\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.3296 - accuracy: 0.8757 - val_loss: 0.4244 - val_accuracy: 0.8265\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.3223 - accuracy: 0.8767 - val_loss: 0.4174 - val_accuracy: 0.8265\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.3160 - accuracy: 0.8767 - val_loss: 0.4115 - val_accuracy: 0.8265\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.3104 - accuracy: 0.8777 - val_loss: 0.4061 - val_accuracy: 0.8265\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.3054 - accuracy: 0.8777 - val_loss: 0.4008 - val_accuracy: 0.8219\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.3009 - accuracy: 0.8806 - val_loss: 0.3962 - val_accuracy: 0.8219\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2968 - accuracy: 0.8796 - val_loss: 0.3921 - val_accuracy: 0.8219\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2932 - accuracy: 0.8806 - val_loss: 0.3885 - val_accuracy: 0.8219\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2897 - accuracy: 0.8806 - val_loss: 0.3850 - val_accuracy: 0.8265\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2868 - accuracy: 0.8826 - val_loss: 0.3818 - val_accuracy: 0.8265\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 89us/step - loss: 0.2840 - accuracy: 0.8836 - val_loss: 0.3788 - val_accuracy: 0.8265\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2812 - accuracy: 0.8845 - val_loss: 0.3761 - val_accuracy: 0.8311\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 183us/step - loss: 0.2789 - accuracy: 0.8855 - val_loss: 0.3736 - val_accuracy: 0.8311\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2766 - accuracy: 0.8875 - val_loss: 0.3713 - val_accuracy: 0.8311\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2744 - accuracy: 0.8875 - val_loss: 0.3688 - val_accuracy: 0.8356\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2723 - accuracy: 0.8885 - val_loss: 0.3667 - val_accuracy: 0.8356\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 175us/step - loss: 0.2703 - accuracy: 0.8894 - val_loss: 0.3648 - val_accuracy: 0.8402\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2686 - accuracy: 0.8894 - val_loss: 0.3629 - val_accuracy: 0.8402\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 186us/step - loss: 0.2668 - accuracy: 0.8914 - val_loss: 0.3615 - val_accuracy: 0.8402\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 199us/step - loss: 0.2653 - accuracy: 0.8924 - val_loss: 0.3600 - val_accuracy: 0.8447\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2638 - accuracy: 0.8914 - val_loss: 0.3585 - val_accuracy: 0.8539\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2625 - accuracy: 0.8914 - val_loss: 0.3572 - val_accuracy: 0.8539\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 194us/step - loss: 0.2610 - accuracy: 0.8924 - val_loss: 0.3559 - val_accuracy: 0.8539\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.2598 - accuracy: 0.8914 - val_loss: 0.3546 - val_accuracy: 0.8539\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2586 - accuracy: 0.8904 - val_loss: 0.3535 - val_accuracy: 0.8539\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2576 - accuracy: 0.8894 - val_loss: 0.3523 - val_accuracy: 0.8539\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2565 - accuracy: 0.8914 - val_loss: 0.3512 - val_accuracy: 0.8539\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2553 - accuracy: 0.8904 - val_loss: 0.3500 - val_accuracy: 0.8539\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.2545 - accuracy: 0.8904 - val_loss: 0.3489 - val_accuracy: 0.8539\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.2535 - accuracy: 0.8924 - val_loss: 0.3479 - val_accuracy: 0.8539\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2526 - accuracy: 0.8914 - val_loss: 0.3468 - val_accuracy: 0.8539\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2518 - accuracy: 0.8914 - val_loss: 0.3458 - val_accuracy: 0.8539\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2509 - accuracy: 0.8914 - val_loss: 0.3448 - val_accuracy: 0.8539\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2502 - accuracy: 0.8933 - val_loss: 0.3438 - val_accuracy: 0.8539\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2494 - accuracy: 0.8924 - val_loss: 0.3429 - val_accuracy: 0.8539\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.2485 - accuracy: 0.8933 - val_loss: 0.3418 - val_accuracy: 0.8539\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2478 - accuracy: 0.8933 - val_loss: 0.3409 - val_accuracy: 0.8539\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2471 - accuracy: 0.8924 - val_loss: 0.3399 - val_accuracy: 0.8539\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 193us/step - loss: 0.2465 - accuracy: 0.8924 - val_loss: 0.3389 - val_accuracy: 0.8539\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 171us/step - loss: 0.2458 - accuracy: 0.8943 - val_loss: 0.3380 - val_accuracy: 0.8539\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 175us/step - loss: 0.2451 - accuracy: 0.8953 - val_loss: 0.3371 - val_accuracy: 0.8539\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2444 - accuracy: 0.8943 - val_loss: 0.3362 - val_accuracy: 0.8539\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2437 - accuracy: 0.8953 - val_loss: 0.3352 - val_accuracy: 0.8539\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2430 - accuracy: 0.8973 - val_loss: 0.3343 - val_accuracy: 0.8539\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2425 - accuracy: 0.8992 - val_loss: 0.3336 - val_accuracy: 0.8539\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2419 - accuracy: 0.8992 - val_loss: 0.3327 - val_accuracy: 0.8539\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2414 - accuracy: 0.9012 - val_loss: 0.3319 - val_accuracy: 0.8539\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2408 - accuracy: 0.8992 - val_loss: 0.3311 - val_accuracy: 0.8539\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2403 - accuracy: 0.9002 - val_loss: 0.3304 - val_accuracy: 0.8539\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2398 - accuracy: 0.8973 - val_loss: 0.3297 - val_accuracy: 0.8539\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2393 - accuracy: 0.9002 - val_loss: 0.3290 - val_accuracy: 0.8539\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2388 - accuracy: 0.9012 - val_loss: 0.3284 - val_accuracy: 0.8493\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 168us/step - loss: 0.2382 - accuracy: 0.9002 - val_loss: 0.3277 - val_accuracy: 0.8493\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2379 - accuracy: 0.9012 - val_loss: 0.3271 - val_accuracy: 0.8493\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2373 - accuracy: 0.9012 - val_loss: 0.3266 - val_accuracy: 0.8493\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2368 - accuracy: 0.9031 - val_loss: 0.3259 - val_accuracy: 0.8493\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.2363 - accuracy: 0.9002 - val_loss: 0.3253 - val_accuracy: 0.8493\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 183us/step - loss: 0.2359 - accuracy: 0.9022 - val_loss: 0.3247 - val_accuracy: 0.8539\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2356 - accuracy: 0.9031 - val_loss: 0.3241 - val_accuracy: 0.8539\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 173us/step - loss: 0.2350 - accuracy: 0.9031 - val_loss: 0.3235 - val_accuracy: 0.8539\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2345 - accuracy: 0.9012 - val_loss: 0.3228 - val_accuracy: 0.8539\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2341 - accuracy: 0.9031 - val_loss: 0.3222 - val_accuracy: 0.8493\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2336 - accuracy: 0.9041 - val_loss: 0.3215 - val_accuracy: 0.8493\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2331 - accuracy: 0.9041 - val_loss: 0.3210 - val_accuracy: 0.8493\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2326 - accuracy: 0.9041 - val_loss: 0.3205 - val_accuracy: 0.8493\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 201us/step - loss: 0.2323 - accuracy: 0.9041 - val_loss: 0.3199 - val_accuracy: 0.8493\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 166us/step - loss: 0.2318 - accuracy: 0.9041 - val_loss: 0.3194 - val_accuracy: 0.8493\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 181us/step - loss: 0.2314 - accuracy: 0.9031 - val_loss: 0.3188 - val_accuracy: 0.8493\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2309 - accuracy: 0.9041 - val_loss: 0.3183 - val_accuracy: 0.8493\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.2304 - accuracy: 0.9041 - val_loss: 0.3179 - val_accuracy: 0.8493\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2302 - accuracy: 0.9041 - val_loss: 0.3175 - val_accuracy: 0.8493\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2297 - accuracy: 0.9051 - val_loss: 0.3170 - val_accuracy: 0.8493\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2292 - accuracy: 0.9041 - val_loss: 0.3166 - val_accuracy: 0.8493\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2289 - accuracy: 0.9041 - val_loss: 0.3160 - val_accuracy: 0.8493\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2285 - accuracy: 0.9031 - val_loss: 0.3156 - val_accuracy: 0.8493\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.2282 - accuracy: 0.9041 - val_loss: 0.3151 - val_accuracy: 0.8493\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.2278 - accuracy: 0.9041 - val_loss: 0.3146 - val_accuracy: 0.8493\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2274 - accuracy: 0.9051 - val_loss: 0.3141 - val_accuracy: 0.8493\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2270 - accuracy: 0.9051 - val_loss: 0.3136 - val_accuracy: 0.8493\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.2267 - accuracy: 0.9061 - val_loss: 0.3132 - val_accuracy: 0.8493\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2262 - accuracy: 0.9061 - val_loss: 0.3128 - val_accuracy: 0.8493\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 249us/step - loss: 0.2259 - accuracy: 0.9070 - val_loss: 0.3124 - val_accuracy: 0.8493\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 238us/step - loss: 0.2255 - accuracy: 0.9061 - val_loss: 0.3120 - val_accuracy: 0.8493\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2252 - accuracy: 0.9051 - val_loss: 0.3114 - val_accuracy: 0.8493\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.2248 - accuracy: 0.9051 - val_loss: 0.3110 - val_accuracy: 0.8493\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2244 - accuracy: 0.9061 - val_loss: 0.3107 - val_accuracy: 0.8493\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2240 - accuracy: 0.9051 - val_loss: 0.3103 - val_accuracy: 0.8493\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 816us/step - loss: 0.6807 - accuracy: 0.5235 - val_loss: 0.6608 - val_accuracy: 0.5616\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.6560 - accuracy: 0.6027 - val_loss: 0.6391 - val_accuracy: 0.6712\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.6361 - accuracy: 0.6986 - val_loss: 0.6204 - val_accuracy: 0.7671\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 228us/step - loss: 0.6188 - accuracy: 0.7583 - val_loss: 0.6036 - val_accuracy: 0.7717\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 345us/step - loss: 0.6029 - accuracy: 0.7613 - val_loss: 0.5879 - val_accuracy: 0.7900\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.5876 - accuracy: 0.7632 - val_loss: 0.5730 - val_accuracy: 0.8037\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.5730 - accuracy: 0.7759 - val_loss: 0.5585 - val_accuracy: 0.8128\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.5587 - accuracy: 0.7847 - val_loss: 0.5443 - val_accuracy: 0.8265\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.5445 - accuracy: 0.7906 - val_loss: 0.5304 - val_accuracy: 0.8311\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.5304 - accuracy: 0.7955 - val_loss: 0.5166 - val_accuracy: 0.8402\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.5164 - accuracy: 0.8033 - val_loss: 0.5028 - val_accuracy: 0.8402\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.5022 - accuracy: 0.8112 - val_loss: 0.4893 - val_accuracy: 0.8402\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.4882 - accuracy: 0.8209 - val_loss: 0.4758 - val_accuracy: 0.8356\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.4740 - accuracy: 0.8297 - val_loss: 0.4626 - val_accuracy: 0.8447\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.4599 - accuracy: 0.8288 - val_loss: 0.4499 - val_accuracy: 0.8402\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.4458 - accuracy: 0.8327 - val_loss: 0.4375 - val_accuracy: 0.8539\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 99us/step - loss: 0.4321 - accuracy: 0.8405 - val_loss: 0.4256 - val_accuracy: 0.8584\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 174us/step - loss: 0.4184 - accuracy: 0.8415 - val_loss: 0.4141 - val_accuracy: 0.8630\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 435us/step - loss: 0.4053 - accuracy: 0.8523 - val_loss: 0.4036 - val_accuracy: 0.8721\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 302us/step - loss: 0.3928 - accuracy: 0.8601 - val_loss: 0.3941 - val_accuracy: 0.8767\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 267us/step - loss: 0.3809 - accuracy: 0.8611 - val_loss: 0.3854 - val_accuracy: 0.8813\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 203us/step - loss: 0.3697 - accuracy: 0.8679 - val_loss: 0.3772 - val_accuracy: 0.8904\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 180us/step - loss: 0.3593 - accuracy: 0.8757 - val_loss: 0.3700 - val_accuracy: 0.8858\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 184us/step - loss: 0.3496 - accuracy: 0.8767 - val_loss: 0.3634 - val_accuracy: 0.8858\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 220us/step - loss: 0.3407 - accuracy: 0.8806 - val_loss: 0.3575 - val_accuracy: 0.8767\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 217us/step - loss: 0.3325 - accuracy: 0.8826 - val_loss: 0.3523 - val_accuracy: 0.8767\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 189us/step - loss: 0.3250 - accuracy: 0.8865 - val_loss: 0.3477 - val_accuracy: 0.8767\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 199us/step - loss: 0.3182 - accuracy: 0.8865 - val_loss: 0.3436 - val_accuracy: 0.8767\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 266us/step - loss: 0.3121 - accuracy: 0.8894 - val_loss: 0.3400 - val_accuracy: 0.8813\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 222us/step - loss: 0.3066 - accuracy: 0.8875 - val_loss: 0.3368 - val_accuracy: 0.8721\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 309us/step - loss: 0.3016 - accuracy: 0.8894 - val_loss: 0.3341 - val_accuracy: 0.8767\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 263us/step - loss: 0.2972 - accuracy: 0.8894 - val_loss: 0.3317 - val_accuracy: 0.8767\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 228us/step - loss: 0.2929 - accuracy: 0.8894 - val_loss: 0.3293 - val_accuracy: 0.8676\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 290us/step - loss: 0.2890 - accuracy: 0.8914 - val_loss: 0.3273 - val_accuracy: 0.8676\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 224us/step - loss: 0.2854 - accuracy: 0.8924 - val_loss: 0.3255 - val_accuracy: 0.8584\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 211us/step - loss: 0.2822 - accuracy: 0.8924 - val_loss: 0.3238 - val_accuracy: 0.8584\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 216us/step - loss: 0.2793 - accuracy: 0.8943 - val_loss: 0.3221 - val_accuracy: 0.8584\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 388us/step - loss: 0.2765 - accuracy: 0.8953 - val_loss: 0.3207 - val_accuracy: 0.8584\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 225us/step - loss: 0.2741 - accuracy: 0.8953 - val_loss: 0.3195 - val_accuracy: 0.8584\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 345us/step - loss: 0.2719 - accuracy: 0.8943 - val_loss: 0.3184 - val_accuracy: 0.8584\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 242us/step - loss: 0.2698 - accuracy: 0.8953 - val_loss: 0.3174 - val_accuracy: 0.8584\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 223us/step - loss: 0.2679 - accuracy: 0.8963 - val_loss: 0.3164 - val_accuracy: 0.8584\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 386us/step - loss: 0.2660 - accuracy: 0.8963 - val_loss: 0.3154 - val_accuracy: 0.8584\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 269us/step - loss: 0.2644 - accuracy: 0.8973 - val_loss: 0.3146 - val_accuracy: 0.8584\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 307us/step - loss: 0.2628 - accuracy: 0.8982 - val_loss: 0.3137 - val_accuracy: 0.8584\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 487us/step - loss: 0.2613 - accuracy: 0.8992 - val_loss: 0.3129 - val_accuracy: 0.8584\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 325us/step - loss: 0.2599 - accuracy: 0.8992 - val_loss: 0.3119 - val_accuracy: 0.8584\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.2586 - accuracy: 0.8992 - val_loss: 0.3111 - val_accuracy: 0.8584\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2573 - accuracy: 0.9012 - val_loss: 0.3102 - val_accuracy: 0.8630\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2561 - accuracy: 0.8992 - val_loss: 0.3093 - val_accuracy: 0.8630\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 180us/step - loss: 0.2549 - accuracy: 0.8992 - val_loss: 0.3085 - val_accuracy: 0.8630\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2538 - accuracy: 0.8982 - val_loss: 0.3077 - val_accuracy: 0.8630\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 171us/step - loss: 0.2529 - accuracy: 0.8973 - val_loss: 0.3068 - val_accuracy: 0.8630\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2518 - accuracy: 0.8982 - val_loss: 0.3060 - val_accuracy: 0.8630\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2509 - accuracy: 0.9002 - val_loss: 0.3052 - val_accuracy: 0.8630\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 260us/step - loss: 0.2499 - accuracy: 0.8982 - val_loss: 0.3044 - val_accuracy: 0.8630\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2490 - accuracy: 0.8982 - val_loss: 0.3036 - val_accuracy: 0.8630\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2481 - accuracy: 0.8992 - val_loss: 0.3029 - val_accuracy: 0.8630\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 101us/step - loss: 0.2474 - accuracy: 0.9002 - val_loss: 0.3021 - val_accuracy: 0.8630\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 90us/step - loss: 0.2466 - accuracy: 0.9002 - val_loss: 0.3013 - val_accuracy: 0.8630\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2459 - accuracy: 0.9012 - val_loss: 0.3007 - val_accuracy: 0.8630\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2451 - accuracy: 0.9012 - val_loss: 0.3001 - val_accuracy: 0.8630\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2445 - accuracy: 0.9022 - val_loss: 0.2995 - val_accuracy: 0.8630\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2438 - accuracy: 0.9002 - val_loss: 0.2989 - val_accuracy: 0.8630\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.2432 - accuracy: 0.9002 - val_loss: 0.2983 - val_accuracy: 0.8630\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 100us/step - loss: 0.2426 - accuracy: 0.9022 - val_loss: 0.2976 - val_accuracy: 0.8630\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.2419 - accuracy: 0.9022 - val_loss: 0.2969 - val_accuracy: 0.8630\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2415 - accuracy: 0.9012 - val_loss: 0.2964 - val_accuracy: 0.8630\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2407 - accuracy: 0.9022 - val_loss: 0.2957 - val_accuracy: 0.8630\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 101us/step - loss: 0.2402 - accuracy: 0.9022 - val_loss: 0.2951 - val_accuracy: 0.8630\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2396 - accuracy: 0.9031 - val_loss: 0.2945 - val_accuracy: 0.8630\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2391 - accuracy: 0.9012 - val_loss: 0.2939 - val_accuracy: 0.8676\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 100us/step - loss: 0.2386 - accuracy: 0.9031 - val_loss: 0.2933 - val_accuracy: 0.8721\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2381 - accuracy: 0.9012 - val_loss: 0.2928 - val_accuracy: 0.8721\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.2376 - accuracy: 0.9022 - val_loss: 0.2922 - val_accuracy: 0.8721\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2371 - accuracy: 0.9022 - val_loss: 0.2919 - val_accuracy: 0.8721\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2367 - accuracy: 0.9022 - val_loss: 0.2916 - val_accuracy: 0.8721\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2365 - accuracy: 0.9012 - val_loss: 0.2911 - val_accuracy: 0.8721\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2361 - accuracy: 0.9022 - val_loss: 0.2908 - val_accuracy: 0.8767\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2356 - accuracy: 0.9022 - val_loss: 0.2904 - val_accuracy: 0.8767\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2351 - accuracy: 0.9012 - val_loss: 0.2901 - val_accuracy: 0.8767\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2348 - accuracy: 0.9022 - val_loss: 0.2897 - val_accuracy: 0.8767\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2345 - accuracy: 0.9002 - val_loss: 0.2894 - val_accuracy: 0.8767\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2340 - accuracy: 0.8992 - val_loss: 0.2892 - val_accuracy: 0.8767\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 100us/step - loss: 0.2337 - accuracy: 0.9022 - val_loss: 0.2890 - val_accuracy: 0.8767\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 292us/step - loss: 0.2333 - accuracy: 0.8992 - val_loss: 0.2887 - val_accuracy: 0.8767\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 410us/step - loss: 0.2330 - accuracy: 0.9002 - val_loss: 0.2884 - val_accuracy: 0.8767\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2326 - accuracy: 0.9012 - val_loss: 0.2883 - val_accuracy: 0.8767\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 275us/step - loss: 0.2323 - accuracy: 0.8992 - val_loss: 0.2880 - val_accuracy: 0.8767\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.2320 - accuracy: 0.9012 - val_loss: 0.2878 - val_accuracy: 0.8767\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2318 - accuracy: 0.9022 - val_loss: 0.2876 - val_accuracy: 0.8767\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 101us/step - loss: 0.2313 - accuracy: 0.9022 - val_loss: 0.2874 - val_accuracy: 0.8721\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.2311 - accuracy: 0.9002 - val_loss: 0.2871 - val_accuracy: 0.8721\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.2308 - accuracy: 0.9002 - val_loss: 0.2869 - val_accuracy: 0.8721\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2306 - accuracy: 0.9031 - val_loss: 0.2867 - val_accuracy: 0.8721\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2302 - accuracy: 0.9031 - val_loss: 0.2866 - val_accuracy: 0.8721\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 100us/step - loss: 0.2301 - accuracy: 0.9041 - val_loss: 0.2864 - val_accuracy: 0.8721\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 94us/step - loss: 0.2297 - accuracy: 0.9031 - val_loss: 0.2863 - val_accuracy: 0.8721\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.2294 - accuracy: 0.9031 - val_loss: 0.2861 - val_accuracy: 0.8767\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2292 - accuracy: 0.9061 - val_loss: 0.2860 - val_accuracy: 0.8767\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 883us/step - loss: 0.7233 - accuracy: 0.3493 - val_loss: 0.6931 - val_accuracy: 0.4932\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.6751 - accuracy: 0.5470 - val_loss: 0.6564 - val_accuracy: 0.5799\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.6387 - accuracy: 0.6233 - val_loss: 0.6261 - val_accuracy: 0.6849\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 87us/step - loss: 0.6080 - accuracy: 0.7172 - val_loss: 0.5992 - val_accuracy: 0.7854\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 94us/step - loss: 0.5798 - accuracy: 0.7847 - val_loss: 0.5740 - val_accuracy: 0.7945\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 97us/step - loss: 0.5534 - accuracy: 0.7935 - val_loss: 0.5499 - val_accuracy: 0.8037\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 99us/step - loss: 0.5283 - accuracy: 0.8053 - val_loss: 0.5269 - val_accuracy: 0.8037\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.5042 - accuracy: 0.8141 - val_loss: 0.5048 - val_accuracy: 0.7991\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 94us/step - loss: 0.4811 - accuracy: 0.8278 - val_loss: 0.4837 - val_accuracy: 0.8037\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 95us/step - loss: 0.4593 - accuracy: 0.8376 - val_loss: 0.4638 - val_accuracy: 0.8174\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 92us/step - loss: 0.4390 - accuracy: 0.8444 - val_loss: 0.4454 - val_accuracy: 0.8311\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 99us/step - loss: 0.4202 - accuracy: 0.8523 - val_loss: 0.4282 - val_accuracy: 0.8402\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.4030 - accuracy: 0.8620 - val_loss: 0.4126 - val_accuracy: 0.8447\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.3874 - accuracy: 0.8640 - val_loss: 0.3986 - val_accuracy: 0.8447\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 400us/step - loss: 0.3733 - accuracy: 0.8650 - val_loss: 0.3859 - val_accuracy: 0.8447\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.3607 - accuracy: 0.8699 - val_loss: 0.3748 - val_accuracy: 0.8447\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.3495 - accuracy: 0.8738 - val_loss: 0.3650 - val_accuracy: 0.8539\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.3395 - accuracy: 0.8738 - val_loss: 0.3563 - val_accuracy: 0.8539\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 216us/step - loss: 0.3306 - accuracy: 0.8748 - val_loss: 0.3488 - val_accuracy: 0.8584\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.3228 - accuracy: 0.8728 - val_loss: 0.3423 - val_accuracy: 0.8584\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.3160 - accuracy: 0.8728 - val_loss: 0.3367 - val_accuracy: 0.8584\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.3099 - accuracy: 0.8708 - val_loss: 0.3317 - val_accuracy: 0.8584\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.3047 - accuracy: 0.8738 - val_loss: 0.3273 - val_accuracy: 0.8630\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2999 - accuracy: 0.8767 - val_loss: 0.3236 - val_accuracy: 0.8630\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2956 - accuracy: 0.8767 - val_loss: 0.3203 - val_accuracy: 0.8630\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2920 - accuracy: 0.8787 - val_loss: 0.3174 - val_accuracy: 0.8630\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2886 - accuracy: 0.8787 - val_loss: 0.3148 - val_accuracy: 0.8676\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2856 - accuracy: 0.8796 - val_loss: 0.3126 - val_accuracy: 0.8676\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.2828 - accuracy: 0.8796 - val_loss: 0.3106 - val_accuracy: 0.8676\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2804 - accuracy: 0.8826 - val_loss: 0.3088 - val_accuracy: 0.8676\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2782 - accuracy: 0.8836 - val_loss: 0.3073 - val_accuracy: 0.8676\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2762 - accuracy: 0.8826 - val_loss: 0.3060 - val_accuracy: 0.8676\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2742 - accuracy: 0.8865 - val_loss: 0.3048 - val_accuracy: 0.8767\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 93us/step - loss: 0.2725 - accuracy: 0.8855 - val_loss: 0.3037 - val_accuracy: 0.8767\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.2708 - accuracy: 0.8845 - val_loss: 0.3027 - val_accuracy: 0.8813\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.2694 - accuracy: 0.8845 - val_loss: 0.3018 - val_accuracy: 0.8813\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 100us/step - loss: 0.2681 - accuracy: 0.8845 - val_loss: 0.3008 - val_accuracy: 0.8813\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.2667 - accuracy: 0.8855 - val_loss: 0.2999 - val_accuracy: 0.8813\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.2655 - accuracy: 0.8855 - val_loss: 0.2992 - val_accuracy: 0.8813\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 96us/step - loss: 0.2644 - accuracy: 0.8855 - val_loss: 0.2985 - val_accuracy: 0.8813\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 215us/step - loss: 0.2632 - accuracy: 0.8875 - val_loss: 0.2979 - val_accuracy: 0.8813\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 305us/step - loss: 0.2622 - accuracy: 0.8885 - val_loss: 0.2971 - val_accuracy: 0.8767\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2613 - accuracy: 0.8875 - val_loss: 0.2964 - val_accuracy: 0.8767\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 95us/step - loss: 0.2603 - accuracy: 0.8894 - val_loss: 0.2958 - val_accuracy: 0.8676\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 95us/step - loss: 0.2593 - accuracy: 0.8924 - val_loss: 0.2955 - val_accuracy: 0.8630\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2585 - accuracy: 0.8904 - val_loss: 0.2949 - val_accuracy: 0.8630\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 94us/step - loss: 0.2577 - accuracy: 0.8914 - val_loss: 0.2943 - val_accuracy: 0.8584\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2568 - accuracy: 0.8914 - val_loss: 0.2938 - val_accuracy: 0.8584\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 93us/step - loss: 0.2562 - accuracy: 0.8914 - val_loss: 0.2933 - val_accuracy: 0.8584\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 99us/step - loss: 0.2554 - accuracy: 0.8933 - val_loss: 0.2928 - val_accuracy: 0.8584\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.2547 - accuracy: 0.8943 - val_loss: 0.2925 - val_accuracy: 0.8676\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 94us/step - loss: 0.2542 - accuracy: 0.8943 - val_loss: 0.2921 - val_accuracy: 0.8676\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2535 - accuracy: 0.8953 - val_loss: 0.2916 - val_accuracy: 0.8630\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 95us/step - loss: 0.2528 - accuracy: 0.8943 - val_loss: 0.2911 - val_accuracy: 0.8630\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2521 - accuracy: 0.8953 - val_loss: 0.2906 - val_accuracy: 0.8584\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.2516 - accuracy: 0.8943 - val_loss: 0.2902 - val_accuracy: 0.8630\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 96us/step - loss: 0.2509 - accuracy: 0.8943 - val_loss: 0.2898 - val_accuracy: 0.8630\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2503 - accuracy: 0.8924 - val_loss: 0.2895 - val_accuracy: 0.8630\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2498 - accuracy: 0.8973 - val_loss: 0.2890 - val_accuracy: 0.8630\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2492 - accuracy: 0.8973 - val_loss: 0.2885 - val_accuracy: 0.8630\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.2487 - accuracy: 0.8953 - val_loss: 0.2882 - val_accuracy: 0.8630\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.2481 - accuracy: 0.8953 - val_loss: 0.2877 - val_accuracy: 0.8630\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2477 - accuracy: 0.8953 - val_loss: 0.2873 - val_accuracy: 0.8630\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 99us/step - loss: 0.2471 - accuracy: 0.8953 - val_loss: 0.2870 - val_accuracy: 0.8630\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 101us/step - loss: 0.2467 - accuracy: 0.8963 - val_loss: 0.2865 - val_accuracy: 0.8630\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 99us/step - loss: 0.2462 - accuracy: 0.8982 - val_loss: 0.2861 - val_accuracy: 0.8676\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 100us/step - loss: 0.2457 - accuracy: 0.8953 - val_loss: 0.2858 - val_accuracy: 0.8676\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 100us/step - loss: 0.2452 - accuracy: 0.8953 - val_loss: 0.2855 - val_accuracy: 0.8676\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.2448 - accuracy: 0.8963 - val_loss: 0.2852 - val_accuracy: 0.8676\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2442 - accuracy: 0.8963 - val_loss: 0.2848 - val_accuracy: 0.8676\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 99us/step - loss: 0.2437 - accuracy: 0.9012 - val_loss: 0.2844 - val_accuracy: 0.8676\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.2432 - accuracy: 0.9031 - val_loss: 0.2839 - val_accuracy: 0.8676\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 96us/step - loss: 0.2430 - accuracy: 0.8992 - val_loss: 0.2837 - val_accuracy: 0.8676\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 94us/step - loss: 0.2424 - accuracy: 0.9002 - val_loss: 0.2834 - val_accuracy: 0.8676\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 95us/step - loss: 0.2420 - accuracy: 0.8992 - val_loss: 0.2830 - val_accuracy: 0.8676\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 96us/step - loss: 0.2415 - accuracy: 0.9002 - val_loss: 0.2826 - val_accuracy: 0.8676\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2410 - accuracy: 0.8992 - val_loss: 0.2823 - val_accuracy: 0.8676\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.2406 - accuracy: 0.8992 - val_loss: 0.2818 - val_accuracy: 0.8676\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 99us/step - loss: 0.2402 - accuracy: 0.8992 - val_loss: 0.2815 - val_accuracy: 0.8676\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 99us/step - loss: 0.2398 - accuracy: 0.9002 - val_loss: 0.2813 - val_accuracy: 0.8676\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 96us/step - loss: 0.2394 - accuracy: 0.9002 - val_loss: 0.2810 - val_accuracy: 0.8676\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 101us/step - loss: 0.2389 - accuracy: 0.9012 - val_loss: 0.2806 - val_accuracy: 0.8676\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 99us/step - loss: 0.2385 - accuracy: 0.9012 - val_loss: 0.2803 - val_accuracy: 0.8676\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 101us/step - loss: 0.2382 - accuracy: 0.9012 - val_loss: 0.2801 - val_accuracy: 0.8676\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 84us/step - loss: 0.2378 - accuracy: 0.9012 - val_loss: 0.2800 - val_accuracy: 0.8676\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.2375 - accuracy: 0.9012 - val_loss: 0.2797 - val_accuracy: 0.8676\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 95us/step - loss: 0.2371 - accuracy: 0.9012 - val_loss: 0.2793 - val_accuracy: 0.8676\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 99us/step - loss: 0.2367 - accuracy: 0.9022 - val_loss: 0.2791 - val_accuracy: 0.8676\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.2364 - accuracy: 0.9022 - val_loss: 0.2786 - val_accuracy: 0.8676\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 97us/step - loss: 0.2360 - accuracy: 0.9022 - val_loss: 0.2785 - val_accuracy: 0.8676\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2356 - accuracy: 0.9012 - val_loss: 0.2783 - val_accuracy: 0.8676\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 95us/step - loss: 0.2354 - accuracy: 0.9022 - val_loss: 0.2782 - val_accuracy: 0.8676\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.2350 - accuracy: 0.9022 - val_loss: 0.2780 - val_accuracy: 0.8676\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.2346 - accuracy: 0.9022 - val_loss: 0.2778 - val_accuracy: 0.8676\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.2344 - accuracy: 0.9022 - val_loss: 0.2774 - val_accuracy: 0.8676\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 100us/step - loss: 0.2341 - accuracy: 0.9022 - val_loss: 0.2772 - val_accuracy: 0.8676\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.2338 - accuracy: 0.9022 - val_loss: 0.2770 - val_accuracy: 0.8676\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 99us/step - loss: 0.2334 - accuracy: 0.9022 - val_loss: 0.2767 - val_accuracy: 0.8676\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 99us/step - loss: 0.2331 - accuracy: 0.9022 - val_loss: 0.2765 - val_accuracy: 0.8676\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 97us/step - loss: 0.2329 - accuracy: 0.9031 - val_loss: 0.2761 - val_accuracy: 0.8676\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 762us/step - loss: 0.7100 - accuracy: 0.4883 - val_loss: 0.6826 - val_accuracy: 0.5114\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.6705 - accuracy: 0.5196 - val_loss: 0.6550 - val_accuracy: 0.5434\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.6435 - accuracy: 0.6174 - val_loss: 0.6342 - val_accuracy: 0.6484\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.6215 - accuracy: 0.6869 - val_loss: 0.6165 - val_accuracy: 0.7078\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.6023 - accuracy: 0.7436 - val_loss: 0.6006 - val_accuracy: 0.7352\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.5844 - accuracy: 0.7720 - val_loss: 0.5858 - val_accuracy: 0.7534\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.5672 - accuracy: 0.7857 - val_loss: 0.5714 - val_accuracy: 0.7626\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.5504 - accuracy: 0.7994 - val_loss: 0.5572 - val_accuracy: 0.7763\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.5337 - accuracy: 0.8072 - val_loss: 0.5432 - val_accuracy: 0.7763\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.5171 - accuracy: 0.8112 - val_loss: 0.5292 - val_accuracy: 0.7854\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.5004 - accuracy: 0.8151 - val_loss: 0.5153 - val_accuracy: 0.7900\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.4836 - accuracy: 0.8209 - val_loss: 0.5017 - val_accuracy: 0.7900\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.4672 - accuracy: 0.8249 - val_loss: 0.4885 - val_accuracy: 0.7991\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.4509 - accuracy: 0.8317 - val_loss: 0.4758 - val_accuracy: 0.8037\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.4350 - accuracy: 0.8395 - val_loss: 0.4636 - val_accuracy: 0.8174\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.4196 - accuracy: 0.8493 - val_loss: 0.4519 - val_accuracy: 0.8265\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.4049 - accuracy: 0.8581 - val_loss: 0.4411 - val_accuracy: 0.8402\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.3911 - accuracy: 0.8640 - val_loss: 0.4312 - val_accuracy: 0.8356\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.3784 - accuracy: 0.8689 - val_loss: 0.4220 - val_accuracy: 0.8356\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.3660 - accuracy: 0.8767 - val_loss: 0.4138 - val_accuracy: 0.8356\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.3551 - accuracy: 0.8806 - val_loss: 0.4065 - val_accuracy: 0.8402\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.3451 - accuracy: 0.8865 - val_loss: 0.4001 - val_accuracy: 0.8447\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.3360 - accuracy: 0.8885 - val_loss: 0.3944 - val_accuracy: 0.8493\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.3280 - accuracy: 0.8933 - val_loss: 0.3894 - val_accuracy: 0.8493\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.3207 - accuracy: 0.8973 - val_loss: 0.3848 - val_accuracy: 0.8447\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.3142 - accuracy: 0.8973 - val_loss: 0.3809 - val_accuracy: 0.8447\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.3085 - accuracy: 0.8973 - val_loss: 0.3771 - val_accuracy: 0.8447\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.3028 - accuracy: 0.8982 - val_loss: 0.3735 - val_accuracy: 0.8447\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2976 - accuracy: 0.8963 - val_loss: 0.3702 - val_accuracy: 0.8447\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2929 - accuracy: 0.8963 - val_loss: 0.3674 - val_accuracy: 0.8447\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2888 - accuracy: 0.8973 - val_loss: 0.3646 - val_accuracy: 0.8447\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2847 - accuracy: 0.8963 - val_loss: 0.3618 - val_accuracy: 0.8493\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2811 - accuracy: 0.9002 - val_loss: 0.3593 - val_accuracy: 0.8539\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2776 - accuracy: 0.9031 - val_loss: 0.3571 - val_accuracy: 0.8493\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2745 - accuracy: 0.9041 - val_loss: 0.3549 - val_accuracy: 0.8539\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2714 - accuracy: 0.9031 - val_loss: 0.3529 - val_accuracy: 0.8539\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2688 - accuracy: 0.9031 - val_loss: 0.3510 - val_accuracy: 0.8539\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2664 - accuracy: 0.9041 - val_loss: 0.3493 - val_accuracy: 0.8539\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 216us/step - loss: 0.2639 - accuracy: 0.9070 - val_loss: 0.3477 - val_accuracy: 0.8539\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 333us/step - loss: 0.2618 - accuracy: 0.9061 - val_loss: 0.3459 - val_accuracy: 0.8539\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 301us/step - loss: 0.2597 - accuracy: 0.9061 - val_loss: 0.3445 - val_accuracy: 0.8584\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2578 - accuracy: 0.9041 - val_loss: 0.3431 - val_accuracy: 0.8584\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2559 - accuracy: 0.9061 - val_loss: 0.3418 - val_accuracy: 0.8584\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2543 - accuracy: 0.9051 - val_loss: 0.3407 - val_accuracy: 0.8630\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2527 - accuracy: 0.9061 - val_loss: 0.3396 - val_accuracy: 0.8630\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2512 - accuracy: 0.9061 - val_loss: 0.3387 - val_accuracy: 0.8630\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.2499 - accuracy: 0.9090 - val_loss: 0.3377 - val_accuracy: 0.8630\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2486 - accuracy: 0.9080 - val_loss: 0.3368 - val_accuracy: 0.8630\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2474 - accuracy: 0.9100 - val_loss: 0.3360 - val_accuracy: 0.8630\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2463 - accuracy: 0.9090 - val_loss: 0.3352 - val_accuracy: 0.8584\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2453 - accuracy: 0.9110 - val_loss: 0.3344 - val_accuracy: 0.8584\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2442 - accuracy: 0.9100 - val_loss: 0.3337 - val_accuracy: 0.8584\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2435 - accuracy: 0.9100 - val_loss: 0.3331 - val_accuracy: 0.8539\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2425 - accuracy: 0.9100 - val_loss: 0.3326 - val_accuracy: 0.8539\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.2417 - accuracy: 0.9100 - val_loss: 0.3320 - val_accuracy: 0.8539\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2409 - accuracy: 0.9090 - val_loss: 0.3316 - val_accuracy: 0.8584\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2402 - accuracy: 0.9100 - val_loss: 0.3311 - val_accuracy: 0.8584\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2395 - accuracy: 0.9090 - val_loss: 0.3307 - val_accuracy: 0.8584\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2387 - accuracy: 0.9090 - val_loss: 0.3302 - val_accuracy: 0.8584\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 279us/step - loss: 0.2381 - accuracy: 0.9090 - val_loss: 0.3298 - val_accuracy: 0.8630\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 364us/step - loss: 0.2375 - accuracy: 0.9080 - val_loss: 0.3294 - val_accuracy: 0.8630\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 363us/step - loss: 0.2370 - accuracy: 0.9080 - val_loss: 0.3291 - val_accuracy: 0.8630\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.2363 - accuracy: 0.9080 - val_loss: 0.3288 - val_accuracy: 0.8630\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2359 - accuracy: 0.9080 - val_loss: 0.3284 - val_accuracy: 0.8630\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2352 - accuracy: 0.9070 - val_loss: 0.3280 - val_accuracy: 0.8630\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2348 - accuracy: 0.9061 - val_loss: 0.3277 - val_accuracy: 0.8676\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2342 - accuracy: 0.9070 - val_loss: 0.3274 - val_accuracy: 0.8676\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2338 - accuracy: 0.9070 - val_loss: 0.3270 - val_accuracy: 0.8676\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2333 - accuracy: 0.9070 - val_loss: 0.3267 - val_accuracy: 0.8676\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2329 - accuracy: 0.9070 - val_loss: 0.3264 - val_accuracy: 0.8676\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2325 - accuracy: 0.9061 - val_loss: 0.3261 - val_accuracy: 0.8676\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2321 - accuracy: 0.9070 - val_loss: 0.3258 - val_accuracy: 0.8676\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2317 - accuracy: 0.9061 - val_loss: 0.3255 - val_accuracy: 0.8676\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2312 - accuracy: 0.9070 - val_loss: 0.3253 - val_accuracy: 0.8676\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2308 - accuracy: 0.9080 - val_loss: 0.3250 - val_accuracy: 0.8676\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2306 - accuracy: 0.9090 - val_loss: 0.3247 - val_accuracy: 0.8676\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2302 - accuracy: 0.9070 - val_loss: 0.3244 - val_accuracy: 0.8676\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2298 - accuracy: 0.9061 - val_loss: 0.3241 - val_accuracy: 0.8584\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2296 - accuracy: 0.9061 - val_loss: 0.3239 - val_accuracy: 0.8584\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2292 - accuracy: 0.9070 - val_loss: 0.3235 - val_accuracy: 0.8584\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2289 - accuracy: 0.9070 - val_loss: 0.3233 - val_accuracy: 0.8584\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2286 - accuracy: 0.9080 - val_loss: 0.3232 - val_accuracy: 0.8630\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2284 - accuracy: 0.9070 - val_loss: 0.3229 - val_accuracy: 0.8630\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2281 - accuracy: 0.9070 - val_loss: 0.3227 - val_accuracy: 0.8630\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2278 - accuracy: 0.9070 - val_loss: 0.3223 - val_accuracy: 0.8630\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2276 - accuracy: 0.9070 - val_loss: 0.3221 - val_accuracy: 0.8630\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.2273 - accuracy: 0.9061 - val_loss: 0.3218 - val_accuracy: 0.8630\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2271 - accuracy: 0.9051 - val_loss: 0.3215 - val_accuracy: 0.8630\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.2269 - accuracy: 0.9070 - val_loss: 0.3213 - val_accuracy: 0.8630\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2265 - accuracy: 0.9061 - val_loss: 0.3211 - val_accuracy: 0.8630\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2264 - accuracy: 0.9070 - val_loss: 0.3209 - val_accuracy: 0.8630\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2261 - accuracy: 0.9051 - val_loss: 0.3207 - val_accuracy: 0.8630\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2258 - accuracy: 0.9051 - val_loss: 0.3204 - val_accuracy: 0.8630\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2256 - accuracy: 0.9051 - val_loss: 0.3201 - val_accuracy: 0.8630\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2254 - accuracy: 0.9051 - val_loss: 0.3198 - val_accuracy: 0.8630\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2252 - accuracy: 0.9061 - val_loss: 0.3196 - val_accuracy: 0.8630\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2250 - accuracy: 0.9080 - val_loss: 0.3194 - val_accuracy: 0.8630\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2248 - accuracy: 0.9080 - val_loss: 0.3192 - val_accuracy: 0.8630\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2246 - accuracy: 0.9070 - val_loss: 0.3189 - val_accuracy: 0.8676\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2244 - accuracy: 0.9080 - val_loss: 0.3186 - val_accuracy: 0.8676\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 722us/step - loss: 0.7394 - accuracy: 0.4902 - val_loss: 0.7097 - val_accuracy: 0.5023\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.7048 - accuracy: 0.5117 - val_loss: 0.6835 - val_accuracy: 0.5342\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 370us/step - loss: 0.6830 - accuracy: 0.5548 - val_loss: 0.6650 - val_accuracy: 0.5890\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 207us/step - loss: 0.6663 - accuracy: 0.6018 - val_loss: 0.6496 - val_accuracy: 0.6530\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.6516 - accuracy: 0.6360 - val_loss: 0.6360 - val_accuracy: 0.6712\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.6374 - accuracy: 0.6683 - val_loss: 0.6222 - val_accuracy: 0.7169\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.6230 - accuracy: 0.6859 - val_loss: 0.6077 - val_accuracy: 0.7671\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.6083 - accuracy: 0.7133 - val_loss: 0.5930 - val_accuracy: 0.7717\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 172us/step - loss: 0.5938 - accuracy: 0.7368 - val_loss: 0.5787 - val_accuracy: 0.7763\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 235us/step - loss: 0.5794 - accuracy: 0.7524 - val_loss: 0.5653 - val_accuracy: 0.7854\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.5659 - accuracy: 0.7661 - val_loss: 0.5534 - val_accuracy: 0.7900\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.5533 - accuracy: 0.7838 - val_loss: 0.5423 - val_accuracy: 0.8037\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.5412 - accuracy: 0.7857 - val_loss: 0.5316 - val_accuracy: 0.7945\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.5295 - accuracy: 0.7906 - val_loss: 0.5208 - val_accuracy: 0.7900\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 93us/step - loss: 0.5177 - accuracy: 0.8072 - val_loss: 0.5102 - val_accuracy: 0.7900\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 83us/step - loss: 0.5061 - accuracy: 0.8141 - val_loss: 0.4994 - val_accuracy: 0.7945\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 86us/step - loss: 0.4947 - accuracy: 0.8327 - val_loss: 0.4893 - val_accuracy: 0.8174\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 79us/step - loss: 0.4838 - accuracy: 0.8395 - val_loss: 0.4792 - val_accuracy: 0.8219\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 99us/step - loss: 0.4727 - accuracy: 0.8434 - val_loss: 0.4695 - val_accuracy: 0.8265\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.4619 - accuracy: 0.8542 - val_loss: 0.4605 - val_accuracy: 0.8311\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 382us/step - loss: 0.4520 - accuracy: 0.8630 - val_loss: 0.4523 - val_accuracy: 0.8402\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.4427 - accuracy: 0.8718 - val_loss: 0.4451 - val_accuracy: 0.8447\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.4342 - accuracy: 0.8757 - val_loss: 0.4385 - val_accuracy: 0.8493\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.4263 - accuracy: 0.8806 - val_loss: 0.4325 - val_accuracy: 0.8447\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 223us/step - loss: 0.4189 - accuracy: 0.8836 - val_loss: 0.4270 - val_accuracy: 0.8493\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 286us/step - loss: 0.4117 - accuracy: 0.8885 - val_loss: 0.4218 - val_accuracy: 0.8356\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 196us/step - loss: 0.4049 - accuracy: 0.8894 - val_loss: 0.4169 - val_accuracy: 0.8356\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.3986 - accuracy: 0.8914 - val_loss: 0.4125 - val_accuracy: 0.8402\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.3928 - accuracy: 0.8924 - val_loss: 0.4085 - val_accuracy: 0.8402\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 316us/step - loss: 0.3873 - accuracy: 0.8924 - val_loss: 0.4047 - val_accuracy: 0.8402\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.3820 - accuracy: 0.8924 - val_loss: 0.4012 - val_accuracy: 0.8402\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.3773 - accuracy: 0.8914 - val_loss: 0.3981 - val_accuracy: 0.8402\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.3728 - accuracy: 0.8924 - val_loss: 0.3952 - val_accuracy: 0.8402\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.3686 - accuracy: 0.8924 - val_loss: 0.3924 - val_accuracy: 0.8402\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.3647 - accuracy: 0.8914 - val_loss: 0.3899 - val_accuracy: 0.8447\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.3610 - accuracy: 0.8924 - val_loss: 0.3875 - val_accuracy: 0.8447\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.3575 - accuracy: 0.8953 - val_loss: 0.3852 - val_accuracy: 0.8493\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.3542 - accuracy: 0.8924 - val_loss: 0.3832 - val_accuracy: 0.8493\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.3511 - accuracy: 0.8943 - val_loss: 0.3814 - val_accuracy: 0.8539\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.3482 - accuracy: 0.8943 - val_loss: 0.3795 - val_accuracy: 0.8539\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.3455 - accuracy: 0.8943 - val_loss: 0.3777 - val_accuracy: 0.8584\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.3429 - accuracy: 0.8953 - val_loss: 0.3760 - val_accuracy: 0.8584\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.3403 - accuracy: 0.8953 - val_loss: 0.3744 - val_accuracy: 0.8584\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 170us/step - loss: 0.3380 - accuracy: 0.8973 - val_loss: 0.3729 - val_accuracy: 0.8584\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 422us/step - loss: 0.3357 - accuracy: 0.8973 - val_loss: 0.3714 - val_accuracy: 0.8584\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 243us/step - loss: 0.3337 - accuracy: 0.8982 - val_loss: 0.3700 - val_accuracy: 0.8584\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 101us/step - loss: 0.3316 - accuracy: 0.8963 - val_loss: 0.3687 - val_accuracy: 0.8584\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.3296 - accuracy: 0.8982 - val_loss: 0.3673 - val_accuracy: 0.8584\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.3278 - accuracy: 0.8982 - val_loss: 0.3661 - val_accuracy: 0.8584\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.3261 - accuracy: 0.8992 - val_loss: 0.3650 - val_accuracy: 0.8584\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.3244 - accuracy: 0.8992 - val_loss: 0.3639 - val_accuracy: 0.8584\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.3226 - accuracy: 0.8992 - val_loss: 0.3628 - val_accuracy: 0.8584\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.3210 - accuracy: 0.9002 - val_loss: 0.3618 - val_accuracy: 0.8584\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.3195 - accuracy: 0.8992 - val_loss: 0.3608 - val_accuracy: 0.8584\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.3181 - accuracy: 0.9002 - val_loss: 0.3599 - val_accuracy: 0.8584\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.3166 - accuracy: 0.9002 - val_loss: 0.3590 - val_accuracy: 0.8584\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 210us/step - loss: 0.3154 - accuracy: 0.9012 - val_loss: 0.3581 - val_accuracy: 0.8630\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 276us/step - loss: 0.3140 - accuracy: 0.9002 - val_loss: 0.3573 - val_accuracy: 0.8630\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.3127 - accuracy: 0.9002 - val_loss: 0.3564 - val_accuracy: 0.8630\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.3115 - accuracy: 0.9012 - val_loss: 0.3556 - val_accuracy: 0.8630\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.3103 - accuracy: 0.9012 - val_loss: 0.3548 - val_accuracy: 0.8630\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.3091 - accuracy: 0.9012 - val_loss: 0.3539 - val_accuracy: 0.8630\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.3081 - accuracy: 0.9012 - val_loss: 0.3531 - val_accuracy: 0.8630\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.3070 - accuracy: 0.9012 - val_loss: 0.3524 - val_accuracy: 0.8630\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.3059 - accuracy: 0.9022 - val_loss: 0.3517 - val_accuracy: 0.8630\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.3051 - accuracy: 0.9022 - val_loss: 0.3510 - val_accuracy: 0.8630\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.3040 - accuracy: 0.9012 - val_loss: 0.3502 - val_accuracy: 0.8630\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.3030 - accuracy: 0.9031 - val_loss: 0.3494 - val_accuracy: 0.8630\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 266us/step - loss: 0.3022 - accuracy: 0.9031 - val_loss: 0.3486 - val_accuracy: 0.8630\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 397us/step - loss: 0.3013 - accuracy: 0.9041 - val_loss: 0.3479 - val_accuracy: 0.8630\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 242us/step - loss: 0.3003 - accuracy: 0.9061 - val_loss: 0.3472 - val_accuracy: 0.8630\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2995 - accuracy: 0.9061 - val_loss: 0.3465 - val_accuracy: 0.8630\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2987 - accuracy: 0.9051 - val_loss: 0.3458 - val_accuracy: 0.8630\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2980 - accuracy: 0.9041 - val_loss: 0.3452 - val_accuracy: 0.8630\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.2972 - accuracy: 0.9041 - val_loss: 0.3446 - val_accuracy: 0.8630\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2963 - accuracy: 0.9061 - val_loss: 0.3440 - val_accuracy: 0.8630\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2956 - accuracy: 0.9051 - val_loss: 0.3434 - val_accuracy: 0.8630\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2948 - accuracy: 0.9041 - val_loss: 0.3428 - val_accuracy: 0.8630\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2941 - accuracy: 0.9051 - val_loss: 0.3423 - val_accuracy: 0.8630\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 364us/step - loss: 0.2934 - accuracy: 0.9051 - val_loss: 0.3417 - val_accuracy: 0.8630\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 461us/step - loss: 0.2928 - accuracy: 0.9041 - val_loss: 0.3412 - val_accuracy: 0.8630\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 281us/step - loss: 0.2921 - accuracy: 0.9051 - val_loss: 0.3406 - val_accuracy: 0.8630\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2913 - accuracy: 0.9041 - val_loss: 0.3400 - val_accuracy: 0.8630\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2908 - accuracy: 0.9061 - val_loss: 0.3394 - val_accuracy: 0.8630\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2900 - accuracy: 0.9041 - val_loss: 0.3389 - val_accuracy: 0.8630\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2894 - accuracy: 0.9061 - val_loss: 0.3384 - val_accuracy: 0.8630\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2889 - accuracy: 0.9061 - val_loss: 0.3379 - val_accuracy: 0.8630\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2882 - accuracy: 0.9041 - val_loss: 0.3375 - val_accuracy: 0.8630\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2877 - accuracy: 0.9041 - val_loss: 0.3370 - val_accuracy: 0.8630\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2871 - accuracy: 0.9051 - val_loss: 0.3366 - val_accuracy: 0.8676\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2866 - accuracy: 0.9061 - val_loss: 0.3361 - val_accuracy: 0.8676\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2861 - accuracy: 0.9041 - val_loss: 0.3357 - val_accuracy: 0.8676\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2856 - accuracy: 0.9061 - val_loss: 0.3352 - val_accuracy: 0.8676\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2851 - accuracy: 0.9051 - val_loss: 0.3348 - val_accuracy: 0.8676\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2845 - accuracy: 0.9051 - val_loss: 0.3344 - val_accuracy: 0.8676\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2839 - accuracy: 0.9061 - val_loss: 0.3339 - val_accuracy: 0.8721\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2833 - accuracy: 0.9051 - val_loss: 0.3335 - val_accuracy: 0.8721\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2829 - accuracy: 0.9051 - val_loss: 0.3330 - val_accuracy: 0.8721\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2823 - accuracy: 0.9070 - val_loss: 0.3325 - val_accuracy: 0.8721\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2819 - accuracy: 0.9061 - val_loss: 0.3321 - val_accuracy: 0.8676\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 938us/step - loss: 0.7209 - accuracy: 0.4951 - val_loss: 0.7368 - val_accuracy: 0.5251\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.6805 - accuracy: 0.5587 - val_loss: 0.7036 - val_accuracy: 0.6073\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 94us/step - loss: 0.6532 - accuracy: 0.6341 - val_loss: 0.6792 - val_accuracy: 0.6484\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.6312 - accuracy: 0.6859 - val_loss: 0.6589 - val_accuracy: 0.7032\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 100us/step - loss: 0.6107 - accuracy: 0.7290 - val_loss: 0.6399 - val_accuracy: 0.7534\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 93us/step - loss: 0.5908 - accuracy: 0.7671 - val_loss: 0.6215 - val_accuracy: 0.7808\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.5710 - accuracy: 0.7955 - val_loss: 0.6034 - val_accuracy: 0.8037\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 101us/step - loss: 0.5513 - accuracy: 0.8141 - val_loss: 0.5854 - val_accuracy: 0.8128\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.5318 - accuracy: 0.8278 - val_loss: 0.5673 - val_accuracy: 0.8219\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.5123 - accuracy: 0.8337 - val_loss: 0.5493 - val_accuracy: 0.8219\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 97us/step - loss: 0.4932 - accuracy: 0.8434 - val_loss: 0.5318 - val_accuracy: 0.8356\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 97us/step - loss: 0.4748 - accuracy: 0.8483 - val_loss: 0.5146 - val_accuracy: 0.8402\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 278us/step - loss: 0.4572 - accuracy: 0.8532 - val_loss: 0.4980 - val_accuracy: 0.8447\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 95us/step - loss: 0.4403 - accuracy: 0.8571 - val_loss: 0.4819 - val_accuracy: 0.8447\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 97us/step - loss: 0.4244 - accuracy: 0.8571 - val_loss: 0.4664 - val_accuracy: 0.8447\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.4095 - accuracy: 0.8581 - val_loss: 0.4518 - val_accuracy: 0.8447\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 95us/step - loss: 0.3955 - accuracy: 0.8611 - val_loss: 0.4378 - val_accuracy: 0.8493\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 400us/step - loss: 0.3825 - accuracy: 0.8659 - val_loss: 0.4243 - val_accuracy: 0.8493\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.3703 - accuracy: 0.8679 - val_loss: 0.4116 - val_accuracy: 0.8493\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.3591 - accuracy: 0.8699 - val_loss: 0.3998 - val_accuracy: 0.8584\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.3489 - accuracy: 0.8718 - val_loss: 0.3888 - val_accuracy: 0.8584\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.3395 - accuracy: 0.8718 - val_loss: 0.3791 - val_accuracy: 0.8584\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.3309 - accuracy: 0.8757 - val_loss: 0.3708 - val_accuracy: 0.8630\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.3231 - accuracy: 0.8767 - val_loss: 0.3633 - val_accuracy: 0.8676\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 329us/step - loss: 0.3161 - accuracy: 0.8787 - val_loss: 0.3570 - val_accuracy: 0.8721\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 234us/step - loss: 0.3097 - accuracy: 0.8787 - val_loss: 0.3513 - val_accuracy: 0.8721\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.3038 - accuracy: 0.8855 - val_loss: 0.3466 - val_accuracy: 0.8676\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 184us/step - loss: 0.2984 - accuracy: 0.8855 - val_loss: 0.3421 - val_accuracy: 0.8721\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2936 - accuracy: 0.8865 - val_loss: 0.3381 - val_accuracy: 0.8767\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.2890 - accuracy: 0.8865 - val_loss: 0.3348 - val_accuracy: 0.8767\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 317us/step - loss: 0.2849 - accuracy: 0.8875 - val_loss: 0.3318 - val_accuracy: 0.8767\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.2810 - accuracy: 0.8885 - val_loss: 0.3289 - val_accuracy: 0.8767\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 311us/step - loss: 0.2775 - accuracy: 0.8894 - val_loss: 0.3264 - val_accuracy: 0.8767\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 216us/step - loss: 0.2741 - accuracy: 0.8924 - val_loss: 0.3239 - val_accuracy: 0.8767\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 181us/step - loss: 0.2709 - accuracy: 0.8933 - val_loss: 0.3217 - val_accuracy: 0.8767\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 184us/step - loss: 0.2680 - accuracy: 0.8943 - val_loss: 0.3197 - val_accuracy: 0.8767\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2653 - accuracy: 0.8963 - val_loss: 0.3179 - val_accuracy: 0.8767\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 177us/step - loss: 0.2628 - accuracy: 0.8963 - val_loss: 0.3162 - val_accuracy: 0.8767\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2604 - accuracy: 0.8982 - val_loss: 0.3147 - val_accuracy: 0.8813\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 449us/step - loss: 0.2583 - accuracy: 0.8963 - val_loss: 0.3134 - val_accuracy: 0.8813\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2563 - accuracy: 0.8982 - val_loss: 0.3118 - val_accuracy: 0.8813\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2545 - accuracy: 0.9002 - val_loss: 0.3106 - val_accuracy: 0.8813\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.2527 - accuracy: 0.9022 - val_loss: 0.3094 - val_accuracy: 0.8767\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2511 - accuracy: 0.9022 - val_loss: 0.3082 - val_accuracy: 0.8813\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 231us/step - loss: 0.2495 - accuracy: 0.9041 - val_loss: 0.3069 - val_accuracy: 0.8813\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2480 - accuracy: 0.9041 - val_loss: 0.3057 - val_accuracy: 0.8767\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2468 - accuracy: 0.9061 - val_loss: 0.3044 - val_accuracy: 0.8767\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2455 - accuracy: 0.9051 - val_loss: 0.3033 - val_accuracy: 0.8767\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2443 - accuracy: 0.9061 - val_loss: 0.3021 - val_accuracy: 0.8767\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2432 - accuracy: 0.9080 - val_loss: 0.3010 - val_accuracy: 0.8813\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2421 - accuracy: 0.9080 - val_loss: 0.2999 - val_accuracy: 0.8813\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2412 - accuracy: 0.9090 - val_loss: 0.2989 - val_accuracy: 0.8813\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2402 - accuracy: 0.9080 - val_loss: 0.2981 - val_accuracy: 0.8813\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2394 - accuracy: 0.9080 - val_loss: 0.2973 - val_accuracy: 0.8813\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2386 - accuracy: 0.9080 - val_loss: 0.2964 - val_accuracy: 0.8813\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2379 - accuracy: 0.9090 - val_loss: 0.2953 - val_accuracy: 0.8813\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2371 - accuracy: 0.9090 - val_loss: 0.2943 - val_accuracy: 0.8813\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2364 - accuracy: 0.9100 - val_loss: 0.2936 - val_accuracy: 0.8813\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 412us/step - loss: 0.2358 - accuracy: 0.9110 - val_loss: 0.2928 - val_accuracy: 0.8813\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 257us/step - loss: 0.2352 - accuracy: 0.9100 - val_loss: 0.2921 - val_accuracy: 0.8813\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 248us/step - loss: 0.2346 - accuracy: 0.9100 - val_loss: 0.2916 - val_accuracy: 0.8813\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 323us/step - loss: 0.2340 - accuracy: 0.9100 - val_loss: 0.2910 - val_accuracy: 0.8767\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 257us/step - loss: 0.2336 - accuracy: 0.9119 - val_loss: 0.2904 - val_accuracy: 0.8767\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 197us/step - loss: 0.2331 - accuracy: 0.9119 - val_loss: 0.2897 - val_accuracy: 0.8767\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 296us/step - loss: 0.2326 - accuracy: 0.9119 - val_loss: 0.2890 - val_accuracy: 0.8767\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 336us/step - loss: 0.2321 - accuracy: 0.9119 - val_loss: 0.2884 - val_accuracy: 0.8767\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 297us/step - loss: 0.2317 - accuracy: 0.9129 - val_loss: 0.2877 - val_accuracy: 0.8813\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 333us/step - loss: 0.2312 - accuracy: 0.9119 - val_loss: 0.2872 - val_accuracy: 0.8813\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 184us/step - loss: 0.2309 - accuracy: 0.9139 - val_loss: 0.2866 - val_accuracy: 0.8813\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 342us/step - loss: 0.2305 - accuracy: 0.9129 - val_loss: 0.2862 - val_accuracy: 0.8813\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 283us/step - loss: 0.2300 - accuracy: 0.9139 - val_loss: 0.2856 - val_accuracy: 0.8813\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 351us/step - loss: 0.2297 - accuracy: 0.9129 - val_loss: 0.2850 - val_accuracy: 0.8813\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 357us/step - loss: 0.2293 - accuracy: 0.9139 - val_loss: 0.2846 - val_accuracy: 0.8813\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 396us/step - loss: 0.2289 - accuracy: 0.9129 - val_loss: 0.2839 - val_accuracy: 0.8813\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 190us/step - loss: 0.2285 - accuracy: 0.9129 - val_loss: 0.2833 - val_accuracy: 0.8813\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 181us/step - loss: 0.2280 - accuracy: 0.9129 - val_loss: 0.2828 - val_accuracy: 0.8813\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 180us/step - loss: 0.2277 - accuracy: 0.9139 - val_loss: 0.2825 - val_accuracy: 0.8813\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 174us/step - loss: 0.2273 - accuracy: 0.9129 - val_loss: 0.2820 - val_accuracy: 0.8813\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 175us/step - loss: 0.2270 - accuracy: 0.9129 - val_loss: 0.2816 - val_accuracy: 0.8813\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 175us/step - loss: 0.2266 - accuracy: 0.9139 - val_loss: 0.2811 - val_accuracy: 0.8813\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 168us/step - loss: 0.2263 - accuracy: 0.9129 - val_loss: 0.2806 - val_accuracy: 0.8813\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 217us/step - loss: 0.2259 - accuracy: 0.9129 - val_loss: 0.2802 - val_accuracy: 0.8858\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 1s 506us/step - loss: 0.2257 - accuracy: 0.9139 - val_loss: 0.2800 - val_accuracy: 0.8858\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 363us/step - loss: 0.2254 - accuracy: 0.9139 - val_loss: 0.2797 - val_accuracy: 0.8858\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 201us/step - loss: 0.2250 - accuracy: 0.9139 - val_loss: 0.2795 - val_accuracy: 0.8858\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 363us/step - loss: 0.2249 - accuracy: 0.9149 - val_loss: 0.2791 - val_accuracy: 0.8858\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 293us/step - loss: 0.2246 - accuracy: 0.9139 - val_loss: 0.2790 - val_accuracy: 0.8858\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 375us/step - loss: 0.2243 - accuracy: 0.9139 - val_loss: 0.2787 - val_accuracy: 0.8858\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 287us/step - loss: 0.2241 - accuracy: 0.9139 - val_loss: 0.2787 - val_accuracy: 0.8813\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 477us/step - loss: 0.2239 - accuracy: 0.9149 - val_loss: 0.2784 - val_accuracy: 0.8813\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 256us/step - loss: 0.2236 - accuracy: 0.9149 - val_loss: 0.2781 - val_accuracy: 0.8813\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 183us/step - loss: 0.2234 - accuracy: 0.9149 - val_loss: 0.2780 - val_accuracy: 0.8813\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 222us/step - loss: 0.2232 - accuracy: 0.9149 - val_loss: 0.2778 - val_accuracy: 0.8813\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 234us/step - loss: 0.2229 - accuracy: 0.9149 - val_loss: 0.2777 - val_accuracy: 0.8813\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 207us/step - loss: 0.2227 - accuracy: 0.9159 - val_loss: 0.2776 - val_accuracy: 0.8813\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2225 - accuracy: 0.9149 - val_loss: 0.2776 - val_accuracy: 0.8813\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 204us/step - loss: 0.2223 - accuracy: 0.9159 - val_loss: 0.2776 - val_accuracy: 0.8813\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 284us/step - loss: 0.2220 - accuracy: 0.9159 - val_loss: 0.2774 - val_accuracy: 0.8813\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 242us/step - loss: 0.2219 - accuracy: 0.9168 - val_loss: 0.2773 - val_accuracy: 0.8813\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 266us/step - loss: 0.2216 - accuracy: 0.9168 - val_loss: 0.2772 - val_accuracy: 0.8813\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 993us/step - loss: 0.6558 - accuracy: 0.6106 - val_loss: 0.6150 - val_accuracy: 0.7260\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 272us/step - loss: 0.5713 - accuracy: 0.7720 - val_loss: 0.5553 - val_accuracy: 0.7991\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 262us/step - loss: 0.5151 - accuracy: 0.8151 - val_loss: 0.5146 - val_accuracy: 0.8082\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 218us/step - loss: 0.4737 - accuracy: 0.8337 - val_loss: 0.4843 - val_accuracy: 0.8174\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 322us/step - loss: 0.4415 - accuracy: 0.8434 - val_loss: 0.4615 - val_accuracy: 0.8174\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 339us/step - loss: 0.4158 - accuracy: 0.8493 - val_loss: 0.4440 - val_accuracy: 0.8174\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 179us/step - loss: 0.3947 - accuracy: 0.8523 - val_loss: 0.4300 - val_accuracy: 0.8174\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 282us/step - loss: 0.3773 - accuracy: 0.8571 - val_loss: 0.4186 - val_accuracy: 0.8219\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 213us/step - loss: 0.3627 - accuracy: 0.8679 - val_loss: 0.4093 - val_accuracy: 0.8265\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 239us/step - loss: 0.3503 - accuracy: 0.8699 - val_loss: 0.4017 - val_accuracy: 0.8311\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 199us/step - loss: 0.3395 - accuracy: 0.8738 - val_loss: 0.3953 - val_accuracy: 0.8311\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 182us/step - loss: 0.3303 - accuracy: 0.8787 - val_loss: 0.3897 - val_accuracy: 0.8311\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 242us/step - loss: 0.3220 - accuracy: 0.8826 - val_loss: 0.3849 - val_accuracy: 0.8356\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.3146 - accuracy: 0.8855 - val_loss: 0.3807 - val_accuracy: 0.8402\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.3081 - accuracy: 0.8894 - val_loss: 0.3770 - val_accuracy: 0.8402\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 196us/step - loss: 0.3022 - accuracy: 0.8914 - val_loss: 0.3735 - val_accuracy: 0.8447\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2967 - accuracy: 0.8924 - val_loss: 0.3703 - val_accuracy: 0.8539\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2920 - accuracy: 0.8933 - val_loss: 0.3675 - val_accuracy: 0.8539\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2877 - accuracy: 0.8963 - val_loss: 0.3648 - val_accuracy: 0.8539\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2836 - accuracy: 0.8953 - val_loss: 0.3620 - val_accuracy: 0.8539\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2798 - accuracy: 0.8963 - val_loss: 0.3594 - val_accuracy: 0.8493\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2765 - accuracy: 0.8963 - val_loss: 0.3570 - val_accuracy: 0.8539\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2733 - accuracy: 0.9022 - val_loss: 0.3549 - val_accuracy: 0.8539\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2705 - accuracy: 0.9002 - val_loss: 0.3528 - val_accuracy: 0.8539\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.2677 - accuracy: 0.9022 - val_loss: 0.3508 - val_accuracy: 0.8539\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2652 - accuracy: 0.9012 - val_loss: 0.3488 - val_accuracy: 0.8584\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2629 - accuracy: 0.9012 - val_loss: 0.3469 - val_accuracy: 0.8493\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2609 - accuracy: 0.9012 - val_loss: 0.3451 - val_accuracy: 0.8493\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.2588 - accuracy: 0.8982 - val_loss: 0.3434 - val_accuracy: 0.8493\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2568 - accuracy: 0.8982 - val_loss: 0.3417 - val_accuracy: 0.8493\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2551 - accuracy: 0.8973 - val_loss: 0.3400 - val_accuracy: 0.8493\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2533 - accuracy: 0.8982 - val_loss: 0.3383 - val_accuracy: 0.8493\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2516 - accuracy: 0.8973 - val_loss: 0.3366 - val_accuracy: 0.8493\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.2500 - accuracy: 0.8982 - val_loss: 0.3350 - val_accuracy: 0.8493\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.2485 - accuracy: 0.8982 - val_loss: 0.3335 - val_accuracy: 0.8539\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2473 - accuracy: 0.8982 - val_loss: 0.3322 - val_accuracy: 0.8539\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2459 - accuracy: 0.9002 - val_loss: 0.3309 - val_accuracy: 0.8493\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2448 - accuracy: 0.8973 - val_loss: 0.3295 - val_accuracy: 0.8493\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2436 - accuracy: 0.8982 - val_loss: 0.3281 - val_accuracy: 0.8493\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2426 - accuracy: 0.8992 - val_loss: 0.3268 - val_accuracy: 0.8493\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2415 - accuracy: 0.8992 - val_loss: 0.3256 - val_accuracy: 0.8493\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2406 - accuracy: 0.8982 - val_loss: 0.3244 - val_accuracy: 0.8493\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 188us/step - loss: 0.2397 - accuracy: 0.8982 - val_loss: 0.3234 - val_accuracy: 0.8493\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2389 - accuracy: 0.8982 - val_loss: 0.3223 - val_accuracy: 0.8493\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2381 - accuracy: 0.8973 - val_loss: 0.3214 - val_accuracy: 0.8493\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2373 - accuracy: 0.8973 - val_loss: 0.3204 - val_accuracy: 0.8493\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2367 - accuracy: 0.8982 - val_loss: 0.3193 - val_accuracy: 0.8493\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.2358 - accuracy: 0.9002 - val_loss: 0.3182 - val_accuracy: 0.8493\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 166us/step - loss: 0.2352 - accuracy: 0.9002 - val_loss: 0.3170 - val_accuracy: 0.8493\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2344 - accuracy: 0.9012 - val_loss: 0.3160 - val_accuracy: 0.8584\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2337 - accuracy: 0.9022 - val_loss: 0.3149 - val_accuracy: 0.8584\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2330 - accuracy: 0.9022 - val_loss: 0.3138 - val_accuracy: 0.8584\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2323 - accuracy: 0.9022 - val_loss: 0.3127 - val_accuracy: 0.8676\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2316 - accuracy: 0.9012 - val_loss: 0.3117 - val_accuracy: 0.8676\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2311 - accuracy: 0.9022 - val_loss: 0.3107 - val_accuracy: 0.8721\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2305 - accuracy: 0.9022 - val_loss: 0.3098 - val_accuracy: 0.8721\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2300 - accuracy: 0.9022 - val_loss: 0.3089 - val_accuracy: 0.8721\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2295 - accuracy: 0.9022 - val_loss: 0.3082 - val_accuracy: 0.8721\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 289us/step - loss: 0.2290 - accuracy: 0.9031 - val_loss: 0.3074 - val_accuracy: 0.8721\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 408us/step - loss: 0.2285 - accuracy: 0.9002 - val_loss: 0.3066 - val_accuracy: 0.8721\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.2280 - accuracy: 0.9022 - val_loss: 0.3058 - val_accuracy: 0.8721\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2276 - accuracy: 0.9041 - val_loss: 0.3052 - val_accuracy: 0.8721\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2272 - accuracy: 0.9031 - val_loss: 0.3045 - val_accuracy: 0.8721\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2268 - accuracy: 0.9022 - val_loss: 0.3040 - val_accuracy: 0.8721\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2264 - accuracy: 0.9041 - val_loss: 0.3035 - val_accuracy: 0.8721\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2261 - accuracy: 0.9031 - val_loss: 0.3030 - val_accuracy: 0.8721\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.2258 - accuracy: 0.9041 - val_loss: 0.3024 - val_accuracy: 0.8767\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2254 - accuracy: 0.9041 - val_loss: 0.3019 - val_accuracy: 0.8767\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2252 - accuracy: 0.9041 - val_loss: 0.3014 - val_accuracy: 0.8767\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2248 - accuracy: 0.9051 - val_loss: 0.3009 - val_accuracy: 0.8767\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 178us/step - loss: 0.2246 - accuracy: 0.9041 - val_loss: 0.3005 - val_accuracy: 0.8767\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2242 - accuracy: 0.9041 - val_loss: 0.3001 - val_accuracy: 0.8721\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2240 - accuracy: 0.9051 - val_loss: 0.2996 - val_accuracy: 0.8721\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2237 - accuracy: 0.9051 - val_loss: 0.2993 - val_accuracy: 0.8721\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2236 - accuracy: 0.9031 - val_loss: 0.2990 - val_accuracy: 0.8721\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2232 - accuracy: 0.9031 - val_loss: 0.2986 - val_accuracy: 0.8721\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2230 - accuracy: 0.9070 - val_loss: 0.2982 - val_accuracy: 0.8721\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2228 - accuracy: 0.9041 - val_loss: 0.2979 - val_accuracy: 0.8721\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.2225 - accuracy: 0.9070 - val_loss: 0.2976 - val_accuracy: 0.8721\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2223 - accuracy: 0.9080 - val_loss: 0.2972 - val_accuracy: 0.8721\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2221 - accuracy: 0.9070 - val_loss: 0.2969 - val_accuracy: 0.8721\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2220 - accuracy: 0.9080 - val_loss: 0.2966 - val_accuracy: 0.8721\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2217 - accuracy: 0.9080 - val_loss: 0.2965 - val_accuracy: 0.8721\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2216 - accuracy: 0.9080 - val_loss: 0.2962 - val_accuracy: 0.8721\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2213 - accuracy: 0.9070 - val_loss: 0.2961 - val_accuracy: 0.8721\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2211 - accuracy: 0.9090 - val_loss: 0.2958 - val_accuracy: 0.8721\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.2210 - accuracy: 0.9080 - val_loss: 0.2956 - val_accuracy: 0.8721\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2209 - accuracy: 0.9080 - val_loss: 0.2951 - val_accuracy: 0.8721\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2206 - accuracy: 0.9090 - val_loss: 0.2948 - val_accuracy: 0.8721\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2204 - accuracy: 0.9100 - val_loss: 0.2946 - val_accuracy: 0.8721\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2201 - accuracy: 0.9090 - val_loss: 0.2944 - val_accuracy: 0.8721\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 170us/step - loss: 0.2200 - accuracy: 0.9090 - val_loss: 0.2942 - val_accuracy: 0.8721\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 247us/step - loss: 0.2197 - accuracy: 0.9090 - val_loss: 0.2942 - val_accuracy: 0.8721\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 300us/step - loss: 0.2195 - accuracy: 0.9100 - val_loss: 0.2939 - val_accuracy: 0.8676\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 178us/step - loss: 0.2194 - accuracy: 0.9100 - val_loss: 0.2937 - val_accuracy: 0.8721\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 264us/step - loss: 0.2191 - accuracy: 0.9100 - val_loss: 0.2935 - val_accuracy: 0.8721\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2190 - accuracy: 0.9100 - val_loss: 0.2932 - val_accuracy: 0.8676\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2188 - accuracy: 0.9090 - val_loss: 0.2930 - val_accuracy: 0.8676\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2186 - accuracy: 0.9090 - val_loss: 0.2929 - val_accuracy: 0.8676\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2184 - accuracy: 0.9090 - val_loss: 0.2926 - val_accuracy: 0.8676\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 873us/step - loss: 0.8423 - accuracy: 0.1830 - val_loss: 0.7812 - val_accuracy: 0.2055\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 186us/step - loss: 0.7517 - accuracy: 0.2505 - val_loss: 0.7161 - val_accuracy: 0.3973\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 178us/step - loss: 0.6975 - accuracy: 0.4550 - val_loss: 0.6731 - val_accuracy: 0.5616\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.6611 - accuracy: 0.5822 - val_loss: 0.6412 - val_accuracy: 0.6621\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 367us/step - loss: 0.6333 - accuracy: 0.6634 - val_loss: 0.6155 - val_accuracy: 0.7352\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 209us/step - loss: 0.6100 - accuracy: 0.7348 - val_loss: 0.5929 - val_accuracy: 0.7717\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 178us/step - loss: 0.5889 - accuracy: 0.7720 - val_loss: 0.5724 - val_accuracy: 0.8082\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.5695 - accuracy: 0.8023 - val_loss: 0.5530 - val_accuracy: 0.8356\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.5508 - accuracy: 0.8219 - val_loss: 0.5346 - val_accuracy: 0.8539\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.5326 - accuracy: 0.8297 - val_loss: 0.5168 - val_accuracy: 0.8676\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.5147 - accuracy: 0.8405 - val_loss: 0.4996 - val_accuracy: 0.8676\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.4969 - accuracy: 0.8493 - val_loss: 0.4826 - val_accuracy: 0.8676\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.4792 - accuracy: 0.8532 - val_loss: 0.4658 - val_accuracy: 0.8721\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.4617 - accuracy: 0.8581 - val_loss: 0.4495 - val_accuracy: 0.8767\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.4443 - accuracy: 0.8591 - val_loss: 0.4337 - val_accuracy: 0.8767\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.4273 - accuracy: 0.8630 - val_loss: 0.4184 - val_accuracy: 0.8767\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 180us/step - loss: 0.4105 - accuracy: 0.8650 - val_loss: 0.4038 - val_accuracy: 0.8813\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.3945 - accuracy: 0.8689 - val_loss: 0.3900 - val_accuracy: 0.8767\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.3793 - accuracy: 0.8718 - val_loss: 0.3770 - val_accuracy: 0.8858\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 191us/step - loss: 0.3651 - accuracy: 0.8757 - val_loss: 0.3651 - val_accuracy: 0.8858\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.3520 - accuracy: 0.8767 - val_loss: 0.3545 - val_accuracy: 0.8858\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.3402 - accuracy: 0.8787 - val_loss: 0.3451 - val_accuracy: 0.8858\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.3294 - accuracy: 0.8816 - val_loss: 0.3369 - val_accuracy: 0.8904\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.3197 - accuracy: 0.8836 - val_loss: 0.3299 - val_accuracy: 0.8950\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.3112 - accuracy: 0.8855 - val_loss: 0.3241 - val_accuracy: 0.8904\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.3037 - accuracy: 0.8875 - val_loss: 0.3192 - val_accuracy: 0.8858\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2970 - accuracy: 0.8875 - val_loss: 0.3150 - val_accuracy: 0.8904\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2912 - accuracy: 0.8894 - val_loss: 0.3114 - val_accuracy: 0.8904\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2860 - accuracy: 0.8924 - val_loss: 0.3085 - val_accuracy: 0.8904\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.2815 - accuracy: 0.8924 - val_loss: 0.3060 - val_accuracy: 0.8904\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2776 - accuracy: 0.8973 - val_loss: 0.3040 - val_accuracy: 0.8904\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2740 - accuracy: 0.8982 - val_loss: 0.3025 - val_accuracy: 0.8904\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2709 - accuracy: 0.9002 - val_loss: 0.3012 - val_accuracy: 0.8858\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2680 - accuracy: 0.8992 - val_loss: 0.3001 - val_accuracy: 0.8858\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2655 - accuracy: 0.9022 - val_loss: 0.2991 - val_accuracy: 0.8858\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2632 - accuracy: 0.9022 - val_loss: 0.2982 - val_accuracy: 0.8858\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2612 - accuracy: 0.9031 - val_loss: 0.2975 - val_accuracy: 0.8858\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2592 - accuracy: 0.9041 - val_loss: 0.2969 - val_accuracy: 0.8858\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2575 - accuracy: 0.9031 - val_loss: 0.2965 - val_accuracy: 0.8813\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2560 - accuracy: 0.9022 - val_loss: 0.2960 - val_accuracy: 0.8858\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2545 - accuracy: 0.9022 - val_loss: 0.2957 - val_accuracy: 0.8858\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2531 - accuracy: 0.9002 - val_loss: 0.2954 - val_accuracy: 0.8858\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2519 - accuracy: 0.9012 - val_loss: 0.2951 - val_accuracy: 0.8858\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2509 - accuracy: 0.9002 - val_loss: 0.2948 - val_accuracy: 0.8858\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2498 - accuracy: 0.9002 - val_loss: 0.2945 - val_accuracy: 0.8858\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2487 - accuracy: 0.9002 - val_loss: 0.2941 - val_accuracy: 0.8858\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2478 - accuracy: 0.9002 - val_loss: 0.2938 - val_accuracy: 0.8858\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2470 - accuracy: 0.9012 - val_loss: 0.2934 - val_accuracy: 0.8858\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2462 - accuracy: 0.9022 - val_loss: 0.2930 - val_accuracy: 0.8858\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2454 - accuracy: 0.9022 - val_loss: 0.2926 - val_accuracy: 0.8858\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2446 - accuracy: 0.9022 - val_loss: 0.2923 - val_accuracy: 0.8858\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2439 - accuracy: 0.9022 - val_loss: 0.2920 - val_accuracy: 0.8813\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2432 - accuracy: 0.9022 - val_loss: 0.2916 - val_accuracy: 0.8813\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2426 - accuracy: 0.9012 - val_loss: 0.2912 - val_accuracy: 0.8813\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2420 - accuracy: 0.9012 - val_loss: 0.2908 - val_accuracy: 0.8813\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2414 - accuracy: 0.9012 - val_loss: 0.2904 - val_accuracy: 0.8813\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2409 - accuracy: 0.9022 - val_loss: 0.2901 - val_accuracy: 0.8813\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2402 - accuracy: 0.9022 - val_loss: 0.2897 - val_accuracy: 0.8858\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2398 - accuracy: 0.9022 - val_loss: 0.2893 - val_accuracy: 0.8858\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2393 - accuracy: 0.9022 - val_loss: 0.2891 - val_accuracy: 0.8858\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2387 - accuracy: 0.9022 - val_loss: 0.2889 - val_accuracy: 0.8858\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2382 - accuracy: 0.9022 - val_loss: 0.2886 - val_accuracy: 0.8858\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2378 - accuracy: 0.9022 - val_loss: 0.2883 - val_accuracy: 0.8858\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2373 - accuracy: 0.9031 - val_loss: 0.2880 - val_accuracy: 0.8858\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.2369 - accuracy: 0.9031 - val_loss: 0.2878 - val_accuracy: 0.8858\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2364 - accuracy: 0.9041 - val_loss: 0.2875 - val_accuracy: 0.8767\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2361 - accuracy: 0.9031 - val_loss: 0.2873 - val_accuracy: 0.8767\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2356 - accuracy: 0.9031 - val_loss: 0.2870 - val_accuracy: 0.8767\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2352 - accuracy: 0.9031 - val_loss: 0.2867 - val_accuracy: 0.8767\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2348 - accuracy: 0.9031 - val_loss: 0.2865 - val_accuracy: 0.8767\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2345 - accuracy: 0.9022 - val_loss: 0.2863 - val_accuracy: 0.8767\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2341 - accuracy: 0.9031 - val_loss: 0.2860 - val_accuracy: 0.8767\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2338 - accuracy: 0.9041 - val_loss: 0.2857 - val_accuracy: 0.8767\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2334 - accuracy: 0.9031 - val_loss: 0.2855 - val_accuracy: 0.8767\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.2331 - accuracy: 0.9031 - val_loss: 0.2852 - val_accuracy: 0.8767\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2327 - accuracy: 0.9031 - val_loss: 0.2849 - val_accuracy: 0.8721\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2325 - accuracy: 0.9031 - val_loss: 0.2846 - val_accuracy: 0.8721\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2322 - accuracy: 0.9022 - val_loss: 0.2843 - val_accuracy: 0.8721\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2319 - accuracy: 0.9031 - val_loss: 0.2840 - val_accuracy: 0.8721\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.2316 - accuracy: 0.9022 - val_loss: 0.2836 - val_accuracy: 0.8721\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2314 - accuracy: 0.9022 - val_loss: 0.2833 - val_accuracy: 0.8721\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2311 - accuracy: 0.9031 - val_loss: 0.2830 - val_accuracy: 0.8721\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2309 - accuracy: 0.9041 - val_loss: 0.2828 - val_accuracy: 0.8721\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 166us/step - loss: 0.2306 - accuracy: 0.9031 - val_loss: 0.2824 - val_accuracy: 0.8721\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2303 - accuracy: 0.9031 - val_loss: 0.2821 - val_accuracy: 0.8721\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.2300 - accuracy: 0.9031 - val_loss: 0.2817 - val_accuracy: 0.8721\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2299 - accuracy: 0.9051 - val_loss: 0.2814 - val_accuracy: 0.8721\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2296 - accuracy: 0.9041 - val_loss: 0.2810 - val_accuracy: 0.8721\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2295 - accuracy: 0.9041 - val_loss: 0.2806 - val_accuracy: 0.8721\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2292 - accuracy: 0.9041 - val_loss: 0.2802 - val_accuracy: 0.8721\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2290 - accuracy: 0.9041 - val_loss: 0.2798 - val_accuracy: 0.8721\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2287 - accuracy: 0.9031 - val_loss: 0.2794 - val_accuracy: 0.8721\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2286 - accuracy: 0.9061 - val_loss: 0.2791 - val_accuracy: 0.8721\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2282 - accuracy: 0.9061 - val_loss: 0.2788 - val_accuracy: 0.8721\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2280 - accuracy: 0.9061 - val_loss: 0.2784 - val_accuracy: 0.8721\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 178us/step - loss: 0.2278 - accuracy: 0.9061 - val_loss: 0.2781 - val_accuracy: 0.8721\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2275 - accuracy: 0.9061 - val_loss: 0.2779 - val_accuracy: 0.8721\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.2274 - accuracy: 0.9061 - val_loss: 0.2775 - val_accuracy: 0.8721\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.2271 - accuracy: 0.9070 - val_loss: 0.2772 - val_accuracy: 0.8721\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.2269 - accuracy: 0.9061 - val_loss: 0.2768 - val_accuracy: 0.8721\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 790us/step - loss: 0.6527 - accuracy: 0.6477 - val_loss: 0.6442 - val_accuracy: 0.7078\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.6156 - accuracy: 0.7524 - val_loss: 0.6113 - val_accuracy: 0.7900\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.5808 - accuracy: 0.8131 - val_loss: 0.5793 - val_accuracy: 0.8082\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.5471 - accuracy: 0.8415 - val_loss: 0.5481 - val_accuracy: 0.8265\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.5140 - accuracy: 0.8620 - val_loss: 0.5175 - val_accuracy: 0.8539\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.4818 - accuracy: 0.8718 - val_loss: 0.4882 - val_accuracy: 0.8539\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.4512 - accuracy: 0.8826 - val_loss: 0.4606 - val_accuracy: 0.8630\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.4229 - accuracy: 0.8855 - val_loss: 0.4352 - val_accuracy: 0.8721\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.3972 - accuracy: 0.8865 - val_loss: 0.4124 - val_accuracy: 0.8858\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.3745 - accuracy: 0.8875 - val_loss: 0.3924 - val_accuracy: 0.8858\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.3546 - accuracy: 0.8894 - val_loss: 0.3753 - val_accuracy: 0.8813\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.3377 - accuracy: 0.8933 - val_loss: 0.3610 - val_accuracy: 0.8767\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.3230 - accuracy: 0.8992 - val_loss: 0.3488 - val_accuracy: 0.8767\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.3105 - accuracy: 0.8982 - val_loss: 0.3388 - val_accuracy: 0.8767\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2997 - accuracy: 0.8963 - val_loss: 0.3304 - val_accuracy: 0.8767\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.2905 - accuracy: 0.8982 - val_loss: 0.3235 - val_accuracy: 0.8767\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2826 - accuracy: 0.9002 - val_loss: 0.3182 - val_accuracy: 0.8767\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.2759 - accuracy: 0.8992 - val_loss: 0.3136 - val_accuracy: 0.8767\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.2701 - accuracy: 0.8982 - val_loss: 0.3100 - val_accuracy: 0.8767\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 173us/step - loss: 0.2651 - accuracy: 0.8982 - val_loss: 0.3069 - val_accuracy: 0.8767\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2608 - accuracy: 0.8982 - val_loss: 0.3043 - val_accuracy: 0.8721\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2572 - accuracy: 0.8973 - val_loss: 0.3021 - val_accuracy: 0.8721\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2539 - accuracy: 0.8982 - val_loss: 0.3002 - val_accuracy: 0.8721\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2511 - accuracy: 0.9002 - val_loss: 0.2988 - val_accuracy: 0.8721\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2485 - accuracy: 0.8992 - val_loss: 0.2972 - val_accuracy: 0.8630\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2463 - accuracy: 0.9012 - val_loss: 0.2961 - val_accuracy: 0.8676\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2443 - accuracy: 0.9022 - val_loss: 0.2950 - val_accuracy: 0.8676\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2425 - accuracy: 0.9022 - val_loss: 0.2940 - val_accuracy: 0.8721\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 167us/step - loss: 0.2410 - accuracy: 0.9012 - val_loss: 0.2932 - val_accuracy: 0.8721\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 175us/step - loss: 0.2396 - accuracy: 0.9002 - val_loss: 0.2923 - val_accuracy: 0.8721\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 187us/step - loss: 0.2383 - accuracy: 0.9002 - val_loss: 0.2916 - val_accuracy: 0.8721\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2370 - accuracy: 0.9002 - val_loss: 0.2909 - val_accuracy: 0.8676\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2359 - accuracy: 0.9012 - val_loss: 0.2903 - val_accuracy: 0.8676\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 175us/step - loss: 0.2349 - accuracy: 0.9012 - val_loss: 0.2896 - val_accuracy: 0.8676\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2340 - accuracy: 0.9012 - val_loss: 0.2890 - val_accuracy: 0.8676\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 173us/step - loss: 0.2331 - accuracy: 0.9012 - val_loss: 0.2884 - val_accuracy: 0.8676\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.2323 - accuracy: 0.9012 - val_loss: 0.2878 - val_accuracy: 0.8676\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2315 - accuracy: 0.9022 - val_loss: 0.2872 - val_accuracy: 0.8676\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2307 - accuracy: 0.9012 - val_loss: 0.2868 - val_accuracy: 0.8676\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2302 - accuracy: 0.9022 - val_loss: 0.2863 - val_accuracy: 0.8676\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2295 - accuracy: 0.9012 - val_loss: 0.2857 - val_accuracy: 0.8676\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2289 - accuracy: 0.9012 - val_loss: 0.2855 - val_accuracy: 0.8676\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2283 - accuracy: 0.9002 - val_loss: 0.2851 - val_accuracy: 0.8676\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2277 - accuracy: 0.9012 - val_loss: 0.2848 - val_accuracy: 0.8676\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2272 - accuracy: 0.9012 - val_loss: 0.2843 - val_accuracy: 0.8676\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2266 - accuracy: 0.9012 - val_loss: 0.2839 - val_accuracy: 0.8676\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2262 - accuracy: 0.9012 - val_loss: 0.2835 - val_accuracy: 0.8676\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2256 - accuracy: 0.9012 - val_loss: 0.2829 - val_accuracy: 0.8630\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2251 - accuracy: 0.9012 - val_loss: 0.2824 - val_accuracy: 0.8584\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 178us/step - loss: 0.2248 - accuracy: 0.9002 - val_loss: 0.2819 - val_accuracy: 0.8584\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2244 - accuracy: 0.9002 - val_loss: 0.2814 - val_accuracy: 0.8676\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2239 - accuracy: 0.9002 - val_loss: 0.2811 - val_accuracy: 0.8676\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2235 - accuracy: 0.9002 - val_loss: 0.2807 - val_accuracy: 0.8676\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2231 - accuracy: 0.9012 - val_loss: 0.2805 - val_accuracy: 0.8630\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2228 - accuracy: 0.9012 - val_loss: 0.2802 - val_accuracy: 0.8630\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2224 - accuracy: 0.9012 - val_loss: 0.2799 - val_accuracy: 0.8630\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2221 - accuracy: 0.9022 - val_loss: 0.2794 - val_accuracy: 0.8676\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2218 - accuracy: 0.9022 - val_loss: 0.2792 - val_accuracy: 0.8676\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 167us/step - loss: 0.2213 - accuracy: 0.9022 - val_loss: 0.2789 - val_accuracy: 0.8676\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2211 - accuracy: 0.9022 - val_loss: 0.2786 - val_accuracy: 0.8676\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2207 - accuracy: 0.9022 - val_loss: 0.2782 - val_accuracy: 0.8676\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2205 - accuracy: 0.9022 - val_loss: 0.2780 - val_accuracy: 0.8676\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2201 - accuracy: 0.9031 - val_loss: 0.2778 - val_accuracy: 0.8721\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.2199 - accuracy: 0.9031 - val_loss: 0.2776 - val_accuracy: 0.8721\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2196 - accuracy: 0.9041 - val_loss: 0.2772 - val_accuracy: 0.8721\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2194 - accuracy: 0.9031 - val_loss: 0.2770 - val_accuracy: 0.8721\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.2191 - accuracy: 0.9051 - val_loss: 0.2769 - val_accuracy: 0.8721\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2189 - accuracy: 0.9031 - val_loss: 0.2767 - val_accuracy: 0.8721\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2185 - accuracy: 0.9041 - val_loss: 0.2766 - val_accuracy: 0.8721\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2184 - accuracy: 0.9041 - val_loss: 0.2764 - val_accuracy: 0.8721\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2181 - accuracy: 0.9041 - val_loss: 0.2762 - val_accuracy: 0.8721\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2179 - accuracy: 0.9051 - val_loss: 0.2760 - val_accuracy: 0.8721\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2176 - accuracy: 0.9061 - val_loss: 0.2757 - val_accuracy: 0.8721\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 167us/step - loss: 0.2175 - accuracy: 0.9051 - val_loss: 0.2755 - val_accuracy: 0.8721\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2171 - accuracy: 0.9051 - val_loss: 0.2752 - val_accuracy: 0.8721\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2169 - accuracy: 0.9051 - val_loss: 0.2751 - val_accuracy: 0.8721\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2166 - accuracy: 0.9051 - val_loss: 0.2747 - val_accuracy: 0.8721\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2165 - accuracy: 0.9051 - val_loss: 0.2745 - val_accuracy: 0.8721\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2162 - accuracy: 0.9041 - val_loss: 0.2744 - val_accuracy: 0.8721\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2160 - accuracy: 0.9061 - val_loss: 0.2741 - val_accuracy: 0.8721\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 181us/step - loss: 0.2157 - accuracy: 0.9031 - val_loss: 0.2739 - val_accuracy: 0.8721\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2156 - accuracy: 0.9070 - val_loss: 0.2736 - val_accuracy: 0.8721\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2152 - accuracy: 0.9061 - val_loss: 0.2734 - val_accuracy: 0.8721\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2151 - accuracy: 0.9031 - val_loss: 0.2734 - val_accuracy: 0.8676\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2148 - accuracy: 0.9051 - val_loss: 0.2732 - val_accuracy: 0.8676\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2147 - accuracy: 0.9041 - val_loss: 0.2731 - val_accuracy: 0.8676\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2145 - accuracy: 0.9041 - val_loss: 0.2729 - val_accuracy: 0.8676\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2144 - accuracy: 0.9070 - val_loss: 0.2727 - val_accuracy: 0.8676\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2141 - accuracy: 0.9041 - val_loss: 0.2725 - val_accuracy: 0.8676\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2139 - accuracy: 0.9041 - val_loss: 0.2725 - val_accuracy: 0.8676\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 170us/step - loss: 0.2137 - accuracy: 0.9070 - val_loss: 0.2722 - val_accuracy: 0.8676\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2136 - accuracy: 0.9051 - val_loss: 0.2719 - val_accuracy: 0.8676\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2134 - accuracy: 0.9051 - val_loss: 0.2717 - val_accuracy: 0.8676\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2132 - accuracy: 0.9061 - val_loss: 0.2715 - val_accuracy: 0.8676\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2129 - accuracy: 0.9061 - val_loss: 0.2712 - val_accuracy: 0.8676\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2129 - accuracy: 0.9061 - val_loss: 0.2709 - val_accuracy: 0.8676\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2127 - accuracy: 0.9070 - val_loss: 0.2707 - val_accuracy: 0.8676\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.2124 - accuracy: 0.9061 - val_loss: 0.2705 - val_accuracy: 0.8676\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2122 - accuracy: 0.9080 - val_loss: 0.2703 - val_accuracy: 0.8676\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2120 - accuracy: 0.9090 - val_loss: 0.2701 - val_accuracy: 0.8676\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 865us/step - loss: 0.7025 - accuracy: 0.4853 - val_loss: 0.6788 - val_accuracy: 0.5753\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.6480 - accuracy: 0.6301 - val_loss: 0.6308 - val_accuracy: 0.7169\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.6031 - accuracy: 0.7280 - val_loss: 0.5914 - val_accuracy: 0.7489\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.5630 - accuracy: 0.7828 - val_loss: 0.5567 - val_accuracy: 0.7717\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 94us/step - loss: 0.5267 - accuracy: 0.8092 - val_loss: 0.5258 - val_accuracy: 0.7945\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.4936 - accuracy: 0.8297 - val_loss: 0.4971 - val_accuracy: 0.8265\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.4633 - accuracy: 0.8444 - val_loss: 0.4711 - val_accuracy: 0.8128\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.4356 - accuracy: 0.8591 - val_loss: 0.4480 - val_accuracy: 0.8174\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.4106 - accuracy: 0.8620 - val_loss: 0.4276 - val_accuracy: 0.8265\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.3882 - accuracy: 0.8640 - val_loss: 0.4099 - val_accuracy: 0.8219\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 223us/step - loss: 0.3683 - accuracy: 0.8669 - val_loss: 0.3949 - val_accuracy: 0.8311\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.3511 - accuracy: 0.8738 - val_loss: 0.3825 - val_accuracy: 0.8265\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.3363 - accuracy: 0.8767 - val_loss: 0.3722 - val_accuracy: 0.8402\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.3235 - accuracy: 0.8826 - val_loss: 0.3639 - val_accuracy: 0.8402\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.3125 - accuracy: 0.8855 - val_loss: 0.3570 - val_accuracy: 0.8402\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.3032 - accuracy: 0.8865 - val_loss: 0.3512 - val_accuracy: 0.8402\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2952 - accuracy: 0.8875 - val_loss: 0.3464 - val_accuracy: 0.8402\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2884 - accuracy: 0.8904 - val_loss: 0.3425 - val_accuracy: 0.8447\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2827 - accuracy: 0.8953 - val_loss: 0.3392 - val_accuracy: 0.8493\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2777 - accuracy: 0.8943 - val_loss: 0.3364 - val_accuracy: 0.8493\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.2732 - accuracy: 0.8933 - val_loss: 0.3338 - val_accuracy: 0.8447\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2693 - accuracy: 0.8943 - val_loss: 0.3316 - val_accuracy: 0.8447\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2661 - accuracy: 0.8973 - val_loss: 0.3298 - val_accuracy: 0.8493\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2630 - accuracy: 0.8963 - val_loss: 0.3281 - val_accuracy: 0.8539\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2603 - accuracy: 0.8992 - val_loss: 0.3267 - val_accuracy: 0.8539\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2580 - accuracy: 0.8963 - val_loss: 0.3254 - val_accuracy: 0.8447\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2557 - accuracy: 0.8973 - val_loss: 0.3242 - val_accuracy: 0.8447\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2539 - accuracy: 0.8982 - val_loss: 0.3230 - val_accuracy: 0.8447\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2521 - accuracy: 0.8953 - val_loss: 0.3220 - val_accuracy: 0.8493\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2506 - accuracy: 0.8973 - val_loss: 0.3210 - val_accuracy: 0.8539\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2490 - accuracy: 0.8982 - val_loss: 0.3199 - val_accuracy: 0.8539\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2476 - accuracy: 0.8982 - val_loss: 0.3188 - val_accuracy: 0.8539\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2462 - accuracy: 0.8982 - val_loss: 0.3177 - val_accuracy: 0.8539\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2449 - accuracy: 0.8982 - val_loss: 0.3166 - val_accuracy: 0.8539\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2436 - accuracy: 0.9022 - val_loss: 0.3154 - val_accuracy: 0.8539\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2425 - accuracy: 0.9031 - val_loss: 0.3142 - val_accuracy: 0.8584\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2414 - accuracy: 0.9031 - val_loss: 0.3133 - val_accuracy: 0.8584\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 184us/step - loss: 0.2404 - accuracy: 0.9051 - val_loss: 0.3124 - val_accuracy: 0.8584\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2394 - accuracy: 0.9051 - val_loss: 0.3114 - val_accuracy: 0.8584\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 187us/step - loss: 0.2385 - accuracy: 0.9051 - val_loss: 0.3105 - val_accuracy: 0.8584\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.2377 - accuracy: 0.9061 - val_loss: 0.3095 - val_accuracy: 0.8584\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2369 - accuracy: 0.9051 - val_loss: 0.3087 - val_accuracy: 0.8630\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2361 - accuracy: 0.9051 - val_loss: 0.3077 - val_accuracy: 0.8630\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2354 - accuracy: 0.9061 - val_loss: 0.3068 - val_accuracy: 0.8630\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.2347 - accuracy: 0.9061 - val_loss: 0.3058 - val_accuracy: 0.8630\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 174us/step - loss: 0.2340 - accuracy: 0.9061 - val_loss: 0.3048 - val_accuracy: 0.8630\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 180us/step - loss: 0.2333 - accuracy: 0.9051 - val_loss: 0.3040 - val_accuracy: 0.8630\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.2326 - accuracy: 0.9061 - val_loss: 0.3030 - val_accuracy: 0.8630\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2320 - accuracy: 0.9051 - val_loss: 0.3022 - val_accuracy: 0.8630\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2315 - accuracy: 0.9051 - val_loss: 0.3014 - val_accuracy: 0.8630\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2307 - accuracy: 0.9051 - val_loss: 0.3007 - val_accuracy: 0.8630\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 190us/step - loss: 0.2299 - accuracy: 0.9041 - val_loss: 0.3000 - val_accuracy: 0.8630\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2296 - accuracy: 0.9041 - val_loss: 0.2993 - val_accuracy: 0.8630\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2290 - accuracy: 0.9041 - val_loss: 0.2986 - val_accuracy: 0.8630\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2284 - accuracy: 0.9051 - val_loss: 0.2979 - val_accuracy: 0.8630\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2278 - accuracy: 0.9051 - val_loss: 0.2971 - val_accuracy: 0.8584\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2273 - accuracy: 0.9041 - val_loss: 0.2963 - val_accuracy: 0.8584\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2268 - accuracy: 0.9041 - val_loss: 0.2957 - val_accuracy: 0.8584\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.2262 - accuracy: 0.9041 - val_loss: 0.2950 - val_accuracy: 0.8584\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2257 - accuracy: 0.9051 - val_loss: 0.2944 - val_accuracy: 0.8584\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2254 - accuracy: 0.9051 - val_loss: 0.2938 - val_accuracy: 0.8584\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2248 - accuracy: 0.9061 - val_loss: 0.2931 - val_accuracy: 0.8676\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2244 - accuracy: 0.9080 - val_loss: 0.2924 - val_accuracy: 0.8676\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2238 - accuracy: 0.9080 - val_loss: 0.2919 - val_accuracy: 0.8676\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.2234 - accuracy: 0.9080 - val_loss: 0.2914 - val_accuracy: 0.8721\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 177us/step - loss: 0.2230 - accuracy: 0.9090 - val_loss: 0.2909 - val_accuracy: 0.8721\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2225 - accuracy: 0.9100 - val_loss: 0.2903 - val_accuracy: 0.8721\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2221 - accuracy: 0.9090 - val_loss: 0.2900 - val_accuracy: 0.8721\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2217 - accuracy: 0.9100 - val_loss: 0.2896 - val_accuracy: 0.8721\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2214 - accuracy: 0.9100 - val_loss: 0.2891 - val_accuracy: 0.8676\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2211 - accuracy: 0.9100 - val_loss: 0.2886 - val_accuracy: 0.8676\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2205 - accuracy: 0.9090 - val_loss: 0.2884 - val_accuracy: 0.8676\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2203 - accuracy: 0.9090 - val_loss: 0.2880 - val_accuracy: 0.8767\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2199 - accuracy: 0.9090 - val_loss: 0.2878 - val_accuracy: 0.8767\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 180us/step - loss: 0.2196 - accuracy: 0.9090 - val_loss: 0.2876 - val_accuracy: 0.8767\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2194 - accuracy: 0.9110 - val_loss: 0.2871 - val_accuracy: 0.8721\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.2191 - accuracy: 0.9090 - val_loss: 0.2870 - val_accuracy: 0.8721\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 170us/step - loss: 0.2187 - accuracy: 0.9110 - val_loss: 0.2867 - val_accuracy: 0.8721\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2183 - accuracy: 0.9100 - val_loss: 0.2864 - val_accuracy: 0.8721\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 169us/step - loss: 0.2181 - accuracy: 0.9090 - val_loss: 0.2863 - val_accuracy: 0.8767\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 166us/step - loss: 0.2178 - accuracy: 0.9100 - val_loss: 0.2860 - val_accuracy: 0.8721\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 187us/step - loss: 0.2177 - accuracy: 0.9090 - val_loss: 0.2856 - val_accuracy: 0.8721\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2173 - accuracy: 0.9110 - val_loss: 0.2853 - val_accuracy: 0.8721\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2169 - accuracy: 0.9100 - val_loss: 0.2850 - val_accuracy: 0.8721\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2165 - accuracy: 0.9119 - val_loss: 0.2848 - val_accuracy: 0.8767\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 164us/step - loss: 0.2163 - accuracy: 0.9100 - val_loss: 0.2845 - val_accuracy: 0.8767\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2159 - accuracy: 0.9119 - val_loss: 0.2841 - val_accuracy: 0.8767\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2158 - accuracy: 0.9129 - val_loss: 0.2838 - val_accuracy: 0.8767\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2154 - accuracy: 0.9119 - val_loss: 0.2835 - val_accuracy: 0.8767\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.2152 - accuracy: 0.9119 - val_loss: 0.2833 - val_accuracy: 0.8767\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2148 - accuracy: 0.9110 - val_loss: 0.2829 - val_accuracy: 0.8767\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2146 - accuracy: 0.9119 - val_loss: 0.2826 - val_accuracy: 0.8767\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - ETA: 0s - loss: 0.2415 - accuracy: 0.89 - 0s 190us/step - loss: 0.2144 - accuracy: 0.9110 - val_loss: 0.2824 - val_accuracy: 0.8767\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 317us/step - loss: 0.2140 - accuracy: 0.9119 - val_loss: 0.2821 - val_accuracy: 0.8767\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 312us/step - loss: 0.2138 - accuracy: 0.9119 - val_loss: 0.2817 - val_accuracy: 0.8767\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 187us/step - loss: 0.2135 - accuracy: 0.9129 - val_loss: 0.2814 - val_accuracy: 0.8767\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 432us/step - loss: 0.2132 - accuracy: 0.9129 - val_loss: 0.2812 - val_accuracy: 0.8767\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2129 - accuracy: 0.9119 - val_loss: 0.2808 - val_accuracy: 0.8767\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2126 - accuracy: 0.9129 - val_loss: 0.2805 - val_accuracy: 0.8767\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2125 - accuracy: 0.9129 - val_loss: 0.2803 - val_accuracy: 0.8767\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 1s 889us/step - loss: 0.6757 - accuracy: 0.5822 - val_loss: 0.6809 - val_accuracy: 0.5845\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.6256 - accuracy: 0.6663 - val_loss: 0.6418 - val_accuracy: 0.6301\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.5894 - accuracy: 0.7074 - val_loss: 0.6110 - val_accuracy: 0.6575\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.5587 - accuracy: 0.7544 - val_loss: 0.5849 - val_accuracy: 0.6941\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.5305 - accuracy: 0.7828 - val_loss: 0.5608 - val_accuracy: 0.7123\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.5040 - accuracy: 0.8004 - val_loss: 0.5384 - val_accuracy: 0.7397\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.4788 - accuracy: 0.8121 - val_loss: 0.5174 - val_accuracy: 0.7671\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.4550 - accuracy: 0.8229 - val_loss: 0.4984 - val_accuracy: 0.7763\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.4332 - accuracy: 0.8386 - val_loss: 0.4814 - val_accuracy: 0.7900\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.4135 - accuracy: 0.8454 - val_loss: 0.4659 - val_accuracy: 0.7991\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.3958 - accuracy: 0.8513 - val_loss: 0.4521 - val_accuracy: 0.8037\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.3799 - accuracy: 0.8552 - val_loss: 0.4398 - val_accuracy: 0.8037\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.3659 - accuracy: 0.8620 - val_loss: 0.4289 - val_accuracy: 0.8174\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.3534 - accuracy: 0.8630 - val_loss: 0.4192 - val_accuracy: 0.8219\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.3424 - accuracy: 0.8659 - val_loss: 0.4106 - val_accuracy: 0.8174\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.3324 - accuracy: 0.8679 - val_loss: 0.4028 - val_accuracy: 0.8219\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.3236 - accuracy: 0.8708 - val_loss: 0.3957 - val_accuracy: 0.8219\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.3158 - accuracy: 0.8728 - val_loss: 0.3895 - val_accuracy: 0.8265\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.3089 - accuracy: 0.8757 - val_loss: 0.3840 - val_accuracy: 0.8265\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.3027 - accuracy: 0.8777 - val_loss: 0.3790 - val_accuracy: 0.8265\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2972 - accuracy: 0.8777 - val_loss: 0.3745 - val_accuracy: 0.8219\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2922 - accuracy: 0.8796 - val_loss: 0.3703 - val_accuracy: 0.8311\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2878 - accuracy: 0.8816 - val_loss: 0.3665 - val_accuracy: 0.8402\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2837 - accuracy: 0.8845 - val_loss: 0.3630 - val_accuracy: 0.8402\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2798 - accuracy: 0.8855 - val_loss: 0.3597 - val_accuracy: 0.8356\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2763 - accuracy: 0.8865 - val_loss: 0.3567 - val_accuracy: 0.8356\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2731 - accuracy: 0.8875 - val_loss: 0.3540 - val_accuracy: 0.8356\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2702 - accuracy: 0.8904 - val_loss: 0.3515 - val_accuracy: 0.8356\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2674 - accuracy: 0.8914 - val_loss: 0.3491 - val_accuracy: 0.8356\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2650 - accuracy: 0.8943 - val_loss: 0.3470 - val_accuracy: 0.8402\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2626 - accuracy: 0.8953 - val_loss: 0.3450 - val_accuracy: 0.8402\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2606 - accuracy: 0.8953 - val_loss: 0.3432 - val_accuracy: 0.8402\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.2585 - accuracy: 0.8963 - val_loss: 0.3414 - val_accuracy: 0.8402\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2568 - accuracy: 0.8973 - val_loss: 0.3398 - val_accuracy: 0.8402\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.2549 - accuracy: 0.8973 - val_loss: 0.3382 - val_accuracy: 0.8447\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2532 - accuracy: 0.9012 - val_loss: 0.3367 - val_accuracy: 0.8447\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.2517 - accuracy: 0.9002 - val_loss: 0.3353 - val_accuracy: 0.8447\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2501 - accuracy: 0.9012 - val_loss: 0.3339 - val_accuracy: 0.8447\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2487 - accuracy: 0.9012 - val_loss: 0.3327 - val_accuracy: 0.8493\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2475 - accuracy: 0.9022 - val_loss: 0.3314 - val_accuracy: 0.8447\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2461 - accuracy: 0.9002 - val_loss: 0.3302 - val_accuracy: 0.8447\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.2450 - accuracy: 0.9022 - val_loss: 0.3291 - val_accuracy: 0.8402\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2438 - accuracy: 0.9012 - val_loss: 0.3280 - val_accuracy: 0.8402\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2427 - accuracy: 0.8992 - val_loss: 0.3270 - val_accuracy: 0.8402\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2416 - accuracy: 0.9012 - val_loss: 0.3260 - val_accuracy: 0.8402\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2407 - accuracy: 0.9012 - val_loss: 0.3251 - val_accuracy: 0.8402\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2399 - accuracy: 0.9002 - val_loss: 0.3243 - val_accuracy: 0.8402\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2389 - accuracy: 0.9012 - val_loss: 0.3234 - val_accuracy: 0.8447\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.2381 - accuracy: 0.9012 - val_loss: 0.3226 - val_accuracy: 0.8447\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.2373 - accuracy: 0.9002 - val_loss: 0.3218 - val_accuracy: 0.8447\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.2368 - accuracy: 0.9002 - val_loss: 0.3210 - val_accuracy: 0.8447\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2359 - accuracy: 0.9031 - val_loss: 0.3203 - val_accuracy: 0.8447\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2353 - accuracy: 0.9031 - val_loss: 0.3195 - val_accuracy: 0.8402\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2346 - accuracy: 0.9031 - val_loss: 0.3187 - val_accuracy: 0.8402\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2340 - accuracy: 0.9041 - val_loss: 0.3180 - val_accuracy: 0.8402\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2335 - accuracy: 0.9051 - val_loss: 0.3173 - val_accuracy: 0.8402\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2329 - accuracy: 0.9051 - val_loss: 0.3166 - val_accuracy: 0.8447\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2324 - accuracy: 0.9061 - val_loss: 0.3159 - val_accuracy: 0.8447\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2318 - accuracy: 0.9051 - val_loss: 0.3152 - val_accuracy: 0.8447\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.2313 - accuracy: 0.9051 - val_loss: 0.3146 - val_accuracy: 0.8447\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2307 - accuracy: 0.9070 - val_loss: 0.3139 - val_accuracy: 0.8447\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2303 - accuracy: 0.9070 - val_loss: 0.3133 - val_accuracy: 0.8493\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.2299 - accuracy: 0.9080 - val_loss: 0.3127 - val_accuracy: 0.8493\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2294 - accuracy: 0.9080 - val_loss: 0.3121 - val_accuracy: 0.8493\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2289 - accuracy: 0.9080 - val_loss: 0.3115 - val_accuracy: 0.8493\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.2285 - accuracy: 0.9090 - val_loss: 0.3110 - val_accuracy: 0.8493\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2279 - accuracy: 0.9090 - val_loss: 0.3105 - val_accuracy: 0.8493\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2276 - accuracy: 0.9090 - val_loss: 0.3098 - val_accuracy: 0.8493\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2272 - accuracy: 0.9090 - val_loss: 0.3092 - val_accuracy: 0.8493\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2268 - accuracy: 0.9090 - val_loss: 0.3087 - val_accuracy: 0.8493\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2264 - accuracy: 0.9080 - val_loss: 0.3082 - val_accuracy: 0.8493\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2260 - accuracy: 0.9080 - val_loss: 0.3078 - val_accuracy: 0.8493\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2256 - accuracy: 0.9080 - val_loss: 0.3072 - val_accuracy: 0.8493\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2253 - accuracy: 0.9070 - val_loss: 0.3068 - val_accuracy: 0.8493\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2250 - accuracy: 0.9070 - val_loss: 0.3064 - val_accuracy: 0.8493\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2246 - accuracy: 0.9080 - val_loss: 0.3059 - val_accuracy: 0.8493\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2242 - accuracy: 0.9070 - val_loss: 0.3054 - val_accuracy: 0.8493\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 95us/step - loss: 0.2239 - accuracy: 0.9070 - val_loss: 0.3049 - val_accuracy: 0.8493\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2236 - accuracy: 0.9061 - val_loss: 0.3045 - val_accuracy: 0.8493\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2233 - accuracy: 0.9080 - val_loss: 0.3041 - val_accuracy: 0.8493\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2230 - accuracy: 0.9070 - val_loss: 0.3037 - val_accuracy: 0.8493\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2227 - accuracy: 0.9070 - val_loss: 0.3032 - val_accuracy: 0.8493\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 96us/step - loss: 0.2224 - accuracy: 0.9070 - val_loss: 0.3028 - val_accuracy: 0.8493\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2222 - accuracy: 0.9070 - val_loss: 0.3024 - val_accuracy: 0.8493\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2220 - accuracy: 0.9090 - val_loss: 0.3020 - val_accuracy: 0.8493\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2217 - accuracy: 0.9100 - val_loss: 0.3016 - val_accuracy: 0.8493\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2214 - accuracy: 0.9080 - val_loss: 0.3012 - val_accuracy: 0.8493\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2211 - accuracy: 0.9090 - val_loss: 0.3008 - val_accuracy: 0.8539\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2208 - accuracy: 0.9080 - val_loss: 0.3005 - val_accuracy: 0.8539\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2205 - accuracy: 0.9080 - val_loss: 0.3001 - val_accuracy: 0.8539\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2203 - accuracy: 0.9090 - val_loss: 0.2998 - val_accuracy: 0.8539\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2200 - accuracy: 0.9080 - val_loss: 0.2994 - val_accuracy: 0.8539\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.2198 - accuracy: 0.9080 - val_loss: 0.2992 - val_accuracy: 0.8539\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2196 - accuracy: 0.9090 - val_loss: 0.2989 - val_accuracy: 0.8539\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.2194 - accuracy: 0.9090 - val_loss: 0.2986 - val_accuracy: 0.8539\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2190 - accuracy: 0.9090 - val_loss: 0.2983 - val_accuracy: 0.8539\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.2188 - accuracy: 0.9100 - val_loss: 0.2980 - val_accuracy: 0.8539\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2186 - accuracy: 0.9110 - val_loss: 0.2978 - val_accuracy: 0.8539\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2183 - accuracy: 0.9100 - val_loss: 0.2976 - val_accuracy: 0.8539\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2181 - accuracy: 0.9110 - val_loss: 0.2975 - val_accuracy: 0.8539\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 893us/step - loss: 0.6505 - accuracy: 0.6820 - val_loss: 0.6466 - val_accuracy: 0.7306\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.6155 - accuracy: 0.7877 - val_loss: 0.6138 - val_accuracy: 0.7763\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.5823 - accuracy: 0.8376 - val_loss: 0.5830 - val_accuracy: 0.7808\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.5498 - accuracy: 0.8434 - val_loss: 0.5530 - val_accuracy: 0.7808\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.5175 - accuracy: 0.8503 - val_loss: 0.5238 - val_accuracy: 0.7854\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.4857 - accuracy: 0.8611 - val_loss: 0.4957 - val_accuracy: 0.7900\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.4551 - accuracy: 0.8659 - val_loss: 0.4694 - val_accuracy: 0.7945\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.4268 - accuracy: 0.8767 - val_loss: 0.4452 - val_accuracy: 0.8082\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.4006 - accuracy: 0.8767 - val_loss: 0.4235 - val_accuracy: 0.8174\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.3774 - accuracy: 0.8816 - val_loss: 0.4048 - val_accuracy: 0.8265\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.3574 - accuracy: 0.8836 - val_loss: 0.3885 - val_accuracy: 0.8311\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.3401 - accuracy: 0.8845 - val_loss: 0.3747 - val_accuracy: 0.8311\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.3253 - accuracy: 0.8865 - val_loss: 0.3631 - val_accuracy: 0.8402\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.3128 - accuracy: 0.8855 - val_loss: 0.3535 - val_accuracy: 0.8493\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.3024 - accuracy: 0.8894 - val_loss: 0.3456 - val_accuracy: 0.8539\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2934 - accuracy: 0.8933 - val_loss: 0.3390 - val_accuracy: 0.8539\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2858 - accuracy: 0.8933 - val_loss: 0.3337 - val_accuracy: 0.8539\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2794 - accuracy: 0.8953 - val_loss: 0.3294 - val_accuracy: 0.8584\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2738 - accuracy: 0.8973 - val_loss: 0.3259 - val_accuracy: 0.8584\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2691 - accuracy: 0.8982 - val_loss: 0.3231 - val_accuracy: 0.8584\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2649 - accuracy: 0.8992 - val_loss: 0.3208 - val_accuracy: 0.8584\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2613 - accuracy: 0.9002 - val_loss: 0.3190 - val_accuracy: 0.8539\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2582 - accuracy: 0.9012 - val_loss: 0.3173 - val_accuracy: 0.8539\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2553 - accuracy: 0.9012 - val_loss: 0.3160 - val_accuracy: 0.8447\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2527 - accuracy: 0.9022 - val_loss: 0.3147 - val_accuracy: 0.8447\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2504 - accuracy: 0.9041 - val_loss: 0.3137 - val_accuracy: 0.8447\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2484 - accuracy: 0.9031 - val_loss: 0.3129 - val_accuracy: 0.8447\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2466 - accuracy: 0.9031 - val_loss: 0.3120 - val_accuracy: 0.8447\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2449 - accuracy: 0.9041 - val_loss: 0.3112 - val_accuracy: 0.8447\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2433 - accuracy: 0.9031 - val_loss: 0.3105 - val_accuracy: 0.8447\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2419 - accuracy: 0.9051 - val_loss: 0.3100 - val_accuracy: 0.8447\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2406 - accuracy: 0.9041 - val_loss: 0.3095 - val_accuracy: 0.8493\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2394 - accuracy: 0.9061 - val_loss: 0.3089 - val_accuracy: 0.8493\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 169us/step - loss: 0.2382 - accuracy: 0.9061 - val_loss: 0.3085 - val_accuracy: 0.8493\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2372 - accuracy: 0.9070 - val_loss: 0.3080 - val_accuracy: 0.8493\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2361 - accuracy: 0.9080 - val_loss: 0.3075 - val_accuracy: 0.8493\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.2351 - accuracy: 0.9090 - val_loss: 0.3070 - val_accuracy: 0.8493\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2343 - accuracy: 0.9090 - val_loss: 0.3066 - val_accuracy: 0.8493\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2334 - accuracy: 0.9100 - val_loss: 0.3063 - val_accuracy: 0.8493\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2327 - accuracy: 0.9110 - val_loss: 0.3061 - val_accuracy: 0.8493\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2320 - accuracy: 0.9110 - val_loss: 0.3058 - val_accuracy: 0.8493\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2313 - accuracy: 0.9119 - val_loss: 0.3054 - val_accuracy: 0.8493\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2305 - accuracy: 0.9110 - val_loss: 0.3051 - val_accuracy: 0.8493\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 164us/step - loss: 0.2300 - accuracy: 0.9100 - val_loss: 0.3047 - val_accuracy: 0.8539\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2293 - accuracy: 0.9100 - val_loss: 0.3043 - val_accuracy: 0.8539\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2288 - accuracy: 0.9119 - val_loss: 0.3040 - val_accuracy: 0.8539\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2282 - accuracy: 0.9119 - val_loss: 0.3037 - val_accuracy: 0.8539\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2276 - accuracy: 0.9119 - val_loss: 0.3033 - val_accuracy: 0.8539\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 170us/step - loss: 0.2270 - accuracy: 0.9110 - val_loss: 0.3029 - val_accuracy: 0.8539\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2266 - accuracy: 0.9119 - val_loss: 0.3025 - val_accuracy: 0.8539\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2261 - accuracy: 0.9110 - val_loss: 0.3021 - val_accuracy: 0.8539\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2256 - accuracy: 0.9119 - val_loss: 0.3019 - val_accuracy: 0.8539\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2251 - accuracy: 0.9129 - val_loss: 0.3015 - val_accuracy: 0.8539\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2247 - accuracy: 0.9119 - val_loss: 0.3011 - val_accuracy: 0.8539\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2242 - accuracy: 0.9110 - val_loss: 0.3007 - val_accuracy: 0.8539\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2238 - accuracy: 0.9129 - val_loss: 0.3002 - val_accuracy: 0.8539\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2233 - accuracy: 0.9119 - val_loss: 0.2997 - val_accuracy: 0.8539\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2228 - accuracy: 0.9139 - val_loss: 0.2993 - val_accuracy: 0.8539\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2225 - accuracy: 0.9129 - val_loss: 0.2989 - val_accuracy: 0.8539\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2220 - accuracy: 0.9119 - val_loss: 0.2984 - val_accuracy: 0.8539\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.2217 - accuracy: 0.9139 - val_loss: 0.2980 - val_accuracy: 0.8539\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2212 - accuracy: 0.9110 - val_loss: 0.2975 - val_accuracy: 0.8539\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2209 - accuracy: 0.9149 - val_loss: 0.2972 - val_accuracy: 0.8539\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.2205 - accuracy: 0.9139 - val_loss: 0.2970 - val_accuracy: 0.8539\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2202 - accuracy: 0.9149 - val_loss: 0.2964 - val_accuracy: 0.8539\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2198 - accuracy: 0.9159 - val_loss: 0.2961 - val_accuracy: 0.8584\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2195 - accuracy: 0.9159 - val_loss: 0.2956 - val_accuracy: 0.8584\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2192 - accuracy: 0.9168 - val_loss: 0.2952 - val_accuracy: 0.8584\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2187 - accuracy: 0.9159 - val_loss: 0.2948 - val_accuracy: 0.8584\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.2184 - accuracy: 0.9168 - val_loss: 0.2943 - val_accuracy: 0.8584\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2181 - accuracy: 0.9188 - val_loss: 0.2941 - val_accuracy: 0.8584\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2178 - accuracy: 0.9168 - val_loss: 0.2937 - val_accuracy: 0.8584\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2175 - accuracy: 0.9188 - val_loss: 0.2935 - val_accuracy: 0.8584\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2172 - accuracy: 0.9178 - val_loss: 0.2931 - val_accuracy: 0.8584\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2168 - accuracy: 0.9168 - val_loss: 0.2927 - val_accuracy: 0.8584\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2164 - accuracy: 0.9188 - val_loss: 0.2925 - val_accuracy: 0.8584\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.2163 - accuracy: 0.9168 - val_loss: 0.2920 - val_accuracy: 0.8584\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 230us/step - loss: 0.2159 - accuracy: 0.9168 - val_loss: 0.2917 - val_accuracy: 0.8584\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.2156 - accuracy: 0.9159 - val_loss: 0.2915 - val_accuracy: 0.8584\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2153 - accuracy: 0.9168 - val_loss: 0.2915 - val_accuracy: 0.8584\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2150 - accuracy: 0.9159 - val_loss: 0.2911 - val_accuracy: 0.8584\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2148 - accuracy: 0.9178 - val_loss: 0.2909 - val_accuracy: 0.8584\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2144 - accuracy: 0.9168 - val_loss: 0.2908 - val_accuracy: 0.8584\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2141 - accuracy: 0.9159 - val_loss: 0.2906 - val_accuracy: 0.8584\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2139 - accuracy: 0.9159 - val_loss: 0.2903 - val_accuracy: 0.8630\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2137 - accuracy: 0.9159 - val_loss: 0.2901 - val_accuracy: 0.8630\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2133 - accuracy: 0.9159 - val_loss: 0.2898 - val_accuracy: 0.8630\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2131 - accuracy: 0.9168 - val_loss: 0.2895 - val_accuracy: 0.8630\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2127 - accuracy: 0.9178 - val_loss: 0.2893 - val_accuracy: 0.8630\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2124 - accuracy: 0.9168 - val_loss: 0.2890 - val_accuracy: 0.8630\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2122 - accuracy: 0.9168 - val_loss: 0.2888 - val_accuracy: 0.8630\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2119 - accuracy: 0.9168 - val_loss: 0.2886 - val_accuracy: 0.8630\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2117 - accuracy: 0.9168 - val_loss: 0.2883 - val_accuracy: 0.8630\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2113 - accuracy: 0.9168 - val_loss: 0.2880 - val_accuracy: 0.8630\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2111 - accuracy: 0.9178 - val_loss: 0.2876 - val_accuracy: 0.8630\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2108 - accuracy: 0.9168 - val_loss: 0.2873 - val_accuracy: 0.8630\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2105 - accuracy: 0.9168 - val_loss: 0.2872 - val_accuracy: 0.8630\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2104 - accuracy: 0.9178 - val_loss: 0.2870 - val_accuracy: 0.8630\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2100 - accuracy: 0.9168 - val_loss: 0.2869 - val_accuracy: 0.8630\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 369us/step - loss: 0.2098 - accuracy: 0.9178 - val_loss: 0.2867 - val_accuracy: 0.8630\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.7916 - accuracy: 0.4560 - val_loss: 0.7354 - val_accuracy: 0.4703\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 180us/step - loss: 0.7315 - accuracy: 0.5059 - val_loss: 0.7042 - val_accuracy: 0.5160\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.7017 - accuracy: 0.6008 - val_loss: 0.6875 - val_accuracy: 0.5936\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.6829 - accuracy: 0.6722 - val_loss: 0.6750 - val_accuracy: 0.6210\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.6675 - accuracy: 0.7211 - val_loss: 0.6620 - val_accuracy: 0.6804\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.6518 - accuracy: 0.7583 - val_loss: 0.6471 - val_accuracy: 0.7215\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.6338 - accuracy: 0.7994 - val_loss: 0.6308 - val_accuracy: 0.7626\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.6152 - accuracy: 0.8258 - val_loss: 0.6147 - val_accuracy: 0.7763\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.5971 - accuracy: 0.8356 - val_loss: 0.5995 - val_accuracy: 0.7763\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.5801 - accuracy: 0.8376 - val_loss: 0.5849 - val_accuracy: 0.7808\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 378us/step - loss: 0.5641 - accuracy: 0.8434 - val_loss: 0.5710 - val_accuracy: 0.7945\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 215us/step - loss: 0.5486 - accuracy: 0.8444 - val_loss: 0.5576 - val_accuracy: 0.7945\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 290us/step - loss: 0.5341 - accuracy: 0.8474 - val_loss: 0.5451 - val_accuracy: 0.8128\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 210us/step - loss: 0.5204 - accuracy: 0.8513 - val_loss: 0.5333 - val_accuracy: 0.8219\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 235us/step - loss: 0.5073 - accuracy: 0.8552 - val_loss: 0.5224 - val_accuracy: 0.8219\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 314us/step - loss: 0.4949 - accuracy: 0.8581 - val_loss: 0.5120 - val_accuracy: 0.8174\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 219us/step - loss: 0.4830 - accuracy: 0.8630 - val_loss: 0.5024 - val_accuracy: 0.8174\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 273us/step - loss: 0.4720 - accuracy: 0.8650 - val_loss: 0.4936 - val_accuracy: 0.8219\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 211us/step - loss: 0.4616 - accuracy: 0.8650 - val_loss: 0.4855 - val_accuracy: 0.8219\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 224us/step - loss: 0.4519 - accuracy: 0.8669 - val_loss: 0.4782 - val_accuracy: 0.8174\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.4427 - accuracy: 0.8699 - val_loss: 0.4716 - val_accuracy: 0.8174\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.4342 - accuracy: 0.8757 - val_loss: 0.4654 - val_accuracy: 0.8219\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.4262 - accuracy: 0.8806 - val_loss: 0.4598 - val_accuracy: 0.8265\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.4187 - accuracy: 0.8826 - val_loss: 0.4545 - val_accuracy: 0.8265\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.4116 - accuracy: 0.8845 - val_loss: 0.4495 - val_accuracy: 0.8265\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.4048 - accuracy: 0.8845 - val_loss: 0.4449 - val_accuracy: 0.8265\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.3985 - accuracy: 0.8836 - val_loss: 0.4407 - val_accuracy: 0.8311\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.3926 - accuracy: 0.8855 - val_loss: 0.4368 - val_accuracy: 0.8311\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.3869 - accuracy: 0.8894 - val_loss: 0.4331 - val_accuracy: 0.8311\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.3817 - accuracy: 0.8933 - val_loss: 0.4297 - val_accuracy: 0.8311\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.3766 - accuracy: 0.8933 - val_loss: 0.4264 - val_accuracy: 0.8311\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.3719 - accuracy: 0.8933 - val_loss: 0.4233 - val_accuracy: 0.8311\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.3674 - accuracy: 0.8953 - val_loss: 0.4205 - val_accuracy: 0.8311\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.3633 - accuracy: 0.8973 - val_loss: 0.4178 - val_accuracy: 0.8311\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.3593 - accuracy: 0.8973 - val_loss: 0.4153 - val_accuracy: 0.8311\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.3555 - accuracy: 0.8963 - val_loss: 0.4128 - val_accuracy: 0.8311\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.3519 - accuracy: 0.8973 - val_loss: 0.4105 - val_accuracy: 0.8311\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.3485 - accuracy: 0.8963 - val_loss: 0.4084 - val_accuracy: 0.8356\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.3452 - accuracy: 0.8973 - val_loss: 0.4063 - val_accuracy: 0.8356\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.3420 - accuracy: 0.8953 - val_loss: 0.4043 - val_accuracy: 0.8356\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.3390 - accuracy: 0.8963 - val_loss: 0.4024 - val_accuracy: 0.8356\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.3360 - accuracy: 0.8982 - val_loss: 0.4005 - val_accuracy: 0.8356\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 171us/step - loss: 0.3332 - accuracy: 0.9002 - val_loss: 0.3987 - val_accuracy: 0.8356\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.3306 - accuracy: 0.9012 - val_loss: 0.3971 - val_accuracy: 0.8356\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.3280 - accuracy: 0.9041 - val_loss: 0.3956 - val_accuracy: 0.8356\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.3256 - accuracy: 0.9041 - val_loss: 0.3941 - val_accuracy: 0.8356\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.3232 - accuracy: 0.9022 - val_loss: 0.3928 - val_accuracy: 0.8356\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.3210 - accuracy: 0.9031 - val_loss: 0.3914 - val_accuracy: 0.8356\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.3189 - accuracy: 0.9022 - val_loss: 0.3901 - val_accuracy: 0.8311\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.3169 - accuracy: 0.9022 - val_loss: 0.3889 - val_accuracy: 0.8311\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.3149 - accuracy: 0.9031 - val_loss: 0.3877 - val_accuracy: 0.8356\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.3130 - accuracy: 0.9031 - val_loss: 0.3866 - val_accuracy: 0.8356\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.3112 - accuracy: 0.9031 - val_loss: 0.3855 - val_accuracy: 0.8402\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.3094 - accuracy: 0.9022 - val_loss: 0.3844 - val_accuracy: 0.8402\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.3078 - accuracy: 0.9031 - val_loss: 0.3835 - val_accuracy: 0.8447\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.3060 - accuracy: 0.9022 - val_loss: 0.3827 - val_accuracy: 0.8402\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.3045 - accuracy: 0.9022 - val_loss: 0.3819 - val_accuracy: 0.8402\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 178us/step - loss: 0.3030 - accuracy: 0.9031 - val_loss: 0.3811 - val_accuracy: 0.8402\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.3017 - accuracy: 0.9012 - val_loss: 0.3803 - val_accuracy: 0.8447\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.3002 - accuracy: 0.9031 - val_loss: 0.3796 - val_accuracy: 0.8447\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2989 - accuracy: 0.9022 - val_loss: 0.3788 - val_accuracy: 0.8447\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2977 - accuracy: 0.9022 - val_loss: 0.3782 - val_accuracy: 0.8493\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2965 - accuracy: 0.9022 - val_loss: 0.3775 - val_accuracy: 0.8493\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2953 - accuracy: 0.9031 - val_loss: 0.3769 - val_accuracy: 0.8493\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.2942 - accuracy: 0.9022 - val_loss: 0.3764 - val_accuracy: 0.8493\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2930 - accuracy: 0.9022 - val_loss: 0.3759 - val_accuracy: 0.8493\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2919 - accuracy: 0.9031 - val_loss: 0.3753 - val_accuracy: 0.8493\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2908 - accuracy: 0.9031 - val_loss: 0.3749 - val_accuracy: 0.8447\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2898 - accuracy: 0.9031 - val_loss: 0.3743 - val_accuracy: 0.8447\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2889 - accuracy: 0.9031 - val_loss: 0.3739 - val_accuracy: 0.8447\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2879 - accuracy: 0.9022 - val_loss: 0.3734 - val_accuracy: 0.8447\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2869 - accuracy: 0.9031 - val_loss: 0.3729 - val_accuracy: 0.8447\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2861 - accuracy: 0.9031 - val_loss: 0.3723 - val_accuracy: 0.8402\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2851 - accuracy: 0.9031 - val_loss: 0.3717 - val_accuracy: 0.8402\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2842 - accuracy: 0.9031 - val_loss: 0.3711 - val_accuracy: 0.8402\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2833 - accuracy: 0.9022 - val_loss: 0.3705 - val_accuracy: 0.8402\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.2824 - accuracy: 0.9031 - val_loss: 0.3698 - val_accuracy: 0.8402\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2817 - accuracy: 0.9022 - val_loss: 0.3691 - val_accuracy: 0.8402\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2808 - accuracy: 0.9022 - val_loss: 0.3684 - val_accuracy: 0.8402\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2800 - accuracy: 0.9012 - val_loss: 0.3675 - val_accuracy: 0.8402\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2791 - accuracy: 0.9022 - val_loss: 0.3667 - val_accuracy: 0.8402\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2783 - accuracy: 0.9022 - val_loss: 0.3658 - val_accuracy: 0.8402\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2774 - accuracy: 0.9012 - val_loss: 0.3651 - val_accuracy: 0.8402\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2766 - accuracy: 0.9031 - val_loss: 0.3643 - val_accuracy: 0.8402\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2759 - accuracy: 0.9041 - val_loss: 0.3636 - val_accuracy: 0.8402\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2752 - accuracy: 0.9031 - val_loss: 0.3629 - val_accuracy: 0.8402\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2744 - accuracy: 0.9041 - val_loss: 0.3622 - val_accuracy: 0.8447\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2737 - accuracy: 0.9051 - val_loss: 0.3614 - val_accuracy: 0.8447\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2731 - accuracy: 0.9041 - val_loss: 0.3607 - val_accuracy: 0.8493\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2724 - accuracy: 0.9041 - val_loss: 0.3599 - val_accuracy: 0.8493\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.2716 - accuracy: 0.9041 - val_loss: 0.3591 - val_accuracy: 0.8493\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2709 - accuracy: 0.9041 - val_loss: 0.3583 - val_accuracy: 0.8493\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2702 - accuracy: 0.9041 - val_loss: 0.3576 - val_accuracy: 0.8493\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.2696 - accuracy: 0.9041 - val_loss: 0.3569 - val_accuracy: 0.8493\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 182us/step - loss: 0.2690 - accuracy: 0.9041 - val_loss: 0.3562 - val_accuracy: 0.8493\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2682 - accuracy: 0.9051 - val_loss: 0.3556 - val_accuracy: 0.8493\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2677 - accuracy: 0.9031 - val_loss: 0.3550 - val_accuracy: 0.8493\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2671 - accuracy: 0.9041 - val_loss: 0.3544 - val_accuracy: 0.8493\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2665 - accuracy: 0.9031 - val_loss: 0.3539 - val_accuracy: 0.8493\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 167us/step - loss: 0.2658 - accuracy: 0.9041 - val_loss: 0.3533 - val_accuracy: 0.8493\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 926us/step - loss: 0.7258 - accuracy: 0.5391 - val_loss: 0.6578 - val_accuracy: 0.6575\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 169us/step - loss: 0.6426 - accuracy: 0.6820 - val_loss: 0.5954 - val_accuracy: 0.7626\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.5763 - accuracy: 0.7681 - val_loss: 0.5448 - val_accuracy: 0.7900\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.5213 - accuracy: 0.8102 - val_loss: 0.5020 - val_accuracy: 0.8082\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 180us/step - loss: 0.4759 - accuracy: 0.8356 - val_loss: 0.4671 - val_accuracy: 0.8219\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.4388 - accuracy: 0.8503 - val_loss: 0.4392 - val_accuracy: 0.8311\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.4074 - accuracy: 0.8630 - val_loss: 0.4165 - val_accuracy: 0.8311\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.3811 - accuracy: 0.8757 - val_loss: 0.3974 - val_accuracy: 0.8447\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.3591 - accuracy: 0.8836 - val_loss: 0.3818 - val_accuracy: 0.8539\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.3412 - accuracy: 0.8845 - val_loss: 0.3694 - val_accuracy: 0.8630\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.3263 - accuracy: 0.8914 - val_loss: 0.3594 - val_accuracy: 0.8630\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.3140 - accuracy: 0.8933 - val_loss: 0.3514 - val_accuracy: 0.8676\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 174us/step - loss: 0.3035 - accuracy: 0.8973 - val_loss: 0.3451 - val_accuracy: 0.8676\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2945 - accuracy: 0.8973 - val_loss: 0.3398 - val_accuracy: 0.8630\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2869 - accuracy: 0.8982 - val_loss: 0.3356 - val_accuracy: 0.8676\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2802 - accuracy: 0.9002 - val_loss: 0.3322 - val_accuracy: 0.8676\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2744 - accuracy: 0.9022 - val_loss: 0.3295 - val_accuracy: 0.8676\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2697 - accuracy: 0.9051 - val_loss: 0.3274 - val_accuracy: 0.8676\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2656 - accuracy: 0.9051 - val_loss: 0.3256 - val_accuracy: 0.8676\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2620 - accuracy: 0.9051 - val_loss: 0.3241 - val_accuracy: 0.8721\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2591 - accuracy: 0.9061 - val_loss: 0.3228 - val_accuracy: 0.8721\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2566 - accuracy: 0.9061 - val_loss: 0.3217 - val_accuracy: 0.8721\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2544 - accuracy: 0.9070 - val_loss: 0.3208 - val_accuracy: 0.8721\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2524 - accuracy: 0.9080 - val_loss: 0.3200 - val_accuracy: 0.8721\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2505 - accuracy: 0.9080 - val_loss: 0.3194 - val_accuracy: 0.8767\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2490 - accuracy: 0.9080 - val_loss: 0.3188 - val_accuracy: 0.8813\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2477 - accuracy: 0.9070 - val_loss: 0.3182 - val_accuracy: 0.8813\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 194us/step - loss: 0.2463 - accuracy: 0.9100 - val_loss: 0.3177 - val_accuracy: 0.8813\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2450 - accuracy: 0.9110 - val_loss: 0.3172 - val_accuracy: 0.8813\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.2438 - accuracy: 0.9100 - val_loss: 0.3168 - val_accuracy: 0.8813\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.2428 - accuracy: 0.9100 - val_loss: 0.3164 - val_accuracy: 0.8813\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2417 - accuracy: 0.9119 - val_loss: 0.3160 - val_accuracy: 0.8813\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2407 - accuracy: 0.9119 - val_loss: 0.3158 - val_accuracy: 0.8813\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2398 - accuracy: 0.9119 - val_loss: 0.3153 - val_accuracy: 0.8858\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2390 - accuracy: 0.9129 - val_loss: 0.3147 - val_accuracy: 0.8904\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2383 - accuracy: 0.9119 - val_loss: 0.3143 - val_accuracy: 0.8858\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.2375 - accuracy: 0.9119 - val_loss: 0.3141 - val_accuracy: 0.8858\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.2368 - accuracy: 0.9119 - val_loss: 0.3138 - val_accuracy: 0.8858\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.2362 - accuracy: 0.9119 - val_loss: 0.3135 - val_accuracy: 0.8858\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2354 - accuracy: 0.9139 - val_loss: 0.3131 - val_accuracy: 0.8858\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.2348 - accuracy: 0.9139 - val_loss: 0.3128 - val_accuracy: 0.8858\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2342 - accuracy: 0.9129 - val_loss: 0.3125 - val_accuracy: 0.8858\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2337 - accuracy: 0.9129 - val_loss: 0.3121 - val_accuracy: 0.8813\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2330 - accuracy: 0.9110 - val_loss: 0.3120 - val_accuracy: 0.8813\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2326 - accuracy: 0.9110 - val_loss: 0.3118 - val_accuracy: 0.8813\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.2318 - accuracy: 0.9129 - val_loss: 0.3115 - val_accuracy: 0.8813\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 245us/step - loss: 0.2314 - accuracy: 0.9129 - val_loss: 0.3112 - val_accuracy: 0.8813\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2309 - accuracy: 0.9129 - val_loss: 0.3109 - val_accuracy: 0.8813\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 184us/step - loss: 0.2303 - accuracy: 0.9139 - val_loss: 0.3106 - val_accuracy: 0.8813\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2298 - accuracy: 0.9129 - val_loss: 0.3103 - val_accuracy: 0.8813\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2294 - accuracy: 0.9129 - val_loss: 0.3100 - val_accuracy: 0.8767\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2290 - accuracy: 0.9139 - val_loss: 0.3098 - val_accuracy: 0.8767\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.2284 - accuracy: 0.9119 - val_loss: 0.3097 - val_accuracy: 0.8767\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2281 - accuracy: 0.9139 - val_loss: 0.3093 - val_accuracy: 0.8767\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2275 - accuracy: 0.9129 - val_loss: 0.3088 - val_accuracy: 0.8767\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.2272 - accuracy: 0.9129 - val_loss: 0.3084 - val_accuracy: 0.8767\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2267 - accuracy: 0.9139 - val_loss: 0.3080 - val_accuracy: 0.8767\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2263 - accuracy: 0.9129 - val_loss: 0.3077 - val_accuracy: 0.8767\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2259 - accuracy: 0.9129 - val_loss: 0.3073 - val_accuracy: 0.8767\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 180us/step - loss: 0.2254 - accuracy: 0.9139 - val_loss: 0.3071 - val_accuracy: 0.8767\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2249 - accuracy: 0.9149 - val_loss: 0.3066 - val_accuracy: 0.8767\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2244 - accuracy: 0.9139 - val_loss: 0.3063 - val_accuracy: 0.8767\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 235us/step - loss: 0.2242 - accuracy: 0.9149 - val_loss: 0.3059 - val_accuracy: 0.8767\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2236 - accuracy: 0.9159 - val_loss: 0.3055 - val_accuracy: 0.8767\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.2232 - accuracy: 0.9149 - val_loss: 0.3049 - val_accuracy: 0.8767\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2228 - accuracy: 0.9139 - val_loss: 0.3044 - val_accuracy: 0.8767\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 167us/step - loss: 0.2223 - accuracy: 0.9139 - val_loss: 0.3040 - val_accuracy: 0.8767\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2219 - accuracy: 0.9139 - val_loss: 0.3036 - val_accuracy: 0.8767\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2214 - accuracy: 0.9139 - val_loss: 0.3031 - val_accuracy: 0.8767\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2209 - accuracy: 0.9129 - val_loss: 0.3028 - val_accuracy: 0.8767\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.2206 - accuracy: 0.9149 - val_loss: 0.3025 - val_accuracy: 0.8767\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2201 - accuracy: 0.9139 - val_loss: 0.3022 - val_accuracy: 0.8767\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2198 - accuracy: 0.9129 - val_loss: 0.3017 - val_accuracy: 0.8767\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 166us/step - loss: 0.2193 - accuracy: 0.9139 - val_loss: 0.3013 - val_accuracy: 0.8767\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.2189 - accuracy: 0.9139 - val_loss: 0.3011 - val_accuracy: 0.8767\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2186 - accuracy: 0.9139 - val_loss: 0.3009 - val_accuracy: 0.8721\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 299us/step - loss: 0.2183 - accuracy: 0.9129 - val_loss: 0.3006 - val_accuracy: 0.8721\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2179 - accuracy: 0.9149 - val_loss: 0.3001 - val_accuracy: 0.8721\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.2176 - accuracy: 0.9149 - val_loss: 0.2997 - val_accuracy: 0.8721\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2172 - accuracy: 0.9139 - val_loss: 0.2993 - val_accuracy: 0.8721\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 170us/step - loss: 0.2168 - accuracy: 0.9139 - val_loss: 0.2988 - val_accuracy: 0.8767\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 333us/step - loss: 0.2164 - accuracy: 0.9149 - val_loss: 0.2985 - val_accuracy: 0.8767\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 275us/step - loss: 0.2161 - accuracy: 0.9149 - val_loss: 0.2982 - val_accuracy: 0.8767\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 370us/step - loss: 0.2158 - accuracy: 0.9159 - val_loss: 0.2978 - val_accuracy: 0.8721\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 350us/step - loss: 0.2154 - accuracy: 0.9149 - val_loss: 0.2975 - val_accuracy: 0.8767\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 187us/step - loss: 0.2149 - accuracy: 0.9159 - val_loss: 0.2970 - val_accuracy: 0.8767\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 191us/step - loss: 0.2146 - accuracy: 0.9149 - val_loss: 0.2966 - val_accuracy: 0.8813\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 198us/step - loss: 0.2142 - accuracy: 0.9159 - val_loss: 0.2962 - val_accuracy: 0.8813\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 243us/step - loss: 0.2140 - accuracy: 0.9168 - val_loss: 0.2960 - val_accuracy: 0.8813\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 211us/step - loss: 0.2137 - accuracy: 0.9168 - val_loss: 0.2957 - val_accuracy: 0.8813\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 225us/step - loss: 0.2133 - accuracy: 0.9149 - val_loss: 0.2956 - val_accuracy: 0.8767\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2130 - accuracy: 0.9168 - val_loss: 0.2954 - val_accuracy: 0.8767\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 193us/step - loss: 0.2125 - accuracy: 0.9149 - val_loss: 0.2952 - val_accuracy: 0.8813\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 198us/step - loss: 0.2124 - accuracy: 0.9159 - val_loss: 0.2947 - val_accuracy: 0.8813\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 201us/step - loss: 0.2120 - accuracy: 0.9159 - val_loss: 0.2944 - val_accuracy: 0.8813\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 260us/step - loss: 0.2118 - accuracy: 0.9159 - val_loss: 0.2943 - val_accuracy: 0.8813\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 346us/step - loss: 0.2114 - accuracy: 0.9159 - val_loss: 0.2940 - val_accuracy: 0.8813\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 186us/step - loss: 0.2112 - accuracy: 0.9139 - val_loss: 0.2938 - val_accuracy: 0.8813\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 208us/step - loss: 0.2108 - accuracy: 0.9139 - val_loss: 0.2937 - val_accuracy: 0.8813\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 264us/step - loss: 0.2106 - accuracy: 0.9159 - val_loss: 0.2933 - val_accuracy: 0.8813\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 834us/step - loss: 0.7128 - accuracy: 0.5303 - val_loss: 0.6751 - val_accuracy: 0.5845\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 237us/step - loss: 0.6322 - accuracy: 0.6849 - val_loss: 0.6115 - val_accuracy: 0.7215\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - ETA: 0s - loss: 0.5724 - accuracy: 0.77 - 0s 195us/step - loss: 0.5675 - accuracy: 0.7798 - val_loss: 0.5592 - val_accuracy: 0.7808\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 258us/step - loss: 0.5127 - accuracy: 0.8425 - val_loss: 0.5148 - val_accuracy: 0.8037\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 233us/step - loss: 0.4659 - accuracy: 0.8640 - val_loss: 0.4769 - val_accuracy: 0.8356\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 249us/step - loss: 0.4264 - accuracy: 0.8748 - val_loss: 0.4456 - val_accuracy: 0.8447\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 243us/step - loss: 0.3934 - accuracy: 0.8855 - val_loss: 0.4196 - val_accuracy: 0.8493\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 212us/step - loss: 0.3661 - accuracy: 0.8894 - val_loss: 0.3987 - val_accuracy: 0.8676\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 207us/step - loss: 0.3438 - accuracy: 0.8865 - val_loss: 0.3821 - val_accuracy: 0.8630\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 218us/step - loss: 0.3259 - accuracy: 0.8914 - val_loss: 0.3689 - val_accuracy: 0.8630\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 194us/step - loss: 0.3112 - accuracy: 0.8924 - val_loss: 0.3584 - val_accuracy: 0.8630\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 225us/step - loss: 0.2990 - accuracy: 0.8963 - val_loss: 0.3498 - val_accuracy: 0.8584\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 226us/step - loss: 0.2891 - accuracy: 0.8963 - val_loss: 0.3432 - val_accuracy: 0.8630\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 226us/step - loss: 0.2809 - accuracy: 0.8982 - val_loss: 0.3376 - val_accuracy: 0.8630\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 230us/step - loss: 0.2740 - accuracy: 0.8963 - val_loss: 0.3333 - val_accuracy: 0.8630\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 215us/step - loss: 0.2683 - accuracy: 0.8953 - val_loss: 0.3296 - val_accuracy: 0.8630\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 199us/step - loss: 0.2634 - accuracy: 0.8982 - val_loss: 0.3268 - val_accuracy: 0.8630\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 279us/step - loss: 0.2593 - accuracy: 0.8992 - val_loss: 0.3243 - val_accuracy: 0.8630\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 212us/step - loss: 0.2557 - accuracy: 0.9002 - val_loss: 0.3223 - val_accuracy: 0.8630\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 196us/step - loss: 0.2527 - accuracy: 0.9012 - val_loss: 0.3205 - val_accuracy: 0.8630\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2499 - accuracy: 0.9031 - val_loss: 0.3189 - val_accuracy: 0.8630\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 219us/step - loss: 0.2475 - accuracy: 0.9061 - val_loss: 0.3176 - val_accuracy: 0.8630\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 201us/step - loss: 0.2455 - accuracy: 0.9051 - val_loss: 0.3165 - val_accuracy: 0.8676\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 190us/step - loss: 0.2436 - accuracy: 0.9051 - val_loss: 0.3155 - val_accuracy: 0.8676\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 187us/step - loss: 0.2420 - accuracy: 0.9051 - val_loss: 0.3147 - val_accuracy: 0.8676\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2404 - accuracy: 0.9051 - val_loss: 0.3139 - val_accuracy: 0.8676\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2390 - accuracy: 0.9051 - val_loss: 0.3131 - val_accuracy: 0.8676\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2378 - accuracy: 0.9061 - val_loss: 0.3123 - val_accuracy: 0.8676\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2367 - accuracy: 0.9070 - val_loss: 0.3116 - val_accuracy: 0.8676\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.2355 - accuracy: 0.9080 - val_loss: 0.3109 - val_accuracy: 0.8676\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2346 - accuracy: 0.9080 - val_loss: 0.3102 - val_accuracy: 0.8676\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 169us/step - loss: 0.2337 - accuracy: 0.9100 - val_loss: 0.3096 - val_accuracy: 0.8676\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 176us/step - loss: 0.2327 - accuracy: 0.9100 - val_loss: 0.3090 - val_accuracy: 0.8630\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2318 - accuracy: 0.9119 - val_loss: 0.3086 - val_accuracy: 0.8630\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 188us/step - loss: 0.2310 - accuracy: 0.9110 - val_loss: 0.3079 - val_accuracy: 0.8630\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 181us/step - loss: 0.2303 - accuracy: 0.9119 - val_loss: 0.3074 - val_accuracy: 0.8630\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 222us/step - loss: 0.2295 - accuracy: 0.9119 - val_loss: 0.3070 - val_accuracy: 0.8630\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 183us/step - loss: 0.2289 - accuracy: 0.9119 - val_loss: 0.3064 - val_accuracy: 0.8630\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.2282 - accuracy: 0.9100 - val_loss: 0.3059 - val_accuracy: 0.8630\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.2276 - accuracy: 0.9119 - val_loss: 0.3054 - val_accuracy: 0.8630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2271 - accuracy: 0.9119 - val_loss: 0.3050 - val_accuracy: 0.8630\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2264 - accuracy: 0.9129 - val_loss: 0.3045 - val_accuracy: 0.8676\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2259 - accuracy: 0.9129 - val_loss: 0.3042 - val_accuracy: 0.8676\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2255 - accuracy: 0.9129 - val_loss: 0.3038 - val_accuracy: 0.8676\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2250 - accuracy: 0.9139 - val_loss: 0.3034 - val_accuracy: 0.8676\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2245 - accuracy: 0.9119 - val_loss: 0.3030 - val_accuracy: 0.8721\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 189us/step - loss: 0.2241 - accuracy: 0.9119 - val_loss: 0.3026 - val_accuracy: 0.8676\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2235 - accuracy: 0.9129 - val_loss: 0.3021 - val_accuracy: 0.8721\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.2232 - accuracy: 0.9129 - val_loss: 0.3016 - val_accuracy: 0.8767\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.2228 - accuracy: 0.9139 - val_loss: 0.3011 - val_accuracy: 0.8767\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 164us/step - loss: 0.2224 - accuracy: 0.9139 - val_loss: 0.3007 - val_accuracy: 0.8767\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 187us/step - loss: 0.2219 - accuracy: 0.9139 - val_loss: 0.3003 - val_accuracy: 0.8767\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2216 - accuracy: 0.9139 - val_loss: 0.2999 - val_accuracy: 0.8767\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2211 - accuracy: 0.9129 - val_loss: 0.2996 - val_accuracy: 0.8767\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2208 - accuracy: 0.9139 - val_loss: 0.2992 - val_accuracy: 0.8767\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2204 - accuracy: 0.9129 - val_loss: 0.2989 - val_accuracy: 0.8767\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.2201 - accuracy: 0.9129 - val_loss: 0.2987 - val_accuracy: 0.8813\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2197 - accuracy: 0.9139 - val_loss: 0.2983 - val_accuracy: 0.8813\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2193 - accuracy: 0.9139 - val_loss: 0.2981 - val_accuracy: 0.8813\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2190 - accuracy: 0.9139 - val_loss: 0.2978 - val_accuracy: 0.8813\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2189 - accuracy: 0.9129 - val_loss: 0.2974 - val_accuracy: 0.8813\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2185 - accuracy: 0.9139 - val_loss: 0.2971 - val_accuracy: 0.8813\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2181 - accuracy: 0.9139 - val_loss: 0.2969 - val_accuracy: 0.8813\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2179 - accuracy: 0.9139 - val_loss: 0.2965 - val_accuracy: 0.8813\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 191us/step - loss: 0.2175 - accuracy: 0.9129 - val_loss: 0.2962 - val_accuracy: 0.8813\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 169us/step - loss: 0.2172 - accuracy: 0.9149 - val_loss: 0.2959 - val_accuracy: 0.8813\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.2169 - accuracy: 0.9149 - val_loss: 0.2957 - val_accuracy: 0.8813\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 166us/step - loss: 0.2167 - accuracy: 0.9149 - val_loss: 0.2954 - val_accuracy: 0.8813\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.2163 - accuracy: 0.9139 - val_loss: 0.2952 - val_accuracy: 0.8813\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2161 - accuracy: 0.9149 - val_loss: 0.2951 - val_accuracy: 0.8813\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2158 - accuracy: 0.9149 - val_loss: 0.2948 - val_accuracy: 0.8813\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2155 - accuracy: 0.9149 - val_loss: 0.2947 - val_accuracy: 0.8813\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2153 - accuracy: 0.9139 - val_loss: 0.2943 - val_accuracy: 0.8813\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2149 - accuracy: 0.9139 - val_loss: 0.2940 - val_accuracy: 0.8813\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2147 - accuracy: 0.9168 - val_loss: 0.2939 - val_accuracy: 0.8813\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2146 - accuracy: 0.9178 - val_loss: 0.2937 - val_accuracy: 0.8813\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 178us/step - loss: 0.2143 - accuracy: 0.9159 - val_loss: 0.2935 - val_accuracy: 0.8858\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 174us/step - loss: 0.2141 - accuracy: 0.9159 - val_loss: 0.2932 - val_accuracy: 0.8858\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 196us/step - loss: 0.2138 - accuracy: 0.9159 - val_loss: 0.2929 - val_accuracy: 0.8858\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2135 - accuracy: 0.9149 - val_loss: 0.2927 - val_accuracy: 0.8858\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 168us/step - loss: 0.2132 - accuracy: 0.9159 - val_loss: 0.2924 - val_accuracy: 0.8858\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2130 - accuracy: 0.9139 - val_loss: 0.2923 - val_accuracy: 0.8858\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2128 - accuracy: 0.9149 - val_loss: 0.2920 - val_accuracy: 0.8858\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2126 - accuracy: 0.9159 - val_loss: 0.2918 - val_accuracy: 0.8858\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2123 - accuracy: 0.9139 - val_loss: 0.2915 - val_accuracy: 0.8858\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2120 - accuracy: 0.9149 - val_loss: 0.2913 - val_accuracy: 0.8858\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2119 - accuracy: 0.9159 - val_loss: 0.2911 - val_accuracy: 0.8858\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2116 - accuracy: 0.9139 - val_loss: 0.2908 - val_accuracy: 0.8904\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2113 - accuracy: 0.9139 - val_loss: 0.2907 - val_accuracy: 0.8904\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2111 - accuracy: 0.9159 - val_loss: 0.2904 - val_accuracy: 0.8904\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2108 - accuracy: 0.9149 - val_loss: 0.2901 - val_accuracy: 0.8904\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.2106 - accuracy: 0.9159 - val_loss: 0.2899 - val_accuracy: 0.8904\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2105 - accuracy: 0.9149 - val_loss: 0.2897 - val_accuracy: 0.8904\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2102 - accuracy: 0.9149 - val_loss: 0.2894 - val_accuracy: 0.8904\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2100 - accuracy: 0.9149 - val_loss: 0.2892 - val_accuracy: 0.8904\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2096 - accuracy: 0.9149 - val_loss: 0.2891 - val_accuracy: 0.8904\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2095 - accuracy: 0.9149 - val_loss: 0.2889 - val_accuracy: 0.8904\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2093 - accuracy: 0.9159 - val_loss: 0.2887 - val_accuracy: 0.8904\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 178us/step - loss: 0.2091 - accuracy: 0.9139 - val_loss: 0.2886 - val_accuracy: 0.8904\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2088 - accuracy: 0.9159 - val_loss: 0.2885 - val_accuracy: 0.8904\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 817us/step - loss: 0.6169 - accuracy: 0.6683 - val_loss: 0.5923 - val_accuracy: 0.7763\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 171us/step - loss: 0.5645 - accuracy: 0.7661 - val_loss: 0.5508 - val_accuracy: 0.8174\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 168us/step - loss: 0.5219 - accuracy: 0.8121 - val_loss: 0.5152 - val_accuracy: 0.7991\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.4847 - accuracy: 0.8425 - val_loss: 0.4837 - val_accuracy: 0.8128\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 269us/step - loss: 0.4518 - accuracy: 0.8532 - val_loss: 0.4562 - val_accuracy: 0.8219\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 252us/step - loss: 0.4226 - accuracy: 0.8601 - val_loss: 0.4324 - val_accuracy: 0.8265\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 175us/step - loss: 0.3971 - accuracy: 0.8630 - val_loss: 0.4124 - val_accuracy: 0.8219\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.3751 - accuracy: 0.8650 - val_loss: 0.3954 - val_accuracy: 0.8311\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.3564 - accuracy: 0.8699 - val_loss: 0.3813 - val_accuracy: 0.8311\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.3405 - accuracy: 0.8757 - val_loss: 0.3695 - val_accuracy: 0.8356\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.3269 - accuracy: 0.8748 - val_loss: 0.3600 - val_accuracy: 0.8356\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.3153 - accuracy: 0.8826 - val_loss: 0.3518 - val_accuracy: 0.8402\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.3054 - accuracy: 0.8836 - val_loss: 0.3451 - val_accuracy: 0.8447\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2969 - accuracy: 0.8865 - val_loss: 0.3394 - val_accuracy: 0.8539\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2893 - accuracy: 0.8894 - val_loss: 0.3349 - val_accuracy: 0.8539\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 227us/step - loss: 0.2828 - accuracy: 0.8914 - val_loss: 0.3312 - val_accuracy: 0.8539\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 232us/step - loss: 0.2772 - accuracy: 0.8924 - val_loss: 0.3279 - val_accuracy: 0.8539\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 196us/step - loss: 0.2721 - accuracy: 0.8953 - val_loss: 0.3251 - val_accuracy: 0.8539\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2675 - accuracy: 0.8982 - val_loss: 0.3227 - val_accuracy: 0.8584\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 257us/step - loss: 0.2635 - accuracy: 0.8982 - val_loss: 0.3206 - val_accuracy: 0.8584\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.2597 - accuracy: 0.8973 - val_loss: 0.3187 - val_accuracy: 0.8584\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2565 - accuracy: 0.9002 - val_loss: 0.3170 - val_accuracy: 0.8584\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2535 - accuracy: 0.8982 - val_loss: 0.3154 - val_accuracy: 0.8584\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 167us/step - loss: 0.2510 - accuracy: 0.9002 - val_loss: 0.3140 - val_accuracy: 0.8584\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2485 - accuracy: 0.9041 - val_loss: 0.3127 - val_accuracy: 0.8584\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2464 - accuracy: 0.9051 - val_loss: 0.3116 - val_accuracy: 0.8584\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.2442 - accuracy: 0.9061 - val_loss: 0.3104 - val_accuracy: 0.8584\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.2424 - accuracy: 0.9051 - val_loss: 0.3092 - val_accuracy: 0.8630\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 231us/step - loss: 0.2406 - accuracy: 0.9051 - val_loss: 0.3080 - val_accuracy: 0.8630\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.2389 - accuracy: 0.9051 - val_loss: 0.3069 - val_accuracy: 0.8676\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.2371 - accuracy: 0.9070 - val_loss: 0.3058 - val_accuracy: 0.8584\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 90us/step - loss: 0.2358 - accuracy: 0.9031 - val_loss: 0.3049 - val_accuracy: 0.8584\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 93us/step - loss: 0.2343 - accuracy: 0.9051 - val_loss: 0.3038 - val_accuracy: 0.8584\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 94us/step - loss: 0.2332 - accuracy: 0.9080 - val_loss: 0.3028 - val_accuracy: 0.8584\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 94us/step - loss: 0.2320 - accuracy: 0.9080 - val_loss: 0.3020 - val_accuracy: 0.8584\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 94us/step - loss: 0.2308 - accuracy: 0.9080 - val_loss: 0.3011 - val_accuracy: 0.8584\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 94us/step - loss: 0.2298 - accuracy: 0.9080 - val_loss: 0.3003 - val_accuracy: 0.8584\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 92us/step - loss: 0.2289 - accuracy: 0.9080 - val_loss: 0.2994 - val_accuracy: 0.8584\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 93us/step - loss: 0.2278 - accuracy: 0.9080 - val_loss: 0.2986 - val_accuracy: 0.8584\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 100us/step - loss: 0.2269 - accuracy: 0.9090 - val_loss: 0.2978 - val_accuracy: 0.8630\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2260 - accuracy: 0.9080 - val_loss: 0.2968 - val_accuracy: 0.8721\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2250 - accuracy: 0.9100 - val_loss: 0.2960 - val_accuracy: 0.8721\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2242 - accuracy: 0.9100 - val_loss: 0.2952 - val_accuracy: 0.8721\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2234 - accuracy: 0.9100 - val_loss: 0.2944 - val_accuracy: 0.8767\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.2227 - accuracy: 0.9100 - val_loss: 0.2936 - val_accuracy: 0.8813\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2219 - accuracy: 0.9090 - val_loss: 0.2927 - val_accuracy: 0.8858\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.2212 - accuracy: 0.9080 - val_loss: 0.2919 - val_accuracy: 0.8858\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.2206 - accuracy: 0.9090 - val_loss: 0.2912 - val_accuracy: 0.8858\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2198 - accuracy: 0.9119 - val_loss: 0.2903 - val_accuracy: 0.8858\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 182us/step - loss: 0.2193 - accuracy: 0.9119 - val_loss: 0.2896 - val_accuracy: 0.8858\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 289us/step - loss: 0.2186 - accuracy: 0.9129 - val_loss: 0.2889 - val_accuracy: 0.8858\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 215us/step - loss: 0.2181 - accuracy: 0.9090 - val_loss: 0.2883 - val_accuracy: 0.8858\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 213us/step - loss: 0.2175 - accuracy: 0.9110 - val_loss: 0.2878 - val_accuracy: 0.8858\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2169 - accuracy: 0.9100 - val_loss: 0.2872 - val_accuracy: 0.8858\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2164 - accuracy: 0.9110 - val_loss: 0.2866 - val_accuracy: 0.8950\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 297us/step - loss: 0.2160 - accuracy: 0.9110 - val_loss: 0.2858 - val_accuracy: 0.8904\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2154 - accuracy: 0.9129 - val_loss: 0.2851 - val_accuracy: 0.8904\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 401us/step - loss: 0.2150 - accuracy: 0.9119 - val_loss: 0.2845 - val_accuracy: 0.8904\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 421us/step - loss: 0.2145 - accuracy: 0.9119 - val_loss: 0.2840 - val_accuracy: 0.8904\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 283us/step - loss: 0.2143 - accuracy: 0.9119 - val_loss: 0.2835 - val_accuracy: 0.8904\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2137 - accuracy: 0.9129 - val_loss: 0.2830 - val_accuracy: 0.8904\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 236us/step - loss: 0.2132 - accuracy: 0.9129 - val_loss: 0.2826 - val_accuracy: 0.8904\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 206us/step - loss: 0.2130 - accuracy: 0.9119 - val_loss: 0.2820 - val_accuracy: 0.8904\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 202us/step - loss: 0.2125 - accuracy: 0.9139 - val_loss: 0.2815 - val_accuracy: 0.8858\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 250us/step - loss: 0.2123 - accuracy: 0.9119 - val_loss: 0.2810 - val_accuracy: 0.8858\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 167us/step - loss: 0.2118 - accuracy: 0.9129 - val_loss: 0.2806 - val_accuracy: 0.8858\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 346us/step - loss: 0.2114 - accuracy: 0.9139 - val_loss: 0.2802 - val_accuracy: 0.8858\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 216us/step - loss: 0.2111 - accuracy: 0.9129 - val_loss: 0.2799 - val_accuracy: 0.8858\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 333us/step - loss: 0.2107 - accuracy: 0.9119 - val_loss: 0.2795 - val_accuracy: 0.8904\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 339us/step - loss: 0.2104 - accuracy: 0.9129 - val_loss: 0.2792 - val_accuracy: 0.8950\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 243us/step - loss: 0.2101 - accuracy: 0.9119 - val_loss: 0.2790 - val_accuracy: 0.8904\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 309us/step - loss: 0.2097 - accuracy: 0.9119 - val_loss: 0.2787 - val_accuracy: 0.8904\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 300us/step - loss: 0.2095 - accuracy: 0.9110 - val_loss: 0.2784 - val_accuracy: 0.8950\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 253us/step - loss: 0.2091 - accuracy: 0.9110 - val_loss: 0.2781 - val_accuracy: 0.8904\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 315us/step - loss: 0.2088 - accuracy: 0.9119 - val_loss: 0.2780 - val_accuracy: 0.8904\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 269us/step - loss: 0.2086 - accuracy: 0.9119 - val_loss: 0.2778 - val_accuracy: 0.8904\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 190us/step - loss: 0.2082 - accuracy: 0.9129 - val_loss: 0.2774 - val_accuracy: 0.8904\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 169us/step - loss: 0.2079 - accuracy: 0.9119 - val_loss: 0.2771 - val_accuracy: 0.8904\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2075 - accuracy: 0.9110 - val_loss: 0.2769 - val_accuracy: 0.8904\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2073 - accuracy: 0.9110 - val_loss: 0.2766 - val_accuracy: 0.8904\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2071 - accuracy: 0.9119 - val_loss: 0.2763 - val_accuracy: 0.8904\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 298us/step - loss: 0.2068 - accuracy: 0.9119 - val_loss: 0.2761 - val_accuracy: 0.8904\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 380us/step - loss: 0.2064 - accuracy: 0.9119 - val_loss: 0.2757 - val_accuracy: 0.8904\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 180us/step - loss: 0.2062 - accuracy: 0.9139 - val_loss: 0.2754 - val_accuracy: 0.8950\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 187us/step - loss: 0.2059 - accuracy: 0.9110 - val_loss: 0.2752 - val_accuracy: 0.8950\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.2056 - accuracy: 0.9139 - val_loss: 0.2748 - val_accuracy: 0.8950\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 220us/step - loss: 0.2054 - accuracy: 0.9119 - val_loss: 0.2745 - val_accuracy: 0.8950\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 259us/step - loss: 0.2051 - accuracy: 0.9119 - val_loss: 0.2742 - val_accuracy: 0.8950\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 182us/step - loss: 0.2048 - accuracy: 0.9129 - val_loss: 0.2740 - val_accuracy: 0.8950\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2045 - accuracy: 0.9129 - val_loss: 0.2738 - val_accuracy: 0.8904\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 200us/step - loss: 0.2043 - accuracy: 0.9129 - val_loss: 0.2734 - val_accuracy: 0.8904\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.2040 - accuracy: 0.9139 - val_loss: 0.2731 - val_accuracy: 0.8950\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2036 - accuracy: 0.9139 - val_loss: 0.2730 - val_accuracy: 0.8950\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2035 - accuracy: 0.9129 - val_loss: 0.2726 - val_accuracy: 0.8904\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 227us/step - loss: 0.2032 - accuracy: 0.9129 - val_loss: 0.2723 - val_accuracy: 0.8904\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 231us/step - loss: 0.2029 - accuracy: 0.9129 - val_loss: 0.2720 - val_accuracy: 0.8950\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.2027 - accuracy: 0.9129 - val_loss: 0.2718 - val_accuracy: 0.8950\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 101us/step - loss: 0.2024 - accuracy: 0.9139 - val_loss: 0.2715 - val_accuracy: 0.8904\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2022 - accuracy: 0.9139 - val_loss: 0.2714 - val_accuracy: 0.8904\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2020 - accuracy: 0.9139 - val_loss: 0.2710 - val_accuracy: 0.8904\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 916us/step - loss: 0.8307 - accuracy: 0.4667 - val_loss: 0.7737 - val_accuracy: 0.4612\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 99us/step - loss: 0.7183 - accuracy: 0.4863 - val_loss: 0.6981 - val_accuracy: 0.5160\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 99us/step - loss: 0.6558 - accuracy: 0.5783 - val_loss: 0.6482 - val_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.6117 - accuracy: 0.7260 - val_loss: 0.6098 - val_accuracy: 0.7397\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 97us/step - loss: 0.5756 - accuracy: 0.7857 - val_loss: 0.5774 - val_accuracy: 0.7991\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.5428 - accuracy: 0.8209 - val_loss: 0.5472 - val_accuracy: 0.8402\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 97us/step - loss: 0.5112 - accuracy: 0.8532 - val_loss: 0.5180 - val_accuracy: 0.8539\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 94us/step - loss: 0.4803 - accuracy: 0.8699 - val_loss: 0.4900 - val_accuracy: 0.8584\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 96us/step - loss: 0.4507 - accuracy: 0.8796 - val_loss: 0.4633 - val_accuracy: 0.8676\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 99us/step - loss: 0.4226 - accuracy: 0.8875 - val_loss: 0.4386 - val_accuracy: 0.8630\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 96us/step - loss: 0.3966 - accuracy: 0.8943 - val_loss: 0.4162 - val_accuracy: 0.8676\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 97us/step - loss: 0.3732 - accuracy: 0.8973 - val_loss: 0.3965 - val_accuracy: 0.8630\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.3525 - accuracy: 0.9002 - val_loss: 0.3796 - val_accuracy: 0.8630\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 97us/step - loss: 0.3346 - accuracy: 0.9022 - val_loss: 0.3657 - val_accuracy: 0.8630\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.3195 - accuracy: 0.9031 - val_loss: 0.3539 - val_accuracy: 0.8630\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 201us/step - loss: 0.3066 - accuracy: 0.9041 - val_loss: 0.3444 - val_accuracy: 0.8676\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 245us/step - loss: 0.2957 - accuracy: 0.9051 - val_loss: 0.3368 - val_accuracy: 0.8721\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2865 - accuracy: 0.9041 - val_loss: 0.3307 - val_accuracy: 0.8721\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 360us/step - loss: 0.2789 - accuracy: 0.9061 - val_loss: 0.3258 - val_accuracy: 0.8721\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 303us/step - loss: 0.2724 - accuracy: 0.9051 - val_loss: 0.3219 - val_accuracy: 0.8767\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 353us/step - loss: 0.2670 - accuracy: 0.9070 - val_loss: 0.3189 - val_accuracy: 0.8767\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 373us/step - loss: 0.2623 - accuracy: 0.9061 - val_loss: 0.3164 - val_accuracy: 0.8767\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2583 - accuracy: 0.9070 - val_loss: 0.3145 - val_accuracy: 0.8721\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2550 - accuracy: 0.9051 - val_loss: 0.3131 - val_accuracy: 0.8721\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2521 - accuracy: 0.9051 - val_loss: 0.3120 - val_accuracy: 0.8676\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2496 - accuracy: 0.9080 - val_loss: 0.3111 - val_accuracy: 0.8676\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2475 - accuracy: 0.9090 - val_loss: 0.3105 - val_accuracy: 0.8676\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2456 - accuracy: 0.9080 - val_loss: 0.3100 - val_accuracy: 0.8676\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2440 - accuracy: 0.9090 - val_loss: 0.3096 - val_accuracy: 0.8676\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2426 - accuracy: 0.9090 - val_loss: 0.3094 - val_accuracy: 0.8676\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2415 - accuracy: 0.9110 - val_loss: 0.3092 - val_accuracy: 0.8676\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 182us/step - loss: 0.2403 - accuracy: 0.9100 - val_loss: 0.3090 - val_accuracy: 0.8676\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2393 - accuracy: 0.9100 - val_loss: 0.3089 - val_accuracy: 0.8676\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 181us/step - loss: 0.2384 - accuracy: 0.9110 - val_loss: 0.3088 - val_accuracy: 0.8676\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2376 - accuracy: 0.9090 - val_loss: 0.3086 - val_accuracy: 0.8676\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2369 - accuracy: 0.9100 - val_loss: 0.3085 - val_accuracy: 0.8676\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2362 - accuracy: 0.9110 - val_loss: 0.3084 - val_accuracy: 0.8676\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 349us/step - loss: 0.2356 - accuracy: 0.9119 - val_loss: 0.3083 - val_accuracy: 0.8676\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.2350 - accuracy: 0.9119 - val_loss: 0.3081 - val_accuracy: 0.8676\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2344 - accuracy: 0.9110 - val_loss: 0.3079 - val_accuracy: 0.8676\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2339 - accuracy: 0.9110 - val_loss: 0.3077 - val_accuracy: 0.8676\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.2333 - accuracy: 0.9090 - val_loss: 0.3075 - val_accuracy: 0.8721\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2328 - accuracy: 0.9090 - val_loss: 0.3073 - val_accuracy: 0.8676\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2324 - accuracy: 0.9090 - val_loss: 0.3071 - val_accuracy: 0.8676\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2318 - accuracy: 0.9100 - val_loss: 0.3069 - val_accuracy: 0.8630\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2314 - accuracy: 0.9100 - val_loss: 0.3067 - val_accuracy: 0.8676\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2310 - accuracy: 0.9110 - val_loss: 0.3065 - val_accuracy: 0.8676\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2306 - accuracy: 0.9110 - val_loss: 0.3063 - val_accuracy: 0.8676\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 203us/step - loss: 0.2300 - accuracy: 0.9129 - val_loss: 0.3061 - val_accuracy: 0.8630\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 215us/step - loss: 0.2297 - accuracy: 0.9110 - val_loss: 0.3058 - val_accuracy: 0.8630\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 216us/step - loss: 0.2293 - accuracy: 0.9119 - val_loss: 0.3055 - val_accuracy: 0.8676\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.2288 - accuracy: 0.9129 - val_loss: 0.3053 - val_accuracy: 0.8676\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2285 - accuracy: 0.9119 - val_loss: 0.3051 - val_accuracy: 0.8676\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2282 - accuracy: 0.9119 - val_loss: 0.3050 - val_accuracy: 0.8676\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2278 - accuracy: 0.9129 - val_loss: 0.3047 - val_accuracy: 0.8676\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 184us/step - loss: 0.2275 - accuracy: 0.9129 - val_loss: 0.3044 - val_accuracy: 0.8676\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 254us/step - loss: 0.2272 - accuracy: 0.9139 - val_loss: 0.3042 - val_accuracy: 0.8676\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 216us/step - loss: 0.2268 - accuracy: 0.9129 - val_loss: 0.3040 - val_accuracy: 0.8676\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 177us/step - loss: 0.2264 - accuracy: 0.9129 - val_loss: 0.3036 - val_accuracy: 0.8676\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 335us/step - loss: 0.2261 - accuracy: 0.9110 - val_loss: 0.3035 - val_accuracy: 0.8676\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 211us/step - loss: 0.2259 - accuracy: 0.9129 - val_loss: 0.3034 - val_accuracy: 0.8676\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 266us/step - loss: 0.2256 - accuracy: 0.9119 - val_loss: 0.3032 - val_accuracy: 0.8676\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 190us/step - loss: 0.2254 - accuracy: 0.9119 - val_loss: 0.3030 - val_accuracy: 0.8676\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 223us/step - loss: 0.2251 - accuracy: 0.9110 - val_loss: 0.3027 - val_accuracy: 0.8676\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 300us/step - loss: 0.2248 - accuracy: 0.9100 - val_loss: 0.3026 - val_accuracy: 0.8676\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 222us/step - loss: 0.2247 - accuracy: 0.9110 - val_loss: 0.3025 - val_accuracy: 0.8721\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.2245 - accuracy: 0.9100 - val_loss: 0.3023 - val_accuracy: 0.8721\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 167us/step - loss: 0.2242 - accuracy: 0.9110 - val_loss: 0.3020 - val_accuracy: 0.8721\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 277us/step - loss: 0.2240 - accuracy: 0.9110 - val_loss: 0.3018 - val_accuracy: 0.8721\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 189us/step - loss: 0.2238 - accuracy: 0.9110 - val_loss: 0.3015 - val_accuracy: 0.8721\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 191us/step - loss: 0.2236 - accuracy: 0.9100 - val_loss: 0.3014 - val_accuracy: 0.8721\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 176us/step - loss: 0.2233 - accuracy: 0.9090 - val_loss: 0.3012 - val_accuracy: 0.8721\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 195us/step - loss: 0.2232 - accuracy: 0.9100 - val_loss: 0.3010 - val_accuracy: 0.8721\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 228us/step - loss: 0.2229 - accuracy: 0.9110 - val_loss: 0.3009 - val_accuracy: 0.8721\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 191us/step - loss: 0.2227 - accuracy: 0.9110 - val_loss: 0.3006 - val_accuracy: 0.8721\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 195us/step - loss: 0.2225 - accuracy: 0.9119 - val_loss: 0.3005 - val_accuracy: 0.8721\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 191us/step - loss: 0.2224 - accuracy: 0.9100 - val_loss: 0.3002 - val_accuracy: 0.8721\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 202us/step - loss: 0.2221 - accuracy: 0.9090 - val_loss: 0.3000 - val_accuracy: 0.8721\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 270us/step - loss: 0.2217 - accuracy: 0.9129 - val_loss: 0.2998 - val_accuracy: 0.8721\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 236us/step - loss: 0.2215 - accuracy: 0.9119 - val_loss: 0.2995 - val_accuracy: 0.8767\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 193us/step - loss: 0.2214 - accuracy: 0.9110 - val_loss: 0.2992 - val_accuracy: 0.8767\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 214us/step - loss: 0.2211 - accuracy: 0.9100 - val_loss: 0.2990 - val_accuracy: 0.8767\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 198us/step - loss: 0.2210 - accuracy: 0.9119 - val_loss: 0.2987 - val_accuracy: 0.8767\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 308us/step - loss: 0.2207 - accuracy: 0.9119 - val_loss: 0.2984 - val_accuracy: 0.8767\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 216us/step - loss: 0.2203 - accuracy: 0.9110 - val_loss: 0.2982 - val_accuracy: 0.8767\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 235us/step - loss: 0.2203 - accuracy: 0.9110 - val_loss: 0.2980 - val_accuracy: 0.8767\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 184us/step - loss: 0.2201 - accuracy: 0.9119 - val_loss: 0.2977 - val_accuracy: 0.8767\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 246us/step - loss: 0.2198 - accuracy: 0.9119 - val_loss: 0.2973 - val_accuracy: 0.8767\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 231us/step - loss: 0.2196 - accuracy: 0.9129 - val_loss: 0.2972 - val_accuracy: 0.8767\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 198us/step - loss: 0.2194 - accuracy: 0.9110 - val_loss: 0.2971 - val_accuracy: 0.8767\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 233us/step - loss: 0.2193 - accuracy: 0.9129 - val_loss: 0.2968 - val_accuracy: 0.8767\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 202us/step - loss: 0.2189 - accuracy: 0.9129 - val_loss: 0.2967 - val_accuracy: 0.8767\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 225us/step - loss: 0.2189 - accuracy: 0.9119 - val_loss: 0.2964 - val_accuracy: 0.8767\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 226us/step - loss: 0.2187 - accuracy: 0.9110 - val_loss: 0.2962 - val_accuracy: 0.8767\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 222us/step - loss: 0.2184 - accuracy: 0.9119 - val_loss: 0.2959 - val_accuracy: 0.8767\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 192us/step - loss: 0.2183 - accuracy: 0.9100 - val_loss: 0.2957 - val_accuracy: 0.8767\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 192us/step - loss: 0.2180 - accuracy: 0.9110 - val_loss: 0.2954 - val_accuracy: 0.8767\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 184us/step - loss: 0.2179 - accuracy: 0.9100 - val_loss: 0.2952 - val_accuracy: 0.8767\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 213us/step - loss: 0.2177 - accuracy: 0.9110 - val_loss: 0.2949 - val_accuracy: 0.8767\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 235us/step - loss: 0.2175 - accuracy: 0.9090 - val_loss: 0.2947 - val_accuracy: 0.8767\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 885us/step - loss: 0.6868 - accuracy: 0.5088 - val_loss: 0.6467 - val_accuracy: 0.5434\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 240us/step - loss: 0.6291 - accuracy: 0.6487 - val_loss: 0.6049 - val_accuracy: 0.6804\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 232us/step - loss: 0.5879 - accuracy: 0.7495 - val_loss: 0.5715 - val_accuracy: 0.7808\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 194us/step - loss: 0.5539 - accuracy: 0.8033 - val_loss: 0.5426 - val_accuracy: 0.8128\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 201us/step - loss: 0.5238 - accuracy: 0.8307 - val_loss: 0.5166 - val_accuracy: 0.8493\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 193us/step - loss: 0.4962 - accuracy: 0.8474 - val_loss: 0.4925 - val_accuracy: 0.8584\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 173us/step - loss: 0.4703 - accuracy: 0.8601 - val_loss: 0.4700 - val_accuracy: 0.8630\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 178us/step - loss: 0.4459 - accuracy: 0.8718 - val_loss: 0.4492 - val_accuracy: 0.8676\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 204us/step - loss: 0.4233 - accuracy: 0.8806 - val_loss: 0.4300 - val_accuracy: 0.8584\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 197us/step - loss: 0.4025 - accuracy: 0.8875 - val_loss: 0.4127 - val_accuracy: 0.8539\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 185us/step - loss: 0.3838 - accuracy: 0.8865 - val_loss: 0.3971 - val_accuracy: 0.8539\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 178us/step - loss: 0.3668 - accuracy: 0.8836 - val_loss: 0.3833 - val_accuracy: 0.8584\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 170us/step - loss: 0.3520 - accuracy: 0.8855 - val_loss: 0.3714 - val_accuracy: 0.8584\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 231us/step - loss: 0.3392 - accuracy: 0.8894 - val_loss: 0.3611 - val_accuracy: 0.8584\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 237us/step - loss: 0.3280 - accuracy: 0.8904 - val_loss: 0.3524 - val_accuracy: 0.8584\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 206us/step - loss: 0.3181 - accuracy: 0.8904 - val_loss: 0.3449 - val_accuracy: 0.8584\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.3096 - accuracy: 0.8904 - val_loss: 0.3385 - val_accuracy: 0.8584\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.3021 - accuracy: 0.8924 - val_loss: 0.3330 - val_accuracy: 0.8539\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2956 - accuracy: 0.8943 - val_loss: 0.3283 - val_accuracy: 0.8584\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.2900 - accuracy: 0.8973 - val_loss: 0.3242 - val_accuracy: 0.8584\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2850 - accuracy: 0.8992 - val_loss: 0.3207 - val_accuracy: 0.8584\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2806 - accuracy: 0.9002 - val_loss: 0.3177 - val_accuracy: 0.8630\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2766 - accuracy: 0.9002 - val_loss: 0.3151 - val_accuracy: 0.8721\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2731 - accuracy: 0.8982 - val_loss: 0.3128 - val_accuracy: 0.8721\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2699 - accuracy: 0.8992 - val_loss: 0.3109 - val_accuracy: 0.8721\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2670 - accuracy: 0.8973 - val_loss: 0.3092 - val_accuracy: 0.8721\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2646 - accuracy: 0.9002 - val_loss: 0.3077 - val_accuracy: 0.8676\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2622 - accuracy: 0.9002 - val_loss: 0.3064 - val_accuracy: 0.8676\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2601 - accuracy: 0.8992 - val_loss: 0.3053 - val_accuracy: 0.8676\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2581 - accuracy: 0.8992 - val_loss: 0.3043 - val_accuracy: 0.8676\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.2565 - accuracy: 0.9012 - val_loss: 0.3034 - val_accuracy: 0.8721\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2548 - accuracy: 0.9022 - val_loss: 0.3026 - val_accuracy: 0.8721\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2534 - accuracy: 0.9022 - val_loss: 0.3019 - val_accuracy: 0.8721\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.2519 - accuracy: 0.9012 - val_loss: 0.3012 - val_accuracy: 0.8767\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2507 - accuracy: 0.9012 - val_loss: 0.3007 - val_accuracy: 0.8813\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2494 - accuracy: 0.9022 - val_loss: 0.3001 - val_accuracy: 0.8813\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2482 - accuracy: 0.9022 - val_loss: 0.2997 - val_accuracy: 0.8767\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2472 - accuracy: 0.9012 - val_loss: 0.2994 - val_accuracy: 0.8767\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.2460 - accuracy: 0.9022 - val_loss: 0.2989 - val_accuracy: 0.8721\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2451 - accuracy: 0.9012 - val_loss: 0.2985 - val_accuracy: 0.8721\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2441 - accuracy: 0.9022 - val_loss: 0.2982 - val_accuracy: 0.8721\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2431 - accuracy: 0.9002 - val_loss: 0.2979 - val_accuracy: 0.8721\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2423 - accuracy: 0.9012 - val_loss: 0.2976 - val_accuracy: 0.8630\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2414 - accuracy: 0.9002 - val_loss: 0.2973 - val_accuracy: 0.8630\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.2405 - accuracy: 0.9012 - val_loss: 0.2970 - val_accuracy: 0.8630\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2397 - accuracy: 0.8992 - val_loss: 0.2968 - val_accuracy: 0.8630\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.2389 - accuracy: 0.9002 - val_loss: 0.2966 - val_accuracy: 0.8630\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2382 - accuracy: 0.9012 - val_loss: 0.2964 - val_accuracy: 0.8630\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.2376 - accuracy: 0.9012 - val_loss: 0.2962 - val_accuracy: 0.8539\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.2369 - accuracy: 0.9012 - val_loss: 0.2960 - val_accuracy: 0.8539\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2361 - accuracy: 0.9012 - val_loss: 0.2959 - val_accuracy: 0.8584\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2356 - accuracy: 0.9022 - val_loss: 0.2958 - val_accuracy: 0.8584\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.2349 - accuracy: 0.9041 - val_loss: 0.2956 - val_accuracy: 0.8584\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.2344 - accuracy: 0.9041 - val_loss: 0.2955 - val_accuracy: 0.8584\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2337 - accuracy: 0.9051 - val_loss: 0.2955 - val_accuracy: 0.8584\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2332 - accuracy: 0.9031 - val_loss: 0.2954 - val_accuracy: 0.8584\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2325 - accuracy: 0.9051 - val_loss: 0.2953 - val_accuracy: 0.8630\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2321 - accuracy: 0.9041 - val_loss: 0.2953 - val_accuracy: 0.8630\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2316 - accuracy: 0.9041 - val_loss: 0.2952 - val_accuracy: 0.8630\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.2310 - accuracy: 0.9041 - val_loss: 0.2951 - val_accuracy: 0.8630\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2306 - accuracy: 0.9022 - val_loss: 0.2950 - val_accuracy: 0.8630\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2301 - accuracy: 0.9041 - val_loss: 0.2949 - val_accuracy: 0.8630\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2296 - accuracy: 0.9041 - val_loss: 0.2948 - val_accuracy: 0.8584\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2292 - accuracy: 0.9051 - val_loss: 0.2947 - val_accuracy: 0.8584\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2287 - accuracy: 0.9070 - val_loss: 0.2945 - val_accuracy: 0.8584\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2283 - accuracy: 0.9041 - val_loss: 0.2944 - val_accuracy: 0.8584\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2279 - accuracy: 0.9070 - val_loss: 0.2942 - val_accuracy: 0.8584\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2275 - accuracy: 0.9051 - val_loss: 0.2940 - val_accuracy: 0.8584\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.2272 - accuracy: 0.9061 - val_loss: 0.2939 - val_accuracy: 0.8584\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2267 - accuracy: 0.9070 - val_loss: 0.2937 - val_accuracy: 0.8584\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2265 - accuracy: 0.9080 - val_loss: 0.2935 - val_accuracy: 0.8584\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2260 - accuracy: 0.9061 - val_loss: 0.2934 - val_accuracy: 0.8584\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2257 - accuracy: 0.9080 - val_loss: 0.2931 - val_accuracy: 0.8584\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2252 - accuracy: 0.9080 - val_loss: 0.2930 - val_accuracy: 0.8584\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2249 - accuracy: 0.9080 - val_loss: 0.2929 - val_accuracy: 0.8584\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2245 - accuracy: 0.9070 - val_loss: 0.2927 - val_accuracy: 0.8584\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2243 - accuracy: 0.9080 - val_loss: 0.2925 - val_accuracy: 0.8584\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2241 - accuracy: 0.9070 - val_loss: 0.2924 - val_accuracy: 0.8584\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2236 - accuracy: 0.9080 - val_loss: 0.2923 - val_accuracy: 0.8584\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.2234 - accuracy: 0.9080 - val_loss: 0.2922 - val_accuracy: 0.8584\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.2232 - accuracy: 0.9080 - val_loss: 0.2920 - val_accuracy: 0.8584\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2227 - accuracy: 0.9080 - val_loss: 0.2919 - val_accuracy: 0.8584\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2225 - accuracy: 0.9080 - val_loss: 0.2917 - val_accuracy: 0.8584\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2223 - accuracy: 0.9080 - val_loss: 0.2915 - val_accuracy: 0.8584\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2219 - accuracy: 0.9080 - val_loss: 0.2914 - val_accuracy: 0.8584\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2218 - accuracy: 0.9080 - val_loss: 0.2911 - val_accuracy: 0.8584\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2213 - accuracy: 0.9070 - val_loss: 0.2909 - val_accuracy: 0.8584\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2211 - accuracy: 0.9080 - val_loss: 0.2907 - val_accuracy: 0.8584\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2209 - accuracy: 0.9080 - val_loss: 0.2906 - val_accuracy: 0.8584\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 182us/step - loss: 0.2205 - accuracy: 0.9080 - val_loss: 0.2903 - val_accuracy: 0.8584\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2203 - accuracy: 0.9080 - val_loss: 0.2901 - val_accuracy: 0.8584\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 183us/step - loss: 0.2200 - accuracy: 0.9070 - val_loss: 0.2899 - val_accuracy: 0.8539\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.2197 - accuracy: 0.9080 - val_loss: 0.2897 - val_accuracy: 0.8539\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2195 - accuracy: 0.9080 - val_loss: 0.2896 - val_accuracy: 0.8539\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2192 - accuracy: 0.9080 - val_loss: 0.2894 - val_accuracy: 0.8539\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.2189 - accuracy: 0.9080 - val_loss: 0.2892 - val_accuracy: 0.8539\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.2187 - accuracy: 0.9080 - val_loss: 0.2891 - val_accuracy: 0.8539\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.2185 - accuracy: 0.9070 - val_loss: 0.2889 - val_accuracy: 0.8539\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2181 - accuracy: 0.9080 - val_loss: 0.2888 - val_accuracy: 0.8539\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2179 - accuracy: 0.9070 - val_loss: 0.2886 - val_accuracy: 0.8584\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.7632 - accuracy: 0.3434 - val_loss: 0.7136 - val_accuracy: 0.4795\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 466us/step - loss: 0.6869 - accuracy: 0.5519 - val_loss: 0.6570 - val_accuracy: 0.6393\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.6321 - accuracy: 0.7143 - val_loss: 0.6123 - val_accuracy: 0.7443\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.5864 - accuracy: 0.7710 - val_loss: 0.5734 - val_accuracy: 0.7808\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.5458 - accuracy: 0.7965 - val_loss: 0.5378 - val_accuracy: 0.8082\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.5088 - accuracy: 0.8151 - val_loss: 0.5046 - val_accuracy: 0.8174\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.4748 - accuracy: 0.8297 - val_loss: 0.4738 - val_accuracy: 0.8356\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.4429 - accuracy: 0.8434 - val_loss: 0.4451 - val_accuracy: 0.8539\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 190us/step - loss: 0.4140 - accuracy: 0.8601 - val_loss: 0.4194 - val_accuracy: 0.8676\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 179us/step - loss: 0.3884 - accuracy: 0.8738 - val_loss: 0.3969 - val_accuracy: 0.8630\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 197us/step - loss: 0.3661 - accuracy: 0.8757 - val_loss: 0.3776 - val_accuracy: 0.8630\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 203us/step - loss: 0.3466 - accuracy: 0.8816 - val_loss: 0.3613 - val_accuracy: 0.8630\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 234us/step - loss: 0.3298 - accuracy: 0.8836 - val_loss: 0.3478 - val_accuracy: 0.8676\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 290us/step - loss: 0.3156 - accuracy: 0.8885 - val_loss: 0.3364 - val_accuracy: 0.8630\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 346us/step - loss: 0.3034 - accuracy: 0.8973 - val_loss: 0.3270 - val_accuracy: 0.8630\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 330us/step - loss: 0.2932 - accuracy: 0.9012 - val_loss: 0.3193 - val_accuracy: 0.8584\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 309us/step - loss: 0.2846 - accuracy: 0.9041 - val_loss: 0.3131 - val_accuracy: 0.8493\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 179us/step - loss: 0.2772 - accuracy: 0.9022 - val_loss: 0.3079 - val_accuracy: 0.8493\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 406us/step - loss: 0.2710 - accuracy: 0.9012 - val_loss: 0.3036 - val_accuracy: 0.8584\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 412us/step - loss: 0.2658 - accuracy: 0.9012 - val_loss: 0.3003 - val_accuracy: 0.8584\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 228us/step - loss: 0.2613 - accuracy: 0.9022 - val_loss: 0.2974 - val_accuracy: 0.8584\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 395us/step - loss: 0.2575 - accuracy: 0.9022 - val_loss: 0.2952 - val_accuracy: 0.8584\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 299us/step - loss: 0.2542 - accuracy: 0.9041 - val_loss: 0.2933 - val_accuracy: 0.8584\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2513 - accuracy: 0.9041 - val_loss: 0.2917 - val_accuracy: 0.8584\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 213us/step - loss: 0.2488 - accuracy: 0.9061 - val_loss: 0.2903 - val_accuracy: 0.8584\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 206us/step - loss: 0.2465 - accuracy: 0.9061 - val_loss: 0.2891 - val_accuracy: 0.8630\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 275us/step - loss: 0.2445 - accuracy: 0.9061 - val_loss: 0.2880 - val_accuracy: 0.8630\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 185us/step - loss: 0.2427 - accuracy: 0.9070 - val_loss: 0.2871 - val_accuracy: 0.8630\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 420us/step - loss: 0.2411 - accuracy: 0.9051 - val_loss: 0.2862 - val_accuracy: 0.8630\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 337us/step - loss: 0.2398 - accuracy: 0.9061 - val_loss: 0.2855 - val_accuracy: 0.8630\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 284us/step - loss: 0.2384 - accuracy: 0.9070 - val_loss: 0.2848 - val_accuracy: 0.8630\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 288us/step - loss: 0.2372 - accuracy: 0.9080 - val_loss: 0.2840 - val_accuracy: 0.8630\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 343us/step - loss: 0.2360 - accuracy: 0.9080 - val_loss: 0.2834 - val_accuracy: 0.8630\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 232us/step - loss: 0.2351 - accuracy: 0.9100 - val_loss: 0.2827 - val_accuracy: 0.8584\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 295us/step - loss: 0.2341 - accuracy: 0.9100 - val_loss: 0.2821 - val_accuracy: 0.8584\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.2332 - accuracy: 0.9110 - val_loss: 0.2815 - val_accuracy: 0.8584\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 232us/step - loss: 0.2324 - accuracy: 0.9119 - val_loss: 0.2809 - val_accuracy: 0.8584\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 248us/step - loss: 0.2315 - accuracy: 0.9100 - val_loss: 0.2803 - val_accuracy: 0.8584\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 272us/step - loss: 0.2308 - accuracy: 0.9090 - val_loss: 0.2797 - val_accuracy: 0.8584\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 201us/step - loss: 0.2300 - accuracy: 0.9080 - val_loss: 0.2791 - val_accuracy: 0.8584\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2293 - accuracy: 0.9100 - val_loss: 0.2785 - val_accuracy: 0.8584\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 225us/step - loss: 0.2287 - accuracy: 0.9090 - val_loss: 0.2780 - val_accuracy: 0.8584\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 251us/step - loss: 0.2281 - accuracy: 0.9080 - val_loss: 0.2776 - val_accuracy: 0.8584\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2275 - accuracy: 0.9100 - val_loss: 0.2772 - val_accuracy: 0.8584\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 275us/step - loss: 0.2269 - accuracy: 0.9090 - val_loss: 0.2768 - val_accuracy: 0.8584\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 209us/step - loss: 0.2264 - accuracy: 0.9100 - val_loss: 0.2764 - val_accuracy: 0.8584\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 230us/step - loss: 0.2258 - accuracy: 0.9100 - val_loss: 0.2761 - val_accuracy: 0.8584\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 229us/step - loss: 0.2253 - accuracy: 0.9110 - val_loss: 0.2757 - val_accuracy: 0.8584\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 196us/step - loss: 0.2248 - accuracy: 0.9100 - val_loss: 0.2754 - val_accuracy: 0.8584\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 289us/step - loss: 0.2244 - accuracy: 0.9119 - val_loss: 0.2751 - val_accuracy: 0.8584\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 216us/step - loss: 0.2239 - accuracy: 0.9110 - val_loss: 0.2748 - val_accuracy: 0.8584\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 193us/step - loss: 0.2236 - accuracy: 0.9119 - val_loss: 0.2746 - val_accuracy: 0.8584\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 249us/step - loss: 0.2231 - accuracy: 0.9119 - val_loss: 0.2743 - val_accuracy: 0.8584\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.2226 - accuracy: 0.9119 - val_loss: 0.2740 - val_accuracy: 0.8630\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2223 - accuracy: 0.9119 - val_loss: 0.2738 - val_accuracy: 0.8630\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 175us/step - loss: 0.2218 - accuracy: 0.9119 - val_loss: 0.2735 - val_accuracy: 0.8630\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 268us/step - loss: 0.2214 - accuracy: 0.9119 - val_loss: 0.2733 - val_accuracy: 0.8630\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 269us/step - loss: 0.2211 - accuracy: 0.9129 - val_loss: 0.2730 - val_accuracy: 0.8630\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 187us/step - loss: 0.2207 - accuracy: 0.9129 - val_loss: 0.2727 - val_accuracy: 0.8630\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 186us/step - loss: 0.2203 - accuracy: 0.9129 - val_loss: 0.2725 - val_accuracy: 0.8630\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 202us/step - loss: 0.2200 - accuracy: 0.9119 - val_loss: 0.2723 - val_accuracy: 0.8630\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 167us/step - loss: 0.2196 - accuracy: 0.9129 - val_loss: 0.2721 - val_accuracy: 0.8630\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 195us/step - loss: 0.2193 - accuracy: 0.9129 - val_loss: 0.2719 - val_accuracy: 0.8630\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 277us/step - loss: 0.2190 - accuracy: 0.9129 - val_loss: 0.2715 - val_accuracy: 0.8630\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 235us/step - loss: 0.2185 - accuracy: 0.9129 - val_loss: 0.2713 - val_accuracy: 0.8630\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 258us/step - loss: 0.2183 - accuracy: 0.9139 - val_loss: 0.2711 - val_accuracy: 0.8630\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 244us/step - loss: 0.2179 - accuracy: 0.9129 - val_loss: 0.2708 - val_accuracy: 0.8630\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 240us/step - loss: 0.2176 - accuracy: 0.9139 - val_loss: 0.2706 - val_accuracy: 0.8630\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 176us/step - loss: 0.2173 - accuracy: 0.9139 - val_loss: 0.2703 - val_accuracy: 0.8630\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 215us/step - loss: 0.2169 - accuracy: 0.9129 - val_loss: 0.2701 - val_accuracy: 0.8630\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 176us/step - loss: 0.2166 - accuracy: 0.9129 - val_loss: 0.2700 - val_accuracy: 0.8630\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 263us/step - loss: 0.2163 - accuracy: 0.9139 - val_loss: 0.2699 - val_accuracy: 0.8630\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 276us/step - loss: 0.2161 - accuracy: 0.9129 - val_loss: 0.2697 - val_accuracy: 0.8630\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 247us/step - loss: 0.2158 - accuracy: 0.9149 - val_loss: 0.2696 - val_accuracy: 0.8630\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 188us/step - loss: 0.2154 - accuracy: 0.9139 - val_loss: 0.2695 - val_accuracy: 0.8630\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 221us/step - loss: 0.2152 - accuracy: 0.9149 - val_loss: 0.2693 - val_accuracy: 0.8630\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 324us/step - loss: 0.2148 - accuracy: 0.9139 - val_loss: 0.2691 - val_accuracy: 0.8630\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 333us/step - loss: 0.2146 - accuracy: 0.9139 - val_loss: 0.2690 - val_accuracy: 0.8630\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 390us/step - loss: 0.2142 - accuracy: 0.9149 - val_loss: 0.2688 - val_accuracy: 0.8630\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 198us/step - loss: 0.2140 - accuracy: 0.9139 - val_loss: 0.2687 - val_accuracy: 0.8630\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 199us/step - loss: 0.2137 - accuracy: 0.9129 - val_loss: 0.2685 - val_accuracy: 0.8630\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2134 - accuracy: 0.9139 - val_loss: 0.2685 - val_accuracy: 0.8630\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2132 - accuracy: 0.9159 - val_loss: 0.2684 - val_accuracy: 0.8630\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2130 - accuracy: 0.9159 - val_loss: 0.2682 - val_accuracy: 0.8630\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2128 - accuracy: 0.9149 - val_loss: 0.2681 - val_accuracy: 0.8676\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.2125 - accuracy: 0.9159 - val_loss: 0.2681 - val_accuracy: 0.8676\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.2122 - accuracy: 0.9168 - val_loss: 0.2680 - val_accuracy: 0.8676\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.2118 - accuracy: 0.9159 - val_loss: 0.2680 - val_accuracy: 0.8676\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2117 - accuracy: 0.9159 - val_loss: 0.2679 - val_accuracy: 0.8676\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2114 - accuracy: 0.9168 - val_loss: 0.2679 - val_accuracy: 0.8676\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2112 - accuracy: 0.9159 - val_loss: 0.2679 - val_accuracy: 0.8676\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2109 - accuracy: 0.9159 - val_loss: 0.2678 - val_accuracy: 0.8676\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2107 - accuracy: 0.9159 - val_loss: 0.2678 - val_accuracy: 0.8676\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2103 - accuracy: 0.9149 - val_loss: 0.2677 - val_accuracy: 0.8676\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2102 - accuracy: 0.9159 - val_loss: 0.2676 - val_accuracy: 0.8676\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2099 - accuracy: 0.9149 - val_loss: 0.2675 - val_accuracy: 0.8676\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2098 - accuracy: 0.9159 - val_loss: 0.2674 - val_accuracy: 0.8676\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2094 - accuracy: 0.9168 - val_loss: 0.2673 - val_accuracy: 0.8676\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2092 - accuracy: 0.9159 - val_loss: 0.2673 - val_accuracy: 0.8676\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2090 - accuracy: 0.9159 - val_loss: 0.2672 - val_accuracy: 0.8676\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 910us/step - loss: 0.6803 - accuracy: 0.5421 - val_loss: 0.6467 - val_accuracy: 0.6621\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 192us/step - loss: 0.6392 - accuracy: 0.6810 - val_loss: 0.6128 - val_accuracy: 0.7534\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.6040 - accuracy: 0.7750 - val_loss: 0.5819 - val_accuracy: 0.7945\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 185us/step - loss: 0.5714 - accuracy: 0.8082 - val_loss: 0.5524 - val_accuracy: 0.8447\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 198us/step - loss: 0.5402 - accuracy: 0.8376 - val_loss: 0.5236 - val_accuracy: 0.8767\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.5100 - accuracy: 0.8581 - val_loss: 0.4952 - val_accuracy: 0.8767\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 207us/step - loss: 0.4811 - accuracy: 0.8669 - val_loss: 0.4682 - val_accuracy: 0.8767\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 180us/step - loss: 0.4539 - accuracy: 0.8718 - val_loss: 0.4431 - val_accuracy: 0.8813\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.4287 - accuracy: 0.8757 - val_loss: 0.4199 - val_accuracy: 0.8813\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 176us/step - loss: 0.4055 - accuracy: 0.8787 - val_loss: 0.3988 - val_accuracy: 0.8813\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.3846 - accuracy: 0.8806 - val_loss: 0.3803 - val_accuracy: 0.8858\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.3656 - accuracy: 0.8836 - val_loss: 0.3643 - val_accuracy: 0.8858\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 169us/step - loss: 0.3489 - accuracy: 0.8885 - val_loss: 0.3506 - val_accuracy: 0.8904\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.3341 - accuracy: 0.8904 - val_loss: 0.3392 - val_accuracy: 0.8950\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.3213 - accuracy: 0.8943 - val_loss: 0.3297 - val_accuracy: 0.8904\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 168us/step - loss: 0.3102 - accuracy: 0.8963 - val_loss: 0.3219 - val_accuracy: 0.8858\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 168us/step - loss: 0.3003 - accuracy: 0.8982 - val_loss: 0.3152 - val_accuracy: 0.8858\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 178us/step - loss: 0.2917 - accuracy: 0.8982 - val_loss: 0.3097 - val_accuracy: 0.8858\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2841 - accuracy: 0.9002 - val_loss: 0.3050 - val_accuracy: 0.8813\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 179us/step - loss: 0.2774 - accuracy: 0.9022 - val_loss: 0.3013 - val_accuracy: 0.8858\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2716 - accuracy: 0.9051 - val_loss: 0.2984 - val_accuracy: 0.8858\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 179us/step - loss: 0.2666 - accuracy: 0.9100 - val_loss: 0.2958 - val_accuracy: 0.8858\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.2622 - accuracy: 0.9110 - val_loss: 0.2937 - val_accuracy: 0.8813\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 184us/step - loss: 0.2584 - accuracy: 0.9119 - val_loss: 0.2920 - val_accuracy: 0.8813\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 166us/step - loss: 0.2550 - accuracy: 0.9110 - val_loss: 0.2908 - val_accuracy: 0.8813\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.2517 - accuracy: 0.9110 - val_loss: 0.2894 - val_accuracy: 0.8813\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 168us/step - loss: 0.2491 - accuracy: 0.9100 - val_loss: 0.2884 - val_accuracy: 0.8813\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 173us/step - loss: 0.2464 - accuracy: 0.9080 - val_loss: 0.2877 - val_accuracy: 0.8858\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2442 - accuracy: 0.9100 - val_loss: 0.2872 - val_accuracy: 0.8858\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 275us/step - loss: 0.2422 - accuracy: 0.9090 - val_loss: 0.2866 - val_accuracy: 0.8858\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.2405 - accuracy: 0.9080 - val_loss: 0.2860 - val_accuracy: 0.8858\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2388 - accuracy: 0.9110 - val_loss: 0.2854 - val_accuracy: 0.8858\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2371 - accuracy: 0.9110 - val_loss: 0.2848 - val_accuracy: 0.8858\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2357 - accuracy: 0.9080 - val_loss: 0.2842 - val_accuracy: 0.8858\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 171us/step - loss: 0.2343 - accuracy: 0.9100 - val_loss: 0.2838 - val_accuracy: 0.8858\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2332 - accuracy: 0.9100 - val_loss: 0.2833 - val_accuracy: 0.8858\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2319 - accuracy: 0.9080 - val_loss: 0.2827 - val_accuracy: 0.8858\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 166us/step - loss: 0.2309 - accuracy: 0.9090 - val_loss: 0.2822 - val_accuracy: 0.8858\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2297 - accuracy: 0.9070 - val_loss: 0.2817 - val_accuracy: 0.8858\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2286 - accuracy: 0.9100 - val_loss: 0.2810 - val_accuracy: 0.8858\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2277 - accuracy: 0.9100 - val_loss: 0.2805 - val_accuracy: 0.8858\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2266 - accuracy: 0.9100 - val_loss: 0.2801 - val_accuracy: 0.8858\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2258 - accuracy: 0.9110 - val_loss: 0.2795 - val_accuracy: 0.8858\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2251 - accuracy: 0.9110 - val_loss: 0.2790 - val_accuracy: 0.8858\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2243 - accuracy: 0.9110 - val_loss: 0.2785 - val_accuracy: 0.8858\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2235 - accuracy: 0.9119 - val_loss: 0.2781 - val_accuracy: 0.8858\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2227 - accuracy: 0.9119 - val_loss: 0.2777 - val_accuracy: 0.8858\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2221 - accuracy: 0.9139 - val_loss: 0.2774 - val_accuracy: 0.8858\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.2214 - accuracy: 0.9139 - val_loss: 0.2770 - val_accuracy: 0.8858\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2208 - accuracy: 0.9149 - val_loss: 0.2767 - val_accuracy: 0.8858\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2201 - accuracy: 0.9159 - val_loss: 0.2763 - val_accuracy: 0.8858\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2195 - accuracy: 0.9159 - val_loss: 0.2759 - val_accuracy: 0.8858\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2189 - accuracy: 0.9149 - val_loss: 0.2755 - val_accuracy: 0.8858\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2184 - accuracy: 0.9139 - val_loss: 0.2753 - val_accuracy: 0.8858\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2178 - accuracy: 0.9149 - val_loss: 0.2751 - val_accuracy: 0.8858\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2173 - accuracy: 0.9159 - val_loss: 0.2747 - val_accuracy: 0.8858\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2166 - accuracy: 0.9149 - val_loss: 0.2745 - val_accuracy: 0.8858\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.2160 - accuracy: 0.9159 - val_loss: 0.2742 - val_accuracy: 0.8858\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2156 - accuracy: 0.9159 - val_loss: 0.2738 - val_accuracy: 0.8858\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2150 - accuracy: 0.9178 - val_loss: 0.2735 - val_accuracy: 0.8858\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2145 - accuracy: 0.9168 - val_loss: 0.2735 - val_accuracy: 0.8858\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2140 - accuracy: 0.9168 - val_loss: 0.2733 - val_accuracy: 0.8858\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2134 - accuracy: 0.9168 - val_loss: 0.2732 - val_accuracy: 0.8858\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2130 - accuracy: 0.9168 - val_loss: 0.2728 - val_accuracy: 0.8858\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2124 - accuracy: 0.9168 - val_loss: 0.2725 - val_accuracy: 0.8858\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2121 - accuracy: 0.9168 - val_loss: 0.2723 - val_accuracy: 0.8858\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2114 - accuracy: 0.9168 - val_loss: 0.2720 - val_accuracy: 0.8858\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2110 - accuracy: 0.9168 - val_loss: 0.2719 - val_accuracy: 0.8813\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2105 - accuracy: 0.9178 - val_loss: 0.2717 - val_accuracy: 0.8813\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2101 - accuracy: 0.9188 - val_loss: 0.2716 - val_accuracy: 0.8767\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2096 - accuracy: 0.9178 - val_loss: 0.2714 - val_accuracy: 0.8767\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.2092 - accuracy: 0.9178 - val_loss: 0.2712 - val_accuracy: 0.8767\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2087 - accuracy: 0.9178 - val_loss: 0.2710 - val_accuracy: 0.8767\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2084 - accuracy: 0.9178 - val_loss: 0.2709 - val_accuracy: 0.8767\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2080 - accuracy: 0.9188 - val_loss: 0.2708 - val_accuracy: 0.8767\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2076 - accuracy: 0.9168 - val_loss: 0.2706 - val_accuracy: 0.8767\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2071 - accuracy: 0.9178 - val_loss: 0.2704 - val_accuracy: 0.8767\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2066 - accuracy: 0.9168 - val_loss: 0.2704 - val_accuracy: 0.8767\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.2063 - accuracy: 0.9178 - val_loss: 0.2705 - val_accuracy: 0.8767\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2059 - accuracy: 0.9178 - val_loss: 0.2702 - val_accuracy: 0.8767\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2056 - accuracy: 0.9178 - val_loss: 0.2701 - val_accuracy: 0.8767\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2053 - accuracy: 0.9178 - val_loss: 0.2700 - val_accuracy: 0.8767\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2048 - accuracy: 0.9159 - val_loss: 0.2699 - val_accuracy: 0.8767\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2045 - accuracy: 0.9178 - val_loss: 0.2698 - val_accuracy: 0.8767\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2041 - accuracy: 0.9178 - val_loss: 0.2698 - val_accuracy: 0.8767\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2038 - accuracy: 0.9178 - val_loss: 0.2697 - val_accuracy: 0.8767\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2035 - accuracy: 0.9168 - val_loss: 0.2696 - val_accuracy: 0.8767\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2032 - accuracy: 0.9178 - val_loss: 0.2696 - val_accuracy: 0.8767\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2028 - accuracy: 0.9178 - val_loss: 0.2693 - val_accuracy: 0.8767\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2025 - accuracy: 0.9178 - val_loss: 0.2692 - val_accuracy: 0.8767\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2021 - accuracy: 0.9178 - val_loss: 0.2692 - val_accuracy: 0.8767\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2018 - accuracy: 0.9178 - val_loss: 0.2692 - val_accuracy: 0.8767\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2015 - accuracy: 0.9188 - val_loss: 0.2692 - val_accuracy: 0.8767\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2013 - accuracy: 0.9188 - val_loss: 0.2691 - val_accuracy: 0.8767\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2011 - accuracy: 0.9178 - val_loss: 0.2690 - val_accuracy: 0.8767\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2008 - accuracy: 0.9159 - val_loss: 0.2690 - val_accuracy: 0.8767\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2004 - accuracy: 0.9168 - val_loss: 0.2688 - val_accuracy: 0.8767\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2001 - accuracy: 0.9178 - val_loss: 0.2689 - val_accuracy: 0.8767\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.1998 - accuracy: 0.9178 - val_loss: 0.2688 - val_accuracy: 0.8767\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.1996 - accuracy: 0.9198 - val_loss: 0.2687 - val_accuracy: 0.8767\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 902us/step - loss: 0.7815 - accuracy: 0.4432 - val_loss: 0.7407 - val_accuracy: 0.4612\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.7295 - accuracy: 0.4755 - val_loss: 0.7096 - val_accuracy: 0.5160\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.7024 - accuracy: 0.5284 - val_loss: 0.6894 - val_accuracy: 0.5799\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.6826 - accuracy: 0.5773 - val_loss: 0.6731 - val_accuracy: 0.6438\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 96us/step - loss: 0.6656 - accuracy: 0.6301 - val_loss: 0.6580 - val_accuracy: 0.6712\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.6489 - accuracy: 0.6928 - val_loss: 0.6430 - val_accuracy: 0.7215\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.6317 - accuracy: 0.7358 - val_loss: 0.6269 - val_accuracy: 0.7534\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.6135 - accuracy: 0.7593 - val_loss: 0.6095 - val_accuracy: 0.7626\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.5939 - accuracy: 0.7779 - val_loss: 0.5909 - val_accuracy: 0.7900\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.5737 - accuracy: 0.7896 - val_loss: 0.5718 - val_accuracy: 0.8037\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.5532 - accuracy: 0.8102 - val_loss: 0.5530 - val_accuracy: 0.8128\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.5330 - accuracy: 0.8219 - val_loss: 0.5352 - val_accuracy: 0.8128\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.5137 - accuracy: 0.8297 - val_loss: 0.5183 - val_accuracy: 0.8311\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.4959 - accuracy: 0.8444 - val_loss: 0.5029 - val_accuracy: 0.8356\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.4793 - accuracy: 0.8601 - val_loss: 0.4886 - val_accuracy: 0.8356\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.4643 - accuracy: 0.8640 - val_loss: 0.4756 - val_accuracy: 0.8402\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.4505 - accuracy: 0.8679 - val_loss: 0.4637 - val_accuracy: 0.8447\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.4379 - accuracy: 0.8689 - val_loss: 0.4529 - val_accuracy: 0.8539\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.4263 - accuracy: 0.8757 - val_loss: 0.4430 - val_accuracy: 0.8584\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.4156 - accuracy: 0.8796 - val_loss: 0.4340 - val_accuracy: 0.8584\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.4058 - accuracy: 0.8806 - val_loss: 0.4255 - val_accuracy: 0.8584\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.3966 - accuracy: 0.8855 - val_loss: 0.4178 - val_accuracy: 0.8584\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.3881 - accuracy: 0.8875 - val_loss: 0.4107 - val_accuracy: 0.8584\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.3803 - accuracy: 0.8914 - val_loss: 0.4040 - val_accuracy: 0.8584\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.3730 - accuracy: 0.8933 - val_loss: 0.3978 - val_accuracy: 0.8539\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.3662 - accuracy: 0.8963 - val_loss: 0.3920 - val_accuracy: 0.8584\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.3599 - accuracy: 0.8982 - val_loss: 0.3866 - val_accuracy: 0.8584\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.3539 - accuracy: 0.8992 - val_loss: 0.3815 - val_accuracy: 0.8584\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.3482 - accuracy: 0.8973 - val_loss: 0.3768 - val_accuracy: 0.8584\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.3429 - accuracy: 0.8992 - val_loss: 0.3723 - val_accuracy: 0.8584\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.3380 - accuracy: 0.9002 - val_loss: 0.3682 - val_accuracy: 0.8584\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.3333 - accuracy: 0.9002 - val_loss: 0.3641 - val_accuracy: 0.8584\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.3288 - accuracy: 0.9002 - val_loss: 0.3604 - val_accuracy: 0.8630\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.3246 - accuracy: 0.9012 - val_loss: 0.3568 - val_accuracy: 0.8676\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.3207 - accuracy: 0.9002 - val_loss: 0.3535 - val_accuracy: 0.8676\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.3169 - accuracy: 0.9012 - val_loss: 0.3503 - val_accuracy: 0.8676\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.3133 - accuracy: 0.9012 - val_loss: 0.3474 - val_accuracy: 0.8676\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.3099 - accuracy: 0.9031 - val_loss: 0.3446 - val_accuracy: 0.8676\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.3068 - accuracy: 0.9031 - val_loss: 0.3420 - val_accuracy: 0.8630\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.3037 - accuracy: 0.9022 - val_loss: 0.3395 - val_accuracy: 0.8630\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.3008 - accuracy: 0.9051 - val_loss: 0.3369 - val_accuracy: 0.8630\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2980 - accuracy: 0.9041 - val_loss: 0.3345 - val_accuracy: 0.8630\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2954 - accuracy: 0.9022 - val_loss: 0.3321 - val_accuracy: 0.8676\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2928 - accuracy: 0.9041 - val_loss: 0.3298 - val_accuracy: 0.8721\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2904 - accuracy: 0.9022 - val_loss: 0.3277 - val_accuracy: 0.8721\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2880 - accuracy: 0.9022 - val_loss: 0.3258 - val_accuracy: 0.8676\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2858 - accuracy: 0.9031 - val_loss: 0.3238 - val_accuracy: 0.8676\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2838 - accuracy: 0.9051 - val_loss: 0.3217 - val_accuracy: 0.8721\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2817 - accuracy: 0.9070 - val_loss: 0.3200 - val_accuracy: 0.8721\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2798 - accuracy: 0.9080 - val_loss: 0.3183 - val_accuracy: 0.8676\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2780 - accuracy: 0.9070 - val_loss: 0.3167 - val_accuracy: 0.8676\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2761 - accuracy: 0.9090 - val_loss: 0.3151 - val_accuracy: 0.8676\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2744 - accuracy: 0.9090 - val_loss: 0.3135 - val_accuracy: 0.8721\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2727 - accuracy: 0.9080 - val_loss: 0.3117 - val_accuracy: 0.8721\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2711 - accuracy: 0.9100 - val_loss: 0.3104 - val_accuracy: 0.8721\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.2696 - accuracy: 0.9100 - val_loss: 0.3090 - val_accuracy: 0.8721\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2681 - accuracy: 0.9100 - val_loss: 0.3077 - val_accuracy: 0.8767\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2666 - accuracy: 0.9100 - val_loss: 0.3063 - val_accuracy: 0.8767\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 164us/step - loss: 0.2653 - accuracy: 0.9090 - val_loss: 0.3050 - val_accuracy: 0.8767\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2639 - accuracy: 0.9100 - val_loss: 0.3038 - val_accuracy: 0.8767\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.2627 - accuracy: 0.9100 - val_loss: 0.3027 - val_accuracy: 0.8767\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2615 - accuracy: 0.9100 - val_loss: 0.3015 - val_accuracy: 0.8813\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2603 - accuracy: 0.9100 - val_loss: 0.3005 - val_accuracy: 0.8813\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 173us/step - loss: 0.2592 - accuracy: 0.9100 - val_loss: 0.2994 - val_accuracy: 0.8813\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2581 - accuracy: 0.9090 - val_loss: 0.2985 - val_accuracy: 0.8813\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2570 - accuracy: 0.9100 - val_loss: 0.2976 - val_accuracy: 0.8813\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2560 - accuracy: 0.9100 - val_loss: 0.2968 - val_accuracy: 0.8813\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 230us/step - loss: 0.2550 - accuracy: 0.9100 - val_loss: 0.2959 - val_accuracy: 0.8813\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.2541 - accuracy: 0.9119 - val_loss: 0.2948 - val_accuracy: 0.8813\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 166us/step - loss: 0.2532 - accuracy: 0.9090 - val_loss: 0.2941 - val_accuracy: 0.8813\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2522 - accuracy: 0.9090 - val_loss: 0.2933 - val_accuracy: 0.8813\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2514 - accuracy: 0.9110 - val_loss: 0.2924 - val_accuracy: 0.8813\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2506 - accuracy: 0.9100 - val_loss: 0.2917 - val_accuracy: 0.8813\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2498 - accuracy: 0.9110 - val_loss: 0.2909 - val_accuracy: 0.8813\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.2489 - accuracy: 0.9100 - val_loss: 0.2902 - val_accuracy: 0.8813\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2481 - accuracy: 0.9090 - val_loss: 0.2895 - val_accuracy: 0.8858\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2474 - accuracy: 0.9100 - val_loss: 0.2892 - val_accuracy: 0.8813\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2467 - accuracy: 0.9100 - val_loss: 0.2886 - val_accuracy: 0.8904\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.2459 - accuracy: 0.9119 - val_loss: 0.2880 - val_accuracy: 0.8904\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2453 - accuracy: 0.9129 - val_loss: 0.2874 - val_accuracy: 0.8904\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2446 - accuracy: 0.9119 - val_loss: 0.2868 - val_accuracy: 0.8904\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2439 - accuracy: 0.9129 - val_loss: 0.2862 - val_accuracy: 0.8904\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2432 - accuracy: 0.9129 - val_loss: 0.2857 - val_accuracy: 0.8904\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.2427 - accuracy: 0.9129 - val_loss: 0.2850 - val_accuracy: 0.8904\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2420 - accuracy: 0.9139 - val_loss: 0.2844 - val_accuracy: 0.8904\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2415 - accuracy: 0.9119 - val_loss: 0.2839 - val_accuracy: 0.8904\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2409 - accuracy: 0.9119 - val_loss: 0.2835 - val_accuracy: 0.8904\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2403 - accuracy: 0.9119 - val_loss: 0.2830 - val_accuracy: 0.8904\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2397 - accuracy: 0.9129 - val_loss: 0.2826 - val_accuracy: 0.8904\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2392 - accuracy: 0.9129 - val_loss: 0.2821 - val_accuracy: 0.8950\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.2387 - accuracy: 0.9129 - val_loss: 0.2819 - val_accuracy: 0.8950\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2381 - accuracy: 0.9139 - val_loss: 0.2814 - val_accuracy: 0.8950\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2376 - accuracy: 0.9139 - val_loss: 0.2810 - val_accuracy: 0.8950\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2371 - accuracy: 0.9139 - val_loss: 0.2807 - val_accuracy: 0.8950\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2367 - accuracy: 0.9139 - val_loss: 0.2803 - val_accuracy: 0.8950\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2362 - accuracy: 0.9139 - val_loss: 0.2801 - val_accuracy: 0.8950\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2358 - accuracy: 0.9139 - val_loss: 0.2798 - val_accuracy: 0.8950\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2353 - accuracy: 0.9139 - val_loss: 0.2796 - val_accuracy: 0.8950\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 167us/step - loss: 0.2348 - accuracy: 0.9139 - val_loss: 0.2792 - val_accuracy: 0.8950\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 164us/step - loss: 0.2343 - accuracy: 0.9139 - val_loss: 0.2790 - val_accuracy: 0.8950\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 1s 793us/step - loss: 0.7011 - accuracy: 0.4883 - val_loss: 0.6922 - val_accuracy: 0.5388\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.6701 - accuracy: 0.5352 - val_loss: 0.6676 - val_accuracy: 0.5936\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.6455 - accuracy: 0.6233 - val_loss: 0.6469 - val_accuracy: 0.6712\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.6238 - accuracy: 0.8072 - val_loss: 0.6279 - val_accuracy: 0.7808\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.6035 - accuracy: 0.8346 - val_loss: 0.6096 - val_accuracy: 0.7945\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.5835 - accuracy: 0.8415 - val_loss: 0.5917 - val_accuracy: 0.8037\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.5636 - accuracy: 0.8444 - val_loss: 0.5742 - val_accuracy: 0.8082\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.5434 - accuracy: 0.8464 - val_loss: 0.5565 - val_accuracy: 0.8082\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.5226 - accuracy: 0.8464 - val_loss: 0.5387 - val_accuracy: 0.8082\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.5014 - accuracy: 0.8523 - val_loss: 0.5204 - val_accuracy: 0.8174\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.4798 - accuracy: 0.8630 - val_loss: 0.5019 - val_accuracy: 0.8311\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.4573 - accuracy: 0.8669 - val_loss: 0.4832 - val_accuracy: 0.8265\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.4342 - accuracy: 0.8689 - val_loss: 0.4645 - val_accuracy: 0.8265\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.4118 - accuracy: 0.8738 - val_loss: 0.4465 - val_accuracy: 0.8311\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 172us/step - loss: 0.3907 - accuracy: 0.8767 - val_loss: 0.4305 - val_accuracy: 0.8311\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.3716 - accuracy: 0.8806 - val_loss: 0.4165 - val_accuracy: 0.8311\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.3548 - accuracy: 0.8855 - val_loss: 0.4049 - val_accuracy: 0.8311\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 210us/step - loss: 0.3402 - accuracy: 0.8865 - val_loss: 0.3945 - val_accuracy: 0.8311\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.3276 - accuracy: 0.8875 - val_loss: 0.3858 - val_accuracy: 0.8311\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.3166 - accuracy: 0.8885 - val_loss: 0.3784 - val_accuracy: 0.8356\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.3074 - accuracy: 0.8885 - val_loss: 0.3721 - val_accuracy: 0.8402\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2993 - accuracy: 0.8875 - val_loss: 0.3666 - val_accuracy: 0.8402\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2926 - accuracy: 0.8885 - val_loss: 0.3618 - val_accuracy: 0.8402\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2868 - accuracy: 0.8885 - val_loss: 0.3574 - val_accuracy: 0.8447\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2816 - accuracy: 0.8875 - val_loss: 0.3537 - val_accuracy: 0.8447\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2769 - accuracy: 0.8894 - val_loss: 0.3499 - val_accuracy: 0.8493\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2725 - accuracy: 0.8885 - val_loss: 0.3466 - val_accuracy: 0.8447\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2685 - accuracy: 0.8914 - val_loss: 0.3431 - val_accuracy: 0.8447\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2648 - accuracy: 0.8914 - val_loss: 0.3396 - val_accuracy: 0.8493\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2616 - accuracy: 0.8943 - val_loss: 0.3370 - val_accuracy: 0.8493\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2589 - accuracy: 0.8924 - val_loss: 0.3348 - val_accuracy: 0.8493\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2564 - accuracy: 0.8943 - val_loss: 0.3330 - val_accuracy: 0.8493\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2541 - accuracy: 0.8953 - val_loss: 0.3312 - val_accuracy: 0.8493\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2520 - accuracy: 0.8963 - val_loss: 0.3296 - val_accuracy: 0.8493\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2500 - accuracy: 0.8963 - val_loss: 0.3281 - val_accuracy: 0.8447\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2481 - accuracy: 0.8973 - val_loss: 0.3268 - val_accuracy: 0.8447\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2465 - accuracy: 0.8973 - val_loss: 0.3255 - val_accuracy: 0.8447\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2450 - accuracy: 0.8982 - val_loss: 0.3243 - val_accuracy: 0.8447\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2436 - accuracy: 0.8982 - val_loss: 0.3231 - val_accuracy: 0.8447\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2422 - accuracy: 0.8973 - val_loss: 0.3219 - val_accuracy: 0.8493\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2409 - accuracy: 0.8992 - val_loss: 0.3207 - val_accuracy: 0.8493\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2399 - accuracy: 0.8982 - val_loss: 0.3196 - val_accuracy: 0.8493\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2387 - accuracy: 0.8992 - val_loss: 0.3185 - val_accuracy: 0.8493\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2376 - accuracy: 0.8992 - val_loss: 0.3174 - val_accuracy: 0.8493\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2365 - accuracy: 0.8992 - val_loss: 0.3164 - val_accuracy: 0.8493\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2355 - accuracy: 0.8992 - val_loss: 0.3154 - val_accuracy: 0.8493\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2347 - accuracy: 0.9002 - val_loss: 0.3145 - val_accuracy: 0.8493\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2339 - accuracy: 0.9002 - val_loss: 0.3135 - val_accuracy: 0.8493\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2331 - accuracy: 0.9012 - val_loss: 0.3125 - val_accuracy: 0.8493\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2324 - accuracy: 0.9012 - val_loss: 0.3116 - val_accuracy: 0.8493\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2315 - accuracy: 0.9002 - val_loss: 0.3107 - val_accuracy: 0.8493\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2309 - accuracy: 0.9022 - val_loss: 0.3098 - val_accuracy: 0.8447\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2302 - accuracy: 0.9022 - val_loss: 0.3091 - val_accuracy: 0.8447\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2296 - accuracy: 0.9022 - val_loss: 0.3082 - val_accuracy: 0.8447\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2289 - accuracy: 0.9022 - val_loss: 0.3075 - val_accuracy: 0.8447\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2284 - accuracy: 0.9012 - val_loss: 0.3067 - val_accuracy: 0.8493\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2277 - accuracy: 0.9012 - val_loss: 0.3060 - val_accuracy: 0.8447\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2271 - accuracy: 0.9022 - val_loss: 0.3052 - val_accuracy: 0.8493\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2267 - accuracy: 0.9022 - val_loss: 0.3045 - val_accuracy: 0.8493\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2262 - accuracy: 0.9051 - val_loss: 0.3038 - val_accuracy: 0.8539\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2257 - accuracy: 0.9051 - val_loss: 0.3032 - val_accuracy: 0.8584\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2253 - accuracy: 0.9061 - val_loss: 0.3026 - val_accuracy: 0.8584\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2247 - accuracy: 0.9070 - val_loss: 0.3019 - val_accuracy: 0.8584\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2243 - accuracy: 0.9080 - val_loss: 0.3014 - val_accuracy: 0.8630\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2239 - accuracy: 0.9070 - val_loss: 0.3008 - val_accuracy: 0.8630\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2234 - accuracy: 0.9080 - val_loss: 0.3004 - val_accuracy: 0.8630\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2231 - accuracy: 0.9100 - val_loss: 0.2998 - val_accuracy: 0.8630\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2226 - accuracy: 0.9090 - val_loss: 0.2993 - val_accuracy: 0.8630\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2222 - accuracy: 0.9070 - val_loss: 0.2990 - val_accuracy: 0.8630\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2220 - accuracy: 0.9080 - val_loss: 0.2986 - val_accuracy: 0.8630\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.2215 - accuracy: 0.9080 - val_loss: 0.2981 - val_accuracy: 0.8630\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2210 - accuracy: 0.9090 - val_loss: 0.2976 - val_accuracy: 0.8630\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.2207 - accuracy: 0.9070 - val_loss: 0.2971 - val_accuracy: 0.8630\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2204 - accuracy: 0.9080 - val_loss: 0.2967 - val_accuracy: 0.8630\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2201 - accuracy: 0.9070 - val_loss: 0.2963 - val_accuracy: 0.8630\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2197 - accuracy: 0.9080 - val_loss: 0.2958 - val_accuracy: 0.8630\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2195 - accuracy: 0.9080 - val_loss: 0.2954 - val_accuracy: 0.8630\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.2191 - accuracy: 0.9070 - val_loss: 0.2951 - val_accuracy: 0.8630\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2188 - accuracy: 0.9080 - val_loss: 0.2947 - val_accuracy: 0.8630\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2186 - accuracy: 0.9080 - val_loss: 0.2942 - val_accuracy: 0.8630\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.2182 - accuracy: 0.9090 - val_loss: 0.2938 - val_accuracy: 0.8630\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2179 - accuracy: 0.9090 - val_loss: 0.2934 - val_accuracy: 0.8630\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2177 - accuracy: 0.9080 - val_loss: 0.2929 - val_accuracy: 0.8630\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2173 - accuracy: 0.9070 - val_loss: 0.2925 - val_accuracy: 0.8630\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.2170 - accuracy: 0.9080 - val_loss: 0.2922 - val_accuracy: 0.8630\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2169 - accuracy: 0.9080 - val_loss: 0.2919 - val_accuracy: 0.8676\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2166 - accuracy: 0.9080 - val_loss: 0.2914 - val_accuracy: 0.8630\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2163 - accuracy: 0.9080 - val_loss: 0.2911 - val_accuracy: 0.8676\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2161 - accuracy: 0.9080 - val_loss: 0.2907 - val_accuracy: 0.8721\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2158 - accuracy: 0.9080 - val_loss: 0.2903 - val_accuracy: 0.8721\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2156 - accuracy: 0.9070 - val_loss: 0.2900 - val_accuracy: 0.8721\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2153 - accuracy: 0.9080 - val_loss: 0.2896 - val_accuracy: 0.8721\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2150 - accuracy: 0.9080 - val_loss: 0.2892 - val_accuracy: 0.8721\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2148 - accuracy: 0.9080 - val_loss: 0.2889 - val_accuracy: 0.8721\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2146 - accuracy: 0.9070 - val_loss: 0.2885 - val_accuracy: 0.8767\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2142 - accuracy: 0.9090 - val_loss: 0.2881 - val_accuracy: 0.8767\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2141 - accuracy: 0.9080 - val_loss: 0.2879 - val_accuracy: 0.8767\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2140 - accuracy: 0.9090 - val_loss: 0.2877 - val_accuracy: 0.8767\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2137 - accuracy: 0.9080 - val_loss: 0.2873 - val_accuracy: 0.8767\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 311us/step - loss: 0.2133 - accuracy: 0.9100 - val_loss: 0.2871 - val_accuracy: 0.8767\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 895us/step - loss: 0.7253 - accuracy: 0.4814 - val_loss: 0.6762 - val_accuracy: 0.5114\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 210us/step - loss: 0.6542 - accuracy: 0.5744 - val_loss: 0.6293 - val_accuracy: 0.6438\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 211us/step - loss: 0.6111 - accuracy: 0.6957 - val_loss: 0.5954 - val_accuracy: 0.7534\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 186us/step - loss: 0.5768 - accuracy: 0.7642 - val_loss: 0.5655 - val_accuracy: 0.8128\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.5453 - accuracy: 0.7935 - val_loss: 0.5370 - val_accuracy: 0.8402\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.5151 - accuracy: 0.8151 - val_loss: 0.5091 - val_accuracy: 0.8447\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.4862 - accuracy: 0.8268 - val_loss: 0.4821 - val_accuracy: 0.8584\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.4587 - accuracy: 0.8366 - val_loss: 0.4566 - val_accuracy: 0.8630\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.4331 - accuracy: 0.8444 - val_loss: 0.4330 - val_accuracy: 0.8630\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.4095 - accuracy: 0.8571 - val_loss: 0.4115 - val_accuracy: 0.8630\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.3878 - accuracy: 0.8611 - val_loss: 0.3922 - val_accuracy: 0.8584\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.3686 - accuracy: 0.8679 - val_loss: 0.3750 - val_accuracy: 0.8676\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.3515 - accuracy: 0.8718 - val_loss: 0.3602 - val_accuracy: 0.8630\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.3364 - accuracy: 0.8757 - val_loss: 0.3475 - val_accuracy: 0.8630\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.3233 - accuracy: 0.8767 - val_loss: 0.3365 - val_accuracy: 0.8676\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.3119 - accuracy: 0.8796 - val_loss: 0.3271 - val_accuracy: 0.8676\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.3020 - accuracy: 0.8836 - val_loss: 0.3190 - val_accuracy: 0.8676\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2933 - accuracy: 0.8845 - val_loss: 0.3120 - val_accuracy: 0.8721\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2857 - accuracy: 0.8894 - val_loss: 0.3062 - val_accuracy: 0.8767\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2790 - accuracy: 0.8885 - val_loss: 0.3011 - val_accuracy: 0.8767\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2731 - accuracy: 0.8963 - val_loss: 0.2969 - val_accuracy: 0.8721\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - ETA: 0s - loss: 0.2868 - accuracy: 0.88 - 0s 147us/step - loss: 0.2680 - accuracy: 0.8963 - val_loss: 0.2931 - val_accuracy: 0.8721\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2635 - accuracy: 0.9002 - val_loss: 0.2899 - val_accuracy: 0.8721\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2594 - accuracy: 0.8992 - val_loss: 0.2871 - val_accuracy: 0.8721\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2559 - accuracy: 0.8992 - val_loss: 0.2847 - val_accuracy: 0.8539\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.2528 - accuracy: 0.8992 - val_loss: 0.2827 - val_accuracy: 0.8493\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2501 - accuracy: 0.8953 - val_loss: 0.2810 - val_accuracy: 0.8493\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2478 - accuracy: 0.8963 - val_loss: 0.2796 - val_accuracy: 0.8493\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2456 - accuracy: 0.8953 - val_loss: 0.2784 - val_accuracy: 0.8447\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2437 - accuracy: 0.8973 - val_loss: 0.2773 - val_accuracy: 0.8447\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.2420 - accuracy: 0.8963 - val_loss: 0.2764 - val_accuracy: 0.8447\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2405 - accuracy: 0.9031 - val_loss: 0.2755 - val_accuracy: 0.8493\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.2391 - accuracy: 0.8982 - val_loss: 0.2748 - val_accuracy: 0.8539\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2378 - accuracy: 0.8982 - val_loss: 0.2741 - val_accuracy: 0.8539\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.2366 - accuracy: 0.9012 - val_loss: 0.2735 - val_accuracy: 0.8584\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.2355 - accuracy: 0.9012 - val_loss: 0.2730 - val_accuracy: 0.8584\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 166us/step - loss: 0.2345 - accuracy: 0.9022 - val_loss: 0.2725 - val_accuracy: 0.8630\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 170us/step - loss: 0.2336 - accuracy: 0.9031 - val_loss: 0.2720 - val_accuracy: 0.8630\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 173us/step - loss: 0.2328 - accuracy: 0.9012 - val_loss: 0.2716 - val_accuracy: 0.8630\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 164us/step - loss: 0.2320 - accuracy: 0.9041 - val_loss: 0.2712 - val_accuracy: 0.8721\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2313 - accuracy: 0.9031 - val_loss: 0.2708 - val_accuracy: 0.8721\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2305 - accuracy: 0.9031 - val_loss: 0.2705 - val_accuracy: 0.8721\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2299 - accuracy: 0.9031 - val_loss: 0.2702 - val_accuracy: 0.8721\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2292 - accuracy: 0.9022 - val_loss: 0.2699 - val_accuracy: 0.8767\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2286 - accuracy: 0.9022 - val_loss: 0.2696 - val_accuracy: 0.8767\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2281 - accuracy: 0.9041 - val_loss: 0.2693 - val_accuracy: 0.8767\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2274 - accuracy: 0.9031 - val_loss: 0.2690 - val_accuracy: 0.8767\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 175us/step - loss: 0.2269 - accuracy: 0.9041 - val_loss: 0.2687 - val_accuracy: 0.8767\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.2263 - accuracy: 0.9051 - val_loss: 0.2684 - val_accuracy: 0.8767\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 180us/step - loss: 0.2258 - accuracy: 0.9051 - val_loss: 0.2681 - val_accuracy: 0.8767\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 187us/step - loss: 0.2252 - accuracy: 0.9051 - val_loss: 0.2679 - val_accuracy: 0.8767\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2248 - accuracy: 0.9070 - val_loss: 0.2676 - val_accuracy: 0.8767\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.2243 - accuracy: 0.9051 - val_loss: 0.2673 - val_accuracy: 0.8767\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2239 - accuracy: 0.9070 - val_loss: 0.2671 - val_accuracy: 0.8767\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 247us/step - loss: 0.2235 - accuracy: 0.9061 - val_loss: 0.2668 - val_accuracy: 0.8767\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 175us/step - loss: 0.2230 - accuracy: 0.9061 - val_loss: 0.2665 - val_accuracy: 0.8767\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.2227 - accuracy: 0.9080 - val_loss: 0.2663 - val_accuracy: 0.8767\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2221 - accuracy: 0.9051 - val_loss: 0.2661 - val_accuracy: 0.8767\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 208us/step - loss: 0.2218 - accuracy: 0.9061 - val_loss: 0.2658 - val_accuracy: 0.8767\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 310us/step - loss: 0.2215 - accuracy: 0.9061 - val_loss: 0.2655 - val_accuracy: 0.8767\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 253us/step - loss: 0.2210 - accuracy: 0.9070 - val_loss: 0.2653 - val_accuracy: 0.8767\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 219us/step - loss: 0.2206 - accuracy: 0.9080 - val_loss: 0.2652 - val_accuracy: 0.8767\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2202 - accuracy: 0.9070 - val_loss: 0.2650 - val_accuracy: 0.8767\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2199 - accuracy: 0.9080 - val_loss: 0.2649 - val_accuracy: 0.8767\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2196 - accuracy: 0.9070 - val_loss: 0.2647 - val_accuracy: 0.8767\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2193 - accuracy: 0.9070 - val_loss: 0.2645 - val_accuracy: 0.8767\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2189 - accuracy: 0.9070 - val_loss: 0.2644 - val_accuracy: 0.8767\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2185 - accuracy: 0.9070 - val_loss: 0.2643 - val_accuracy: 0.8767\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2181 - accuracy: 0.9070 - val_loss: 0.2641 - val_accuracy: 0.8767\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 167us/step - loss: 0.2180 - accuracy: 0.9070 - val_loss: 0.2640 - val_accuracy: 0.8767\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2176 - accuracy: 0.9080 - val_loss: 0.2639 - val_accuracy: 0.8767\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2173 - accuracy: 0.9090 - val_loss: 0.2638 - val_accuracy: 0.8767\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 183us/step - loss: 0.2170 - accuracy: 0.9080 - val_loss: 0.2636 - val_accuracy: 0.8767\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 181us/step - loss: 0.2167 - accuracy: 0.9080 - val_loss: 0.2634 - val_accuracy: 0.8767\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2164 - accuracy: 0.9070 - val_loss: 0.2632 - val_accuracy: 0.8767\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.2160 - accuracy: 0.9080 - val_loss: 0.2630 - val_accuracy: 0.8767\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 97us/step - loss: 0.2156 - accuracy: 0.9080 - val_loss: 0.2628 - val_accuracy: 0.8767\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 240us/step - loss: 0.2153 - accuracy: 0.9080 - val_loss: 0.2626 - val_accuracy: 0.8767\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 99us/step - loss: 0.2151 - accuracy: 0.9080 - val_loss: 0.2623 - val_accuracy: 0.8767\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2147 - accuracy: 0.9080 - val_loss: 0.2621 - val_accuracy: 0.8767\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 100us/step - loss: 0.2144 - accuracy: 0.9080 - val_loss: 0.2619 - val_accuracy: 0.8813\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 101us/step - loss: 0.2141 - accuracy: 0.9119 - val_loss: 0.2617 - val_accuracy: 0.8813\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.2137 - accuracy: 0.9110 - val_loss: 0.2614 - val_accuracy: 0.8813\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2134 - accuracy: 0.9100 - val_loss: 0.2612 - val_accuracy: 0.8813\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2131 - accuracy: 0.9070 - val_loss: 0.2611 - val_accuracy: 0.8813\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.2128 - accuracy: 0.9119 - val_loss: 0.2610 - val_accuracy: 0.8858\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.2125 - accuracy: 0.9129 - val_loss: 0.2608 - val_accuracy: 0.8813\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 185us/step - loss: 0.2122 - accuracy: 0.9129 - val_loss: 0.2607 - val_accuracy: 0.8858\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 262us/step - loss: 0.2118 - accuracy: 0.9100 - val_loss: 0.2606 - val_accuracy: 0.8904\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 247us/step - loss: 0.2116 - accuracy: 0.9110 - val_loss: 0.2605 - val_accuracy: 0.8904\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 257us/step - loss: 0.2113 - accuracy: 0.9100 - val_loss: 0.2603 - val_accuracy: 0.8904\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 288us/step - loss: 0.2110 - accuracy: 0.9129 - val_loss: 0.2601 - val_accuracy: 0.8904\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 214us/step - loss: 0.2109 - accuracy: 0.9129 - val_loss: 0.2600 - val_accuracy: 0.8904\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 172us/step - loss: 0.2106 - accuracy: 0.9129 - val_loss: 0.2599 - val_accuracy: 0.8904\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2102 - accuracy: 0.9119 - val_loss: 0.2598 - val_accuracy: 0.8904\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 185us/step - loss: 0.2100 - accuracy: 0.9119 - val_loss: 0.2596 - val_accuracy: 0.8904\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 236us/step - loss: 0.2098 - accuracy: 0.9110 - val_loss: 0.2595 - val_accuracy: 0.8904\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2094 - accuracy: 0.9149 - val_loss: 0.2594 - val_accuracy: 0.8904\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2091 - accuracy: 0.9139 - val_loss: 0.2593 - val_accuracy: 0.8904\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 169us/step - loss: 0.2089 - accuracy: 0.9129 - val_loss: 0.2592 - val_accuracy: 0.8904\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 796us/step - loss: 0.7572 - accuracy: 0.4824 - val_loss: 0.6783 - val_accuracy: 0.4886\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 327us/step - loss: 0.6555 - accuracy: 0.5558 - val_loss: 0.6186 - val_accuracy: 0.6986\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 224us/step - loss: 0.5922 - accuracy: 0.7515 - val_loss: 0.5763 - val_accuracy: 0.7808\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 219us/step - loss: 0.5437 - accuracy: 0.8131 - val_loss: 0.5417 - val_accuracy: 0.8082\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 225us/step - loss: 0.5025 - accuracy: 0.8346 - val_loss: 0.5116 - val_accuracy: 0.8082\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 277us/step - loss: 0.4667 - accuracy: 0.8493 - val_loss: 0.4855 - val_accuracy: 0.7991\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 259us/step - loss: 0.4358 - accuracy: 0.8581 - val_loss: 0.4626 - val_accuracy: 0.8128\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.4094 - accuracy: 0.8601 - val_loss: 0.4428 - val_accuracy: 0.8082\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.3870 - accuracy: 0.8650 - val_loss: 0.4263 - val_accuracy: 0.8128\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.3678 - accuracy: 0.8679 - val_loss: 0.4126 - val_accuracy: 0.8174\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.3518 - accuracy: 0.8669 - val_loss: 0.4009 - val_accuracy: 0.8128\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.3381 - accuracy: 0.8679 - val_loss: 0.3906 - val_accuracy: 0.8128\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 100us/step - loss: 0.3266 - accuracy: 0.8689 - val_loss: 0.3816 - val_accuracy: 0.8128\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.3166 - accuracy: 0.8699 - val_loss: 0.3736 - val_accuracy: 0.8174\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 101us/step - loss: 0.3081 - accuracy: 0.8738 - val_loss: 0.3666 - val_accuracy: 0.8174\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 100us/step - loss: 0.3007 - accuracy: 0.8757 - val_loss: 0.3605 - val_accuracy: 0.8174\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.2942 - accuracy: 0.8748 - val_loss: 0.3551 - val_accuracy: 0.8219\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2885 - accuracy: 0.8767 - val_loss: 0.3503 - val_accuracy: 0.8265\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2834 - accuracy: 0.8806 - val_loss: 0.3461 - val_accuracy: 0.8265\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.2787 - accuracy: 0.8796 - val_loss: 0.3426 - val_accuracy: 0.8265\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.2748 - accuracy: 0.8816 - val_loss: 0.3394 - val_accuracy: 0.8311\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 100us/step - loss: 0.2712 - accuracy: 0.8836 - val_loss: 0.3365 - val_accuracy: 0.8311\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.2678 - accuracy: 0.8816 - val_loss: 0.3339 - val_accuracy: 0.8311\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 101us/step - loss: 0.2646 - accuracy: 0.8816 - val_loss: 0.3314 - val_accuracy: 0.8311\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2619 - accuracy: 0.8826 - val_loss: 0.3291 - val_accuracy: 0.8356\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 100us/step - loss: 0.2593 - accuracy: 0.8855 - val_loss: 0.3270 - val_accuracy: 0.8356\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2569 - accuracy: 0.8865 - val_loss: 0.3251 - val_accuracy: 0.8356\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.2547 - accuracy: 0.8865 - val_loss: 0.3234 - val_accuracy: 0.8356\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 100us/step - loss: 0.2527 - accuracy: 0.8894 - val_loss: 0.3218 - val_accuracy: 0.8402\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2507 - accuracy: 0.8924 - val_loss: 0.3202 - val_accuracy: 0.8447\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 100us/step - loss: 0.2489 - accuracy: 0.8914 - val_loss: 0.3188 - val_accuracy: 0.8402\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 189us/step - loss: 0.2472 - accuracy: 0.8933 - val_loss: 0.3174 - val_accuracy: 0.8447\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2456 - accuracy: 0.8924 - val_loss: 0.3161 - val_accuracy: 0.8447\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.2441 - accuracy: 0.8904 - val_loss: 0.3148 - val_accuracy: 0.8447\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2426 - accuracy: 0.8904 - val_loss: 0.3135 - val_accuracy: 0.8447\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2413 - accuracy: 0.8924 - val_loss: 0.3124 - val_accuracy: 0.8447\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2399 - accuracy: 0.8933 - val_loss: 0.3114 - val_accuracy: 0.8447\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2388 - accuracy: 0.8943 - val_loss: 0.3104 - val_accuracy: 0.8447\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2375 - accuracy: 0.8953 - val_loss: 0.3094 - val_accuracy: 0.8493\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2364 - accuracy: 0.8953 - val_loss: 0.3085 - val_accuracy: 0.8493\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2353 - accuracy: 0.8953 - val_loss: 0.3076 - val_accuracy: 0.8539\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2342 - accuracy: 0.8963 - val_loss: 0.3066 - val_accuracy: 0.8584\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2331 - accuracy: 0.8973 - val_loss: 0.3056 - val_accuracy: 0.8584\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2322 - accuracy: 0.8973 - val_loss: 0.3047 - val_accuracy: 0.8584\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2313 - accuracy: 0.8982 - val_loss: 0.3038 - val_accuracy: 0.8584\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2303 - accuracy: 0.8992 - val_loss: 0.3029 - val_accuracy: 0.8584\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2294 - accuracy: 0.9012 - val_loss: 0.3022 - val_accuracy: 0.8584\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2286 - accuracy: 0.9012 - val_loss: 0.3014 - val_accuracy: 0.8539\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2278 - accuracy: 0.9002 - val_loss: 0.3006 - val_accuracy: 0.8539\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2269 - accuracy: 0.8992 - val_loss: 0.2999 - val_accuracy: 0.8584\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2261 - accuracy: 0.9002 - val_loss: 0.2991 - val_accuracy: 0.8584\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2254 - accuracy: 0.9002 - val_loss: 0.2984 - val_accuracy: 0.8584\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2247 - accuracy: 0.9002 - val_loss: 0.2978 - val_accuracy: 0.8584\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2239 - accuracy: 0.9002 - val_loss: 0.2972 - val_accuracy: 0.8584\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2233 - accuracy: 0.9002 - val_loss: 0.2967 - val_accuracy: 0.8584\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2225 - accuracy: 0.9002 - val_loss: 0.2961 - val_accuracy: 0.8584\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2218 - accuracy: 0.9012 - val_loss: 0.2955 - val_accuracy: 0.8584\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2212 - accuracy: 0.9022 - val_loss: 0.2951 - val_accuracy: 0.8584\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2206 - accuracy: 0.9012 - val_loss: 0.2947 - val_accuracy: 0.8584\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2199 - accuracy: 0.9022 - val_loss: 0.2944 - val_accuracy: 0.8584\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2194 - accuracy: 0.9012 - val_loss: 0.2939 - val_accuracy: 0.8584\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2189 - accuracy: 0.9022 - val_loss: 0.2935 - val_accuracy: 0.8584\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.2183 - accuracy: 0.9012 - val_loss: 0.2932 - val_accuracy: 0.8584\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2177 - accuracy: 0.9051 - val_loss: 0.2928 - val_accuracy: 0.8584\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2172 - accuracy: 0.9041 - val_loss: 0.2925 - val_accuracy: 0.8584\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2167 - accuracy: 0.9051 - val_loss: 0.2921 - val_accuracy: 0.8584\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2161 - accuracy: 0.9070 - val_loss: 0.2918 - val_accuracy: 0.8584\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.2158 - accuracy: 0.9080 - val_loss: 0.2914 - val_accuracy: 0.8584\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.2153 - accuracy: 0.9041 - val_loss: 0.2910 - val_accuracy: 0.8584\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2149 - accuracy: 0.9070 - val_loss: 0.2906 - val_accuracy: 0.8584\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2143 - accuracy: 0.9070 - val_loss: 0.2904 - val_accuracy: 0.8584\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2139 - accuracy: 0.9070 - val_loss: 0.2899 - val_accuracy: 0.8584\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2134 - accuracy: 0.9080 - val_loss: 0.2896 - val_accuracy: 0.8584\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2130 - accuracy: 0.9070 - val_loss: 0.2892 - val_accuracy: 0.8584\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2126 - accuracy: 0.9070 - val_loss: 0.2888 - val_accuracy: 0.8584\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2120 - accuracy: 0.9090 - val_loss: 0.2885 - val_accuracy: 0.8584\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2116 - accuracy: 0.9080 - val_loss: 0.2880 - val_accuracy: 0.8584\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2112 - accuracy: 0.9070 - val_loss: 0.2876 - val_accuracy: 0.8584\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2109 - accuracy: 0.9080 - val_loss: 0.2873 - val_accuracy: 0.8584\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 193us/step - loss: 0.2104 - accuracy: 0.9090 - val_loss: 0.2870 - val_accuracy: 0.8584\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 100us/step - loss: 0.2100 - accuracy: 0.9100 - val_loss: 0.2867 - val_accuracy: 0.8584\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2096 - accuracy: 0.9090 - val_loss: 0.2864 - val_accuracy: 0.8584\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2093 - accuracy: 0.9100 - val_loss: 0.2860 - val_accuracy: 0.8584\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2089 - accuracy: 0.9100 - val_loss: 0.2857 - val_accuracy: 0.8584\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2085 - accuracy: 0.9100 - val_loss: 0.2852 - val_accuracy: 0.8630\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2081 - accuracy: 0.9100 - val_loss: 0.2849 - val_accuracy: 0.8630\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2078 - accuracy: 0.9090 - val_loss: 0.2847 - val_accuracy: 0.8630\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2074 - accuracy: 0.9100 - val_loss: 0.2843 - val_accuracy: 0.8630\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2069 - accuracy: 0.9100 - val_loss: 0.2840 - val_accuracy: 0.8630\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2067 - accuracy: 0.9100 - val_loss: 0.2838 - val_accuracy: 0.8676\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2063 - accuracy: 0.9100 - val_loss: 0.2836 - val_accuracy: 0.8676\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 100us/step - loss: 0.2060 - accuracy: 0.9100 - val_loss: 0.2833 - val_accuracy: 0.8676\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 95us/step - loss: 0.2058 - accuracy: 0.9100 - val_loss: 0.2830 - val_accuracy: 0.8676\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 96us/step - loss: 0.2053 - accuracy: 0.9110 - val_loss: 0.2827 - val_accuracy: 0.8676\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 97us/step - loss: 0.2050 - accuracy: 0.9090 - val_loss: 0.2824 - val_accuracy: 0.8676\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 99us/step - loss: 0.2048 - accuracy: 0.9110 - val_loss: 0.2822 - val_accuracy: 0.8676\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 99us/step - loss: 0.2043 - accuracy: 0.9110 - val_loss: 0.2820 - val_accuracy: 0.8676\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 100us/step - loss: 0.2040 - accuracy: 0.9110 - val_loss: 0.2818 - val_accuracy: 0.8676\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.2038 - accuracy: 0.9110 - val_loss: 0.2815 - val_accuracy: 0.8676\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 96us/step - loss: 0.2035 - accuracy: 0.9119 - val_loss: 0.2813 - val_accuracy: 0.8676\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 979us/step - loss: 0.6693 - accuracy: 0.6311 - val_loss: 0.6250 - val_accuracy: 0.7306\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.5448 - accuracy: 0.8063 - val_loss: 0.5366 - val_accuracy: 0.8174\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.4692 - accuracy: 0.8366 - val_loss: 0.4776 - val_accuracy: 0.8311\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 191us/step - loss: 0.4171 - accuracy: 0.8611 - val_loss: 0.4362 - val_accuracy: 0.8447\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 186us/step - loss: 0.3795 - accuracy: 0.8728 - val_loss: 0.4061 - val_accuracy: 0.8447\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 197us/step - loss: 0.3513 - accuracy: 0.8767 - val_loss: 0.3831 - val_accuracy: 0.8402\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 225us/step - loss: 0.3298 - accuracy: 0.8806 - val_loss: 0.3657 - val_accuracy: 0.8447\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.3133 - accuracy: 0.8826 - val_loss: 0.3521 - val_accuracy: 0.8493\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 240us/step - loss: 0.3002 - accuracy: 0.8826 - val_loss: 0.3426 - val_accuracy: 0.8493\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 193us/step - loss: 0.2899 - accuracy: 0.8836 - val_loss: 0.3353 - val_accuracy: 0.8539\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 258us/step - loss: 0.2814 - accuracy: 0.8865 - val_loss: 0.3295 - val_accuracy: 0.8539\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 331us/step - loss: 0.2746 - accuracy: 0.8904 - val_loss: 0.3252 - val_accuracy: 0.8539\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2690 - accuracy: 0.8914 - val_loss: 0.3218 - val_accuracy: 0.8584\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2643 - accuracy: 0.8924 - val_loss: 0.3193 - val_accuracy: 0.8584\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 169us/step - loss: 0.2603 - accuracy: 0.8933 - val_loss: 0.3169 - val_accuracy: 0.8584\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2568 - accuracy: 0.8973 - val_loss: 0.3152 - val_accuracy: 0.8584\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2538 - accuracy: 0.8933 - val_loss: 0.3135 - val_accuracy: 0.8584\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2511 - accuracy: 0.8953 - val_loss: 0.3121 - val_accuracy: 0.8584\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2489 - accuracy: 0.8963 - val_loss: 0.3108 - val_accuracy: 0.8584\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2467 - accuracy: 0.8963 - val_loss: 0.3098 - val_accuracy: 0.8584\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2447 - accuracy: 0.8963 - val_loss: 0.3087 - val_accuracy: 0.8584\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 261us/step - loss: 0.2430 - accuracy: 0.8963 - val_loss: 0.3077 - val_accuracy: 0.8630\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 185us/step - loss: 0.2413 - accuracy: 0.8982 - val_loss: 0.3067 - val_accuracy: 0.8630\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 189us/step - loss: 0.2399 - accuracy: 0.8973 - val_loss: 0.3058 - val_accuracy: 0.8630\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 207us/step - loss: 0.2384 - accuracy: 0.8973 - val_loss: 0.3050 - val_accuracy: 0.8630\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - ETA: 0s - loss: 0.2486 - accuracy: 0.89 - 0s 109us/step - loss: 0.2370 - accuracy: 0.8992 - val_loss: 0.3041 - val_accuracy: 0.8630\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2357 - accuracy: 0.9002 - val_loss: 0.3032 - val_accuracy: 0.8630\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2345 - accuracy: 0.8992 - val_loss: 0.3024 - val_accuracy: 0.8630\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2333 - accuracy: 0.9012 - val_loss: 0.3017 - val_accuracy: 0.8676\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2322 - accuracy: 0.9012 - val_loss: 0.3009 - val_accuracy: 0.8676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2311 - accuracy: 0.9012 - val_loss: 0.3002 - val_accuracy: 0.8676\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2300 - accuracy: 0.9031 - val_loss: 0.2993 - val_accuracy: 0.8721\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2291 - accuracy: 0.9051 - val_loss: 0.2986 - val_accuracy: 0.8721\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2282 - accuracy: 0.9061 - val_loss: 0.2979 - val_accuracy: 0.8721\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2272 - accuracy: 0.9022 - val_loss: 0.2971 - val_accuracy: 0.8721\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2264 - accuracy: 0.9031 - val_loss: 0.2964 - val_accuracy: 0.8721\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2255 - accuracy: 0.9061 - val_loss: 0.2956 - val_accuracy: 0.8721\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2247 - accuracy: 0.9061 - val_loss: 0.2948 - val_accuracy: 0.8721\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2239 - accuracy: 0.9061 - val_loss: 0.2941 - val_accuracy: 0.8721\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2230 - accuracy: 0.9061 - val_loss: 0.2933 - val_accuracy: 0.8721\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2223 - accuracy: 0.9070 - val_loss: 0.2925 - val_accuracy: 0.8721\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2215 - accuracy: 0.9070 - val_loss: 0.2919 - val_accuracy: 0.8721\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2206 - accuracy: 0.9080 - val_loss: 0.2912 - val_accuracy: 0.8721\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2200 - accuracy: 0.9090 - val_loss: 0.2905 - val_accuracy: 0.8721\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2194 - accuracy: 0.9090 - val_loss: 0.2899 - val_accuracy: 0.8721\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2186 - accuracy: 0.9090 - val_loss: 0.2893 - val_accuracy: 0.8721\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2180 - accuracy: 0.9090 - val_loss: 0.2887 - val_accuracy: 0.8721\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2173 - accuracy: 0.9080 - val_loss: 0.2882 - val_accuracy: 0.8721\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2166 - accuracy: 0.9110 - val_loss: 0.2875 - val_accuracy: 0.8721\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2160 - accuracy: 0.9110 - val_loss: 0.2869 - val_accuracy: 0.8721\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2153 - accuracy: 0.9100 - val_loss: 0.2865 - val_accuracy: 0.8721\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2148 - accuracy: 0.9110 - val_loss: 0.2860 - val_accuracy: 0.8721\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.2142 - accuracy: 0.9110 - val_loss: 0.2854 - val_accuracy: 0.8721\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 296us/step - loss: 0.2135 - accuracy: 0.9110 - val_loss: 0.2848 - val_accuracy: 0.8721\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.2130 - accuracy: 0.9100 - val_loss: 0.2842 - val_accuracy: 0.8721\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2124 - accuracy: 0.9110 - val_loss: 0.2836 - val_accuracy: 0.8721\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2119 - accuracy: 0.9100 - val_loss: 0.2829 - val_accuracy: 0.8721\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2113 - accuracy: 0.9110 - val_loss: 0.2823 - val_accuracy: 0.8721\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2108 - accuracy: 0.9119 - val_loss: 0.2817 - val_accuracy: 0.8721\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 299us/step - loss: 0.2103 - accuracy: 0.9110 - val_loss: 0.2812 - val_accuracy: 0.8721\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 188us/step - loss: 0.2097 - accuracy: 0.9119 - val_loss: 0.2807 - val_accuracy: 0.8721\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 184us/step - loss: 0.2092 - accuracy: 0.9119 - val_loss: 0.2802 - val_accuracy: 0.8721\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2087 - accuracy: 0.9119 - val_loss: 0.2797 - val_accuracy: 0.8721\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2082 - accuracy: 0.9119 - val_loss: 0.2792 - val_accuracy: 0.8721\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 186us/step - loss: 0.2077 - accuracy: 0.9119 - val_loss: 0.2787 - val_accuracy: 0.8721\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.2073 - accuracy: 0.9119 - val_loss: 0.2782 - val_accuracy: 0.8721\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2068 - accuracy: 0.9119 - val_loss: 0.2778 - val_accuracy: 0.8721\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2064 - accuracy: 0.9119 - val_loss: 0.2773 - val_accuracy: 0.8721\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 220us/step - loss: 0.2059 - accuracy: 0.9139 - val_loss: 0.2770 - val_accuracy: 0.8721\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 262us/step - loss: 0.2054 - accuracy: 0.9129 - val_loss: 0.2766 - val_accuracy: 0.8721\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2050 - accuracy: 0.9139 - val_loss: 0.2761 - val_accuracy: 0.8721\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.2047 - accuracy: 0.9119 - val_loss: 0.2758 - val_accuracy: 0.8721\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2042 - accuracy: 0.9129 - val_loss: 0.2753 - val_accuracy: 0.8721\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2038 - accuracy: 0.9139 - val_loss: 0.2749 - val_accuracy: 0.8721\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 236us/step - loss: 0.2034 - accuracy: 0.9129 - val_loss: 0.2745 - val_accuracy: 0.8721\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 360us/step - loss: 0.2029 - accuracy: 0.9119 - val_loss: 0.2741 - val_accuracy: 0.8721\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 236us/step - loss: 0.2026 - accuracy: 0.9119 - val_loss: 0.2737 - val_accuracy: 0.8721\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 204us/step - loss: 0.2022 - accuracy: 0.9129 - val_loss: 0.2731 - val_accuracy: 0.8721\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 1s 514us/step - loss: 0.2018 - accuracy: 0.9129 - val_loss: 0.2727 - val_accuracy: 0.8721\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 422us/step - loss: 0.2014 - accuracy: 0.9129 - val_loss: 0.2724 - val_accuracy: 0.8721\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 254us/step - loss: 0.2009 - accuracy: 0.9159 - val_loss: 0.2721 - val_accuracy: 0.8721\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 298us/step - loss: 0.2006 - accuracy: 0.9159 - val_loss: 0.2718 - val_accuracy: 0.8721\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.2003 - accuracy: 0.9149 - val_loss: 0.2713 - val_accuracy: 0.8721\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 205us/step - loss: 0.1999 - accuracy: 0.9149 - val_loss: 0.2709 - val_accuracy: 0.8721\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 286us/step - loss: 0.1994 - accuracy: 0.9149 - val_loss: 0.2705 - val_accuracy: 0.8721\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 455us/step - loss: 0.1990 - accuracy: 0.9149 - val_loss: 0.2702 - val_accuracy: 0.8721\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 239us/step - loss: 0.1987 - accuracy: 0.9149 - val_loss: 0.2699 - val_accuracy: 0.8721\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 248us/step - loss: 0.1983 - accuracy: 0.9159 - val_loss: 0.2695 - val_accuracy: 0.8721\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 196us/step - loss: 0.1979 - accuracy: 0.9178 - val_loss: 0.2692 - val_accuracy: 0.8721\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.1975 - accuracy: 0.9139 - val_loss: 0.2689 - val_accuracy: 0.8813\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 169us/step - loss: 0.1971 - accuracy: 0.9149 - val_loss: 0.2685 - val_accuracy: 0.8813\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.1968 - accuracy: 0.9149 - val_loss: 0.2682 - val_accuracy: 0.8813\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 254us/step - loss: 0.1965 - accuracy: 0.9178 - val_loss: 0.2679 - val_accuracy: 0.8813\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 211us/step - loss: 0.1961 - accuracy: 0.9168 - val_loss: 0.2676 - val_accuracy: 0.8813\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 217us/step - loss: 0.1956 - accuracy: 0.9178 - val_loss: 0.2672 - val_accuracy: 0.8813\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 353us/step - loss: 0.1952 - accuracy: 0.9178 - val_loss: 0.2670 - val_accuracy: 0.8813\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 453us/step - loss: 0.1949 - accuracy: 0.9188 - val_loss: 0.2668 - val_accuracy: 0.8813\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 169us/step - loss: 0.1945 - accuracy: 0.9178 - val_loss: 0.2665 - val_accuracy: 0.8813\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 209us/step - loss: 0.1941 - accuracy: 0.9178 - val_loss: 0.2662 - val_accuracy: 0.8813\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.1938 - accuracy: 0.9178 - val_loss: 0.2660 - val_accuracy: 0.8813\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 940us/step - loss: 0.7922 - accuracy: 0.4902 - val_loss: 0.7122 - val_accuracy: 0.4977\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 207us/step - loss: 0.6548 - accuracy: 0.5920 - val_loss: 0.6228 - val_accuracy: 0.6712\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 164us/step - loss: 0.5722 - accuracy: 0.7701 - val_loss: 0.5598 - val_accuracy: 0.8037\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 188us/step - loss: 0.5115 - accuracy: 0.8591 - val_loss: 0.5092 - val_accuracy: 0.8493\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 169us/step - loss: 0.4622 - accuracy: 0.8757 - val_loss: 0.4666 - val_accuracy: 0.8584\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 174us/step - loss: 0.4213 - accuracy: 0.8777 - val_loss: 0.4313 - val_accuracy: 0.8721\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.3873 - accuracy: 0.8777 - val_loss: 0.4024 - val_accuracy: 0.8721\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.3595 - accuracy: 0.8836 - val_loss: 0.3791 - val_accuracy: 0.8721\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.3370 - accuracy: 0.8806 - val_loss: 0.3603 - val_accuracy: 0.8676\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 187us/step - loss: 0.3185 - accuracy: 0.8816 - val_loss: 0.3456 - val_accuracy: 0.8630\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.3036 - accuracy: 0.8845 - val_loss: 0.3339 - val_accuracy: 0.8630\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 190us/step - loss: 0.2913 - accuracy: 0.8845 - val_loss: 0.3249 - val_accuracy: 0.8630\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2812 - accuracy: 0.8894 - val_loss: 0.3181 - val_accuracy: 0.8630\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2729 - accuracy: 0.8904 - val_loss: 0.3129 - val_accuracy: 0.8630\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.2661 - accuracy: 0.8924 - val_loss: 0.3088 - val_accuracy: 0.8676\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 175us/step - loss: 0.2603 - accuracy: 0.8933 - val_loss: 0.3056 - val_accuracy: 0.8676\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 194us/step - loss: 0.2555 - accuracy: 0.8924 - val_loss: 0.3031 - val_accuracy: 0.8676\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 233us/step - loss: 0.2513 - accuracy: 0.8943 - val_loss: 0.3014 - val_accuracy: 0.8676\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 209us/step - loss: 0.2477 - accuracy: 0.8953 - val_loss: 0.2999 - val_accuracy: 0.8676\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 213us/step - loss: 0.2447 - accuracy: 0.8982 - val_loss: 0.2987 - val_accuracy: 0.8676\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 217us/step - loss: 0.2418 - accuracy: 0.8973 - val_loss: 0.2979 - val_accuracy: 0.8676\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 200us/step - loss: 0.2394 - accuracy: 0.8992 - val_loss: 0.2971 - val_accuracy: 0.8584\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 203us/step - loss: 0.2374 - accuracy: 0.9012 - val_loss: 0.2965 - val_accuracy: 0.8584\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - ETA: 0s - loss: 0.2295 - accuracy: 0.90 - 0s 169us/step - loss: 0.2356 - accuracy: 0.9012 - val_loss: 0.2959 - val_accuracy: 0.8584\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 191us/step - loss: 0.2339 - accuracy: 0.9031 - val_loss: 0.2954 - val_accuracy: 0.8584\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 232us/step - loss: 0.2324 - accuracy: 0.9022 - val_loss: 0.2951 - val_accuracy: 0.8584\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - ETA: 0s - loss: 0.2374 - accuracy: 0.89 - 0s 195us/step - loss: 0.2310 - accuracy: 0.9041 - val_loss: 0.2949 - val_accuracy: 0.8584\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 206us/step - loss: 0.2298 - accuracy: 0.9051 - val_loss: 0.2946 - val_accuracy: 0.8584\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 290us/step - loss: 0.2287 - accuracy: 0.9031 - val_loss: 0.2944 - val_accuracy: 0.8584\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 230us/step - loss: 0.2276 - accuracy: 0.9070 - val_loss: 0.2942 - val_accuracy: 0.8584\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 185us/step - loss: 0.2266 - accuracy: 0.9041 - val_loss: 0.2939 - val_accuracy: 0.8584\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 175us/step - loss: 0.2257 - accuracy: 0.9061 - val_loss: 0.2937 - val_accuracy: 0.8630\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 224us/step - loss: 0.2249 - accuracy: 0.9051 - val_loss: 0.2934 - val_accuracy: 0.8630\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 196us/step - loss: 0.2240 - accuracy: 0.9080 - val_loss: 0.2932 - val_accuracy: 0.8630\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 240us/step - loss: 0.2233 - accuracy: 0.9051 - val_loss: 0.2931 - val_accuracy: 0.8630\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 229us/step - loss: 0.2226 - accuracy: 0.9070 - val_loss: 0.2928 - val_accuracy: 0.8630\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 237us/step - loss: 0.2219 - accuracy: 0.9080 - val_loss: 0.2926 - val_accuracy: 0.8630\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 199us/step - loss: 0.2213 - accuracy: 0.9090 - val_loss: 0.2923 - val_accuracy: 0.8630\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 222us/step - loss: 0.2205 - accuracy: 0.9061 - val_loss: 0.2921 - val_accuracy: 0.8630\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 167us/step - loss: 0.2200 - accuracy: 0.9090 - val_loss: 0.2919 - val_accuracy: 0.8630\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2193 - accuracy: 0.9080 - val_loss: 0.2916 - val_accuracy: 0.8630\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2188 - accuracy: 0.9070 - val_loss: 0.2914 - val_accuracy: 0.8676\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2182 - accuracy: 0.9090 - val_loss: 0.2911 - val_accuracy: 0.8676\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2176 - accuracy: 0.9080 - val_loss: 0.2908 - val_accuracy: 0.8676\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2171 - accuracy: 0.9090 - val_loss: 0.2905 - val_accuracy: 0.8721\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2166 - accuracy: 0.9090 - val_loss: 0.2901 - val_accuracy: 0.8721\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2161 - accuracy: 0.9070 - val_loss: 0.2898 - val_accuracy: 0.8721\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2157 - accuracy: 0.9090 - val_loss: 0.2895 - val_accuracy: 0.8721\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2153 - accuracy: 0.9119 - val_loss: 0.2891 - val_accuracy: 0.8721\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2148 - accuracy: 0.9100 - val_loss: 0.2887 - val_accuracy: 0.8721\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.2144 - accuracy: 0.9110 - val_loss: 0.2883 - val_accuracy: 0.8767\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.2138 - accuracy: 0.9100 - val_loss: 0.2879 - val_accuracy: 0.8767\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2135 - accuracy: 0.9100 - val_loss: 0.2876 - val_accuracy: 0.8767\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.2130 - accuracy: 0.9110 - val_loss: 0.2871 - val_accuracy: 0.8767\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2126 - accuracy: 0.9110 - val_loss: 0.2868 - val_accuracy: 0.8767\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.2122 - accuracy: 0.9119 - val_loss: 0.2865 - val_accuracy: 0.8767\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.2118 - accuracy: 0.9119 - val_loss: 0.2861 - val_accuracy: 0.8767\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 168us/step - loss: 0.2112 - accuracy: 0.9119 - val_loss: 0.2857 - val_accuracy: 0.8767\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 183us/step - loss: 0.2109 - accuracy: 0.9110 - val_loss: 0.2853 - val_accuracy: 0.8767\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2105 - accuracy: 0.9139 - val_loss: 0.2850 - val_accuracy: 0.8767\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2102 - accuracy: 0.9139 - val_loss: 0.2847 - val_accuracy: 0.8767\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2098 - accuracy: 0.9149 - val_loss: 0.2844 - val_accuracy: 0.8767\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2094 - accuracy: 0.9139 - val_loss: 0.2840 - val_accuracy: 0.8767\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2090 - accuracy: 0.9129 - val_loss: 0.2837 - val_accuracy: 0.8767\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 188us/step - loss: 0.2086 - accuracy: 0.9149 - val_loss: 0.2834 - val_accuracy: 0.8767\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2083 - accuracy: 0.9119 - val_loss: 0.2831 - val_accuracy: 0.8767\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2080 - accuracy: 0.9149 - val_loss: 0.2828 - val_accuracy: 0.8767\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 186us/step - loss: 0.2074 - accuracy: 0.9139 - val_loss: 0.2824 - val_accuracy: 0.8767\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2072 - accuracy: 0.9110 - val_loss: 0.2822 - val_accuracy: 0.8813\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.2068 - accuracy: 0.9139 - val_loss: 0.2820 - val_accuracy: 0.8813\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 182us/step - loss: 0.2065 - accuracy: 0.9129 - val_loss: 0.2817 - val_accuracy: 0.8813\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2061 - accuracy: 0.9119 - val_loss: 0.2814 - val_accuracy: 0.8813\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2059 - accuracy: 0.9110 - val_loss: 0.2812 - val_accuracy: 0.8813\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2055 - accuracy: 0.9139 - val_loss: 0.2808 - val_accuracy: 0.8813\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2052 - accuracy: 0.9100 - val_loss: 0.2806 - val_accuracy: 0.8813\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2048 - accuracy: 0.9139 - val_loss: 0.2803 - val_accuracy: 0.8813\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2045 - accuracy: 0.9129 - val_loss: 0.2800 - val_accuracy: 0.8813\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2044 - accuracy: 0.9139 - val_loss: 0.2797 - val_accuracy: 0.8813\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2040 - accuracy: 0.9129 - val_loss: 0.2795 - val_accuracy: 0.8813\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2037 - accuracy: 0.9110 - val_loss: 0.2793 - val_accuracy: 0.8813\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2034 - accuracy: 0.9139 - val_loss: 0.2791 - val_accuracy: 0.8813\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2033 - accuracy: 0.9119 - val_loss: 0.2788 - val_accuracy: 0.8813\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2029 - accuracy: 0.9129 - val_loss: 0.2786 - val_accuracy: 0.8813\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2026 - accuracy: 0.9110 - val_loss: 0.2785 - val_accuracy: 0.8813\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2023 - accuracy: 0.9129 - val_loss: 0.2783 - val_accuracy: 0.8813\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2021 - accuracy: 0.9139 - val_loss: 0.2779 - val_accuracy: 0.8813\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2018 - accuracy: 0.9119 - val_loss: 0.2777 - val_accuracy: 0.8767\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2016 - accuracy: 0.9139 - val_loss: 0.2774 - val_accuracy: 0.8767\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2012 - accuracy: 0.9119 - val_loss: 0.2772 - val_accuracy: 0.8767\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2010 - accuracy: 0.9119 - val_loss: 0.2770 - val_accuracy: 0.8767\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2007 - accuracy: 0.9139 - val_loss: 0.2768 - val_accuracy: 0.8813\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2006 - accuracy: 0.9159 - val_loss: 0.2767 - val_accuracy: 0.8813\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2003 - accuracy: 0.9159 - val_loss: 0.2765 - val_accuracy: 0.8813\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2001 - accuracy: 0.9110 - val_loss: 0.2762 - val_accuracy: 0.8813\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 214us/step - loss: 0.1998 - accuracy: 0.9149 - val_loss: 0.2761 - val_accuracy: 0.8813\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 168us/step - loss: 0.1995 - accuracy: 0.9149 - val_loss: 0.2758 - val_accuracy: 0.8813\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.1994 - accuracy: 0.9119 - val_loss: 0.2756 - val_accuracy: 0.8813\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.1991 - accuracy: 0.9139 - val_loss: 0.2755 - val_accuracy: 0.8813\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.1988 - accuracy: 0.9129 - val_loss: 0.2754 - val_accuracy: 0.8813\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.1987 - accuracy: 0.9149 - val_loss: 0.2752 - val_accuracy: 0.8813\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 896us/step - loss: 0.7439 - accuracy: 0.4110 - val_loss: 0.6745 - val_accuracy: 0.5662\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 193us/step - loss: 0.6375 - accuracy: 0.6732 - val_loss: 0.5967 - val_accuracy: 0.7489\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.5646 - accuracy: 0.8190 - val_loss: 0.5404 - val_accuracy: 0.8265\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.5094 - accuracy: 0.8523 - val_loss: 0.4972 - val_accuracy: 0.8447\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.4659 - accuracy: 0.8650 - val_loss: 0.4633 - val_accuracy: 0.8402\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.4312 - accuracy: 0.8728 - val_loss: 0.4365 - val_accuracy: 0.8447\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 174us/step - loss: 0.4029 - accuracy: 0.8777 - val_loss: 0.4152 - val_accuracy: 0.8402\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.3798 - accuracy: 0.8826 - val_loss: 0.3983 - val_accuracy: 0.8447\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 181us/step - loss: 0.3608 - accuracy: 0.8875 - val_loss: 0.3848 - val_accuracy: 0.8493\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 178us/step - loss: 0.3449 - accuracy: 0.8865 - val_loss: 0.3740 - val_accuracy: 0.8493\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.3318 - accuracy: 0.8904 - val_loss: 0.3653 - val_accuracy: 0.8539\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.3207 - accuracy: 0.8904 - val_loss: 0.3580 - val_accuracy: 0.8539\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 170us/step - loss: 0.3114 - accuracy: 0.8933 - val_loss: 0.3521 - val_accuracy: 0.8493\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.3035 - accuracy: 0.8953 - val_loss: 0.3470 - val_accuracy: 0.8493\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2965 - accuracy: 0.8982 - val_loss: 0.3426 - val_accuracy: 0.8493\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2903 - accuracy: 0.8982 - val_loss: 0.3387 - val_accuracy: 0.8493\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2850 - accuracy: 0.8982 - val_loss: 0.3353 - val_accuracy: 0.8493\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2803 - accuracy: 0.8992 - val_loss: 0.3322 - val_accuracy: 0.8539\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.2760 - accuracy: 0.8992 - val_loss: 0.3294 - val_accuracy: 0.8539\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.2723 - accuracy: 0.9012 - val_loss: 0.3268 - val_accuracy: 0.8539\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2689 - accuracy: 0.9012 - val_loss: 0.3245 - val_accuracy: 0.8493\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2658 - accuracy: 0.9012 - val_loss: 0.3222 - val_accuracy: 0.8493\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2630 - accuracy: 0.9002 - val_loss: 0.3200 - val_accuracy: 0.8493\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2603 - accuracy: 0.9002 - val_loss: 0.3180 - val_accuracy: 0.8493\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2579 - accuracy: 0.9012 - val_loss: 0.3162 - val_accuracy: 0.8493\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 174us/step - loss: 0.2556 - accuracy: 0.9022 - val_loss: 0.3144 - val_accuracy: 0.8539\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2537 - accuracy: 0.9031 - val_loss: 0.3127 - val_accuracy: 0.8539\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 190us/step - loss: 0.2516 - accuracy: 0.9031 - val_loss: 0.3110 - val_accuracy: 0.8493\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 224us/step - loss: 0.2499 - accuracy: 0.9022 - val_loss: 0.3095 - val_accuracy: 0.8493\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 177us/step - loss: 0.2482 - accuracy: 0.9022 - val_loss: 0.3080 - val_accuracy: 0.8493\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 186us/step - loss: 0.2466 - accuracy: 0.9031 - val_loss: 0.3066 - val_accuracy: 0.8493\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2451 - accuracy: 0.9031 - val_loss: 0.3052 - val_accuracy: 0.8493\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2437 - accuracy: 0.9012 - val_loss: 0.3038 - val_accuracy: 0.8493\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 185us/step - loss: 0.2423 - accuracy: 0.9022 - val_loss: 0.3023 - val_accuracy: 0.8539\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2411 - accuracy: 0.9012 - val_loss: 0.3011 - val_accuracy: 0.8539\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2397 - accuracy: 0.9022 - val_loss: 0.2998 - val_accuracy: 0.8539\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.2387 - accuracy: 0.9031 - val_loss: 0.2986 - val_accuracy: 0.8539\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.2375 - accuracy: 0.9031 - val_loss: 0.2975 - val_accuracy: 0.8539\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - ETA: 0s - loss: 0.2297 - accuracy: 0.90 - 0s 193us/step - loss: 0.2365 - accuracy: 0.9041 - val_loss: 0.2963 - val_accuracy: 0.8539\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2355 - accuracy: 0.9031 - val_loss: 0.2953 - val_accuracy: 0.8539\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2345 - accuracy: 0.9031 - val_loss: 0.2942 - val_accuracy: 0.8539\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2337 - accuracy: 0.9061 - val_loss: 0.2932 - val_accuracy: 0.8584\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.2329 - accuracy: 0.9051 - val_loss: 0.2922 - val_accuracy: 0.8584\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 177us/step - loss: 0.2319 - accuracy: 0.9041 - val_loss: 0.2913 - val_accuracy: 0.8630\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2309 - accuracy: 0.9041 - val_loss: 0.2903 - val_accuracy: 0.8630\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 174us/step - loss: 0.2302 - accuracy: 0.9051 - val_loss: 0.2894 - val_accuracy: 0.8676\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2293 - accuracy: 0.9051 - val_loss: 0.2885 - val_accuracy: 0.8721\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2286 - accuracy: 0.9051 - val_loss: 0.2876 - val_accuracy: 0.8721\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2279 - accuracy: 0.9061 - val_loss: 0.2868 - val_accuracy: 0.8721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2272 - accuracy: 0.9061 - val_loss: 0.2861 - val_accuracy: 0.8721\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2264 - accuracy: 0.9070 - val_loss: 0.2852 - val_accuracy: 0.8721\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2259 - accuracy: 0.9070 - val_loss: 0.2844 - val_accuracy: 0.8721\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.2251 - accuracy: 0.9070 - val_loss: 0.2836 - val_accuracy: 0.8676\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2244 - accuracy: 0.9090 - val_loss: 0.2830 - val_accuracy: 0.8676\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2238 - accuracy: 0.9090 - val_loss: 0.2822 - val_accuracy: 0.8676\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2232 - accuracy: 0.9080 - val_loss: 0.2815 - val_accuracy: 0.8676\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.2225 - accuracy: 0.9090 - val_loss: 0.2809 - val_accuracy: 0.8676\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.2219 - accuracy: 0.9100 - val_loss: 0.2802 - val_accuracy: 0.8676\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.2213 - accuracy: 0.9119 - val_loss: 0.2797 - val_accuracy: 0.8676\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2208 - accuracy: 0.9110 - val_loss: 0.2791 - val_accuracy: 0.8676\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2202 - accuracy: 0.9119 - val_loss: 0.2786 - val_accuracy: 0.8676\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 199us/step - loss: 0.2196 - accuracy: 0.9110 - val_loss: 0.2781 - val_accuracy: 0.8676\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2190 - accuracy: 0.9119 - val_loss: 0.2776 - val_accuracy: 0.8676\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.2184 - accuracy: 0.9119 - val_loss: 0.2771 - val_accuracy: 0.8676\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2180 - accuracy: 0.9119 - val_loss: 0.2767 - val_accuracy: 0.8676\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2175 - accuracy: 0.9119 - val_loss: 0.2762 - val_accuracy: 0.8676\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2170 - accuracy: 0.9129 - val_loss: 0.2758 - val_accuracy: 0.8676\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2165 - accuracy: 0.9129 - val_loss: 0.2754 - val_accuracy: 0.8676\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2160 - accuracy: 0.9139 - val_loss: 0.2749 - val_accuracy: 0.8676\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2154 - accuracy: 0.9129 - val_loss: 0.2745 - val_accuracy: 0.8676\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2150 - accuracy: 0.9139 - val_loss: 0.2741 - val_accuracy: 0.8676\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2145 - accuracy: 0.9139 - val_loss: 0.2738 - val_accuracy: 0.8676\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2141 - accuracy: 0.9139 - val_loss: 0.2734 - val_accuracy: 0.8676\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2136 - accuracy: 0.9129 - val_loss: 0.2731 - val_accuracy: 0.8676\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2132 - accuracy: 0.9139 - val_loss: 0.2727 - val_accuracy: 0.8676\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2128 - accuracy: 0.9139 - val_loss: 0.2724 - val_accuracy: 0.8676\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2123 - accuracy: 0.9149 - val_loss: 0.2721 - val_accuracy: 0.8721\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2121 - accuracy: 0.9129 - val_loss: 0.2718 - val_accuracy: 0.8721\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2116 - accuracy: 0.9139 - val_loss: 0.2716 - val_accuracy: 0.8721\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2110 - accuracy: 0.9129 - val_loss: 0.2714 - val_accuracy: 0.8721\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 172us/step - loss: 0.2109 - accuracy: 0.9129 - val_loss: 0.2711 - val_accuracy: 0.8721\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 174us/step - loss: 0.2103 - accuracy: 0.9139 - val_loss: 0.2708 - val_accuracy: 0.8767\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2100 - accuracy: 0.9129 - val_loss: 0.2705 - val_accuracy: 0.8767\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2098 - accuracy: 0.9139 - val_loss: 0.2702 - val_accuracy: 0.8767\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2093 - accuracy: 0.9129 - val_loss: 0.2700 - val_accuracy: 0.8767\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2091 - accuracy: 0.9129 - val_loss: 0.2696 - val_accuracy: 0.8721\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.2087 - accuracy: 0.9129 - val_loss: 0.2695 - val_accuracy: 0.8721\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2083 - accuracy: 0.9129 - val_loss: 0.2692 - val_accuracy: 0.8767\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2081 - accuracy: 0.9139 - val_loss: 0.2690 - val_accuracy: 0.8767\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2076 - accuracy: 0.9129 - val_loss: 0.2689 - val_accuracy: 0.8767\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.2074 - accuracy: 0.9149 - val_loss: 0.2687 - val_accuracy: 0.8767\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.2072 - accuracy: 0.9139 - val_loss: 0.2684 - val_accuracy: 0.8767\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2067 - accuracy: 0.9139 - val_loss: 0.2681 - val_accuracy: 0.8813\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2065 - accuracy: 0.9149 - val_loss: 0.2679 - val_accuracy: 0.8767\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2062 - accuracy: 0.9129 - val_loss: 0.2677 - val_accuracy: 0.8813\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2059 - accuracy: 0.9149 - val_loss: 0.2674 - val_accuracy: 0.8813\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2055 - accuracy: 0.9139 - val_loss: 0.2671 - val_accuracy: 0.8813\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2053 - accuracy: 0.9149 - val_loss: 0.2670 - val_accuracy: 0.8813\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2050 - accuracy: 0.9139 - val_loss: 0.2666 - val_accuracy: 0.8813\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2047 - accuracy: 0.9149 - val_loss: 0.2664 - val_accuracy: 0.8858\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 938us/step - loss: 0.6548 - accuracy: 0.6644 - val_loss: 0.6106 - val_accuracy: 0.7169\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 200us/step - loss: 0.5946 - accuracy: 0.7358 - val_loss: 0.5633 - val_accuracy: 0.7808\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.5444 - accuracy: 0.7916 - val_loss: 0.5230 - val_accuracy: 0.8128\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.5015 - accuracy: 0.8200 - val_loss: 0.4877 - val_accuracy: 0.8219\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 166us/step - loss: 0.4636 - accuracy: 0.8503 - val_loss: 0.4569 - val_accuracy: 0.8219\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 168us/step - loss: 0.4304 - accuracy: 0.8659 - val_loss: 0.4304 - val_accuracy: 0.8311\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.4018 - accuracy: 0.8757 - val_loss: 0.4079 - val_accuracy: 0.8539\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.3773 - accuracy: 0.8767 - val_loss: 0.3891 - val_accuracy: 0.8493\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.3566 - accuracy: 0.8816 - val_loss: 0.3737 - val_accuracy: 0.8493\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.3392 - accuracy: 0.8806 - val_loss: 0.3612 - val_accuracy: 0.8493\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.3247 - accuracy: 0.8855 - val_loss: 0.3512 - val_accuracy: 0.8539\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 435us/step - loss: 0.3125 - accuracy: 0.8894 - val_loss: 0.3430 - val_accuracy: 0.8539\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.3023 - accuracy: 0.8904 - val_loss: 0.3365 - val_accuracy: 0.8493\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2937 - accuracy: 0.8914 - val_loss: 0.3313 - val_accuracy: 0.8630\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2866 - accuracy: 0.8933 - val_loss: 0.3271 - val_accuracy: 0.8630\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 399us/step - loss: 0.2803 - accuracy: 0.8953 - val_loss: 0.3237 - val_accuracy: 0.8630\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 257us/step - loss: 0.2749 - accuracy: 0.8963 - val_loss: 0.3208 - val_accuracy: 0.8584\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 432us/step - loss: 0.2703 - accuracy: 0.8992 - val_loss: 0.3184 - val_accuracy: 0.8493\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 370us/step - loss: 0.2663 - accuracy: 0.8982 - val_loss: 0.3162 - val_accuracy: 0.8493\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 271us/step - loss: 0.2628 - accuracy: 0.8982 - val_loss: 0.3144 - val_accuracy: 0.8493\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2595 - accuracy: 0.8992 - val_loss: 0.3128 - val_accuracy: 0.8447\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2567 - accuracy: 0.8992 - val_loss: 0.3113 - val_accuracy: 0.8447\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2542 - accuracy: 0.9022 - val_loss: 0.3100 - val_accuracy: 0.8447\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2520 - accuracy: 0.9012 - val_loss: 0.3088 - val_accuracy: 0.8447\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2498 - accuracy: 0.9012 - val_loss: 0.3077 - val_accuracy: 0.8447\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2480 - accuracy: 0.9002 - val_loss: 0.3067 - val_accuracy: 0.8493\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2462 - accuracy: 0.9002 - val_loss: 0.3056 - val_accuracy: 0.8493\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2447 - accuracy: 0.9002 - val_loss: 0.3045 - val_accuracy: 0.8493\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2432 - accuracy: 0.9012 - val_loss: 0.3035 - val_accuracy: 0.8493\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2418 - accuracy: 0.9002 - val_loss: 0.3025 - val_accuracy: 0.8493\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2404 - accuracy: 0.9012 - val_loss: 0.3015 - val_accuracy: 0.8493\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2394 - accuracy: 0.9012 - val_loss: 0.3006 - val_accuracy: 0.8493\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2382 - accuracy: 0.9022 - val_loss: 0.2996 - val_accuracy: 0.8493\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2371 - accuracy: 0.9031 - val_loss: 0.2987 - val_accuracy: 0.8493\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2362 - accuracy: 0.9031 - val_loss: 0.2978 - val_accuracy: 0.8493\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 166us/step - loss: 0.2351 - accuracy: 0.9041 - val_loss: 0.2969 - val_accuracy: 0.8493\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 190us/step - loss: 0.2342 - accuracy: 0.9051 - val_loss: 0.2960 - val_accuracy: 0.8539\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2334 - accuracy: 0.9090 - val_loss: 0.2952 - val_accuracy: 0.8539\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.2326 - accuracy: 0.9090 - val_loss: 0.2943 - val_accuracy: 0.8539\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 169us/step - loss: 0.2318 - accuracy: 0.9090 - val_loss: 0.2935 - val_accuracy: 0.8539\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 193us/step - loss: 0.2310 - accuracy: 0.9100 - val_loss: 0.2927 - val_accuracy: 0.8539\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2303 - accuracy: 0.9100 - val_loss: 0.2919 - val_accuracy: 0.8584\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2296 - accuracy: 0.9100 - val_loss: 0.2912 - val_accuracy: 0.8584\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2289 - accuracy: 0.9100 - val_loss: 0.2905 - val_accuracy: 0.8584\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2283 - accuracy: 0.9110 - val_loss: 0.2898 - val_accuracy: 0.8584\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.2276 - accuracy: 0.9090 - val_loss: 0.2891 - val_accuracy: 0.8584\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.2271 - accuracy: 0.9100 - val_loss: 0.2883 - val_accuracy: 0.8584\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2265 - accuracy: 0.9119 - val_loss: 0.2877 - val_accuracy: 0.8584\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2259 - accuracy: 0.9119 - val_loss: 0.2871 - val_accuracy: 0.8584\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2254 - accuracy: 0.9110 - val_loss: 0.2865 - val_accuracy: 0.8584\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2249 - accuracy: 0.9100 - val_loss: 0.2859 - val_accuracy: 0.8584\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2243 - accuracy: 0.9100 - val_loss: 0.2853 - val_accuracy: 0.8584\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2238 - accuracy: 0.9080 - val_loss: 0.2847 - val_accuracy: 0.8584\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2233 - accuracy: 0.9080 - val_loss: 0.2841 - val_accuracy: 0.8584\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.2228 - accuracy: 0.9090 - val_loss: 0.2835 - val_accuracy: 0.8584\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2222 - accuracy: 0.9080 - val_loss: 0.2831 - val_accuracy: 0.8584\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2219 - accuracy: 0.9080 - val_loss: 0.2826 - val_accuracy: 0.8584\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2213 - accuracy: 0.9090 - val_loss: 0.2821 - val_accuracy: 0.8584\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2209 - accuracy: 0.9090 - val_loss: 0.2816 - val_accuracy: 0.8584\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2204 - accuracy: 0.9100 - val_loss: 0.2811 - val_accuracy: 0.8584\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2201 - accuracy: 0.9100 - val_loss: 0.2807 - val_accuracy: 0.8584\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2196 - accuracy: 0.9119 - val_loss: 0.2802 - val_accuracy: 0.8584\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 179us/step - loss: 0.2191 - accuracy: 0.9110 - val_loss: 0.2797 - val_accuracy: 0.8584\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2186 - accuracy: 0.9110 - val_loss: 0.2793 - val_accuracy: 0.8584\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.2183 - accuracy: 0.9119 - val_loss: 0.2790 - val_accuracy: 0.8584\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2179 - accuracy: 0.9129 - val_loss: 0.2786 - val_accuracy: 0.8630\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2174 - accuracy: 0.9129 - val_loss: 0.2782 - val_accuracy: 0.8630\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2171 - accuracy: 0.9139 - val_loss: 0.2778 - val_accuracy: 0.8630\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2167 - accuracy: 0.9129 - val_loss: 0.2774 - val_accuracy: 0.8676\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2164 - accuracy: 0.9119 - val_loss: 0.2770 - val_accuracy: 0.8676\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2160 - accuracy: 0.9129 - val_loss: 0.2767 - val_accuracy: 0.8721\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2156 - accuracy: 0.9129 - val_loss: 0.2764 - val_accuracy: 0.8721\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2152 - accuracy: 0.9129 - val_loss: 0.2762 - val_accuracy: 0.8767\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2149 - accuracy: 0.9129 - val_loss: 0.2759 - val_accuracy: 0.8767\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2145 - accuracy: 0.9129 - val_loss: 0.2756 - val_accuracy: 0.8721\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.2142 - accuracy: 0.9129 - val_loss: 0.2754 - val_accuracy: 0.8721\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2139 - accuracy: 0.9129 - val_loss: 0.2752 - val_accuracy: 0.8721\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 202us/step - loss: 0.2135 - accuracy: 0.9129 - val_loss: 0.2751 - val_accuracy: 0.8721\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2131 - accuracy: 0.9139 - val_loss: 0.2748 - val_accuracy: 0.8721\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2128 - accuracy: 0.9139 - val_loss: 0.2746 - val_accuracy: 0.8721\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2125 - accuracy: 0.9129 - val_loss: 0.2744 - val_accuracy: 0.8721\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 169us/step - loss: 0.2122 - accuracy: 0.9129 - val_loss: 0.2742 - val_accuracy: 0.8721\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 185us/step - loss: 0.2119 - accuracy: 0.9129 - val_loss: 0.2740 - val_accuracy: 0.8721\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2116 - accuracy: 0.9129 - val_loss: 0.2738 - val_accuracy: 0.8721\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 189us/step - loss: 0.2112 - accuracy: 0.9129 - val_loss: 0.2738 - val_accuracy: 0.8721\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2109 - accuracy: 0.9129 - val_loss: 0.2735 - val_accuracy: 0.8767\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2107 - accuracy: 0.9129 - val_loss: 0.2734 - val_accuracy: 0.8767\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2104 - accuracy: 0.9129 - val_loss: 0.2732 - val_accuracy: 0.8767\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2101 - accuracy: 0.9129 - val_loss: 0.2731 - val_accuracy: 0.8767\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2097 - accuracy: 0.9119 - val_loss: 0.2730 - val_accuracy: 0.8767\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 187us/step - loss: 0.2095 - accuracy: 0.9129 - val_loss: 0.2728 - val_accuracy: 0.8767\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 182us/step - loss: 0.2092 - accuracy: 0.9139 - val_loss: 0.2726 - val_accuracy: 0.8767\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2090 - accuracy: 0.9149 - val_loss: 0.2725 - val_accuracy: 0.8767\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.2088 - accuracy: 0.9129 - val_loss: 0.2724 - val_accuracy: 0.8767\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2084 - accuracy: 0.9139 - val_loss: 0.2722 - val_accuracy: 0.8813\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.2082 - accuracy: 0.9139 - val_loss: 0.2720 - val_accuracy: 0.8813\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 166us/step - loss: 0.2078 - accuracy: 0.9139 - val_loss: 0.2719 - val_accuracy: 0.8813\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2076 - accuracy: 0.9139 - val_loss: 0.2717 - val_accuracy: 0.8813\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2074 - accuracy: 0.9139 - val_loss: 0.2716 - val_accuracy: 0.8813\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2071 - accuracy: 0.9129 - val_loss: 0.2715 - val_accuracy: 0.8813\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 790us/step - loss: 0.6790 - accuracy: 0.6174 - val_loss: 0.6334 - val_accuracy: 0.7078\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 167us/step - loss: 0.5966 - accuracy: 0.7583 - val_loss: 0.5867 - val_accuracy: 0.7900\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.5592 - accuracy: 0.8170 - val_loss: 0.5586 - val_accuracy: 0.8219\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.5332 - accuracy: 0.8376 - val_loss: 0.5384 - val_accuracy: 0.8219\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.5124 - accuracy: 0.8415 - val_loss: 0.5224 - val_accuracy: 0.8311\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.4948 - accuracy: 0.8562 - val_loss: 0.5090 - val_accuracy: 0.8447\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.4800 - accuracy: 0.8611 - val_loss: 0.4980 - val_accuracy: 0.8447\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.4672 - accuracy: 0.8650 - val_loss: 0.4885 - val_accuracy: 0.8356\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.4560 - accuracy: 0.8699 - val_loss: 0.4800 - val_accuracy: 0.8493\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.4455 - accuracy: 0.8796 - val_loss: 0.4724 - val_accuracy: 0.8447\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.4357 - accuracy: 0.8836 - val_loss: 0.4653 - val_accuracy: 0.8447\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.4268 - accuracy: 0.8894 - val_loss: 0.4588 - val_accuracy: 0.8447\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.4182 - accuracy: 0.8914 - val_loss: 0.4528 - val_accuracy: 0.8402\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.4103 - accuracy: 0.8933 - val_loss: 0.4468 - val_accuracy: 0.8402\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.4028 - accuracy: 0.8963 - val_loss: 0.4403 - val_accuracy: 0.8402\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.3955 - accuracy: 0.8982 - val_loss: 0.4336 - val_accuracy: 0.8402\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.3888 - accuracy: 0.9012 - val_loss: 0.4275 - val_accuracy: 0.8402\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.3825 - accuracy: 0.9031 - val_loss: 0.4218 - val_accuracy: 0.8447\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.3766 - accuracy: 0.9051 - val_loss: 0.4167 - val_accuracy: 0.8447\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.3710 - accuracy: 0.9070 - val_loss: 0.4119 - val_accuracy: 0.8447\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.3658 - accuracy: 0.9051 - val_loss: 0.4075 - val_accuracy: 0.8402\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.3611 - accuracy: 0.9080 - val_loss: 0.4035 - val_accuracy: 0.8402\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.3565 - accuracy: 0.9051 - val_loss: 0.3997 - val_accuracy: 0.8447\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.3522 - accuracy: 0.9090 - val_loss: 0.3963 - val_accuracy: 0.8493\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.3482 - accuracy: 0.9070 - val_loss: 0.3930 - val_accuracy: 0.8539\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.3443 - accuracy: 0.9090 - val_loss: 0.3899 - val_accuracy: 0.8539\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.3407 - accuracy: 0.9051 - val_loss: 0.3870 - val_accuracy: 0.8539\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.3373 - accuracy: 0.9070 - val_loss: 0.3843 - val_accuracy: 0.8584\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 183us/step - loss: 0.3341 - accuracy: 0.9070 - val_loss: 0.3817 - val_accuracy: 0.8584\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.3310 - accuracy: 0.9080 - val_loss: 0.3792 - val_accuracy: 0.8584\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.3281 - accuracy: 0.9080 - val_loss: 0.3770 - val_accuracy: 0.8584\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.3253 - accuracy: 0.9080 - val_loss: 0.3747 - val_accuracy: 0.8584\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.3225 - accuracy: 0.9080 - val_loss: 0.3726 - val_accuracy: 0.8584\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.3200 - accuracy: 0.9070 - val_loss: 0.3707 - val_accuracy: 0.8584\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.3176 - accuracy: 0.9051 - val_loss: 0.3688 - val_accuracy: 0.8584\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.3151 - accuracy: 0.9061 - val_loss: 0.3668 - val_accuracy: 0.8584\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.3128 - accuracy: 0.9051 - val_loss: 0.3650 - val_accuracy: 0.8584\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.3106 - accuracy: 0.9041 - val_loss: 0.3633 - val_accuracy: 0.8584\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 187us/step - loss: 0.3084 - accuracy: 0.9051 - val_loss: 0.3617 - val_accuracy: 0.8584\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.3063 - accuracy: 0.9041 - val_loss: 0.3600 - val_accuracy: 0.8584\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.3044 - accuracy: 0.9051 - val_loss: 0.3584 - val_accuracy: 0.8630\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.3025 - accuracy: 0.9041 - val_loss: 0.3570 - val_accuracy: 0.8630\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.3006 - accuracy: 0.9041 - val_loss: 0.3555 - val_accuracy: 0.8630\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2988 - accuracy: 0.9051 - val_loss: 0.3542 - val_accuracy: 0.8630\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2972 - accuracy: 0.9061 - val_loss: 0.3528 - val_accuracy: 0.8630\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2955 - accuracy: 0.9061 - val_loss: 0.3516 - val_accuracy: 0.8630\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2939 - accuracy: 0.9041 - val_loss: 0.3504 - val_accuracy: 0.8630\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2923 - accuracy: 0.9061 - val_loss: 0.3492 - val_accuracy: 0.8630\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2909 - accuracy: 0.9061 - val_loss: 0.3481 - val_accuracy: 0.8630\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2894 - accuracy: 0.9070 - val_loss: 0.3470 - val_accuracy: 0.8630\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2881 - accuracy: 0.9051 - val_loss: 0.3459 - val_accuracy: 0.8630\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.2867 - accuracy: 0.9061 - val_loss: 0.3447 - val_accuracy: 0.8630\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2855 - accuracy: 0.9051 - val_loss: 0.3437 - val_accuracy: 0.8630\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2842 - accuracy: 0.9070 - val_loss: 0.3428 - val_accuracy: 0.8630\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2830 - accuracy: 0.9061 - val_loss: 0.3418 - val_accuracy: 0.8630\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2818 - accuracy: 0.9061 - val_loss: 0.3411 - val_accuracy: 0.8630\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2807 - accuracy: 0.9070 - val_loss: 0.3403 - val_accuracy: 0.8630\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2796 - accuracy: 0.9070 - val_loss: 0.3393 - val_accuracy: 0.8630\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2785 - accuracy: 0.9061 - val_loss: 0.3385 - val_accuracy: 0.8630\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2774 - accuracy: 0.9061 - val_loss: 0.3378 - val_accuracy: 0.8630\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2764 - accuracy: 0.9070 - val_loss: 0.3371 - val_accuracy: 0.8630\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.2754 - accuracy: 0.9061 - val_loss: 0.3363 - val_accuracy: 0.8630\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 168us/step - loss: 0.2744 - accuracy: 0.9070 - val_loss: 0.3357 - val_accuracy: 0.8630\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 168us/step - loss: 0.2735 - accuracy: 0.9080 - val_loss: 0.3352 - val_accuracy: 0.8630\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 175us/step - loss: 0.2726 - accuracy: 0.9070 - val_loss: 0.3344 - val_accuracy: 0.8630\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2716 - accuracy: 0.9080 - val_loss: 0.3337 - val_accuracy: 0.8630\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2706 - accuracy: 0.9061 - val_loss: 0.3331 - val_accuracy: 0.8630\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2699 - accuracy: 0.9080 - val_loss: 0.3325 - val_accuracy: 0.8630\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2689 - accuracy: 0.9080 - val_loss: 0.3320 - val_accuracy: 0.8630\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2682 - accuracy: 0.9080 - val_loss: 0.3315 - val_accuracy: 0.8630\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2673 - accuracy: 0.9080 - val_loss: 0.3309 - val_accuracy: 0.8630\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2665 - accuracy: 0.9100 - val_loss: 0.3302 - val_accuracy: 0.8630\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2658 - accuracy: 0.9080 - val_loss: 0.3296 - val_accuracy: 0.8630\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2650 - accuracy: 0.9070 - val_loss: 0.3291 - val_accuracy: 0.8630\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 166us/step - loss: 0.2642 - accuracy: 0.9070 - val_loss: 0.3286 - val_accuracy: 0.8630\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 185us/step - loss: 0.2636 - accuracy: 0.9080 - val_loss: 0.3280 - val_accuracy: 0.8630\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2628 - accuracy: 0.9080 - val_loss: 0.3275 - val_accuracy: 0.8630\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2623 - accuracy: 0.9080 - val_loss: 0.3271 - val_accuracy: 0.8676\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2615 - accuracy: 0.9080 - val_loss: 0.3266 - val_accuracy: 0.8676\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2608 - accuracy: 0.9080 - val_loss: 0.3262 - val_accuracy: 0.8676\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2601 - accuracy: 0.9080 - val_loss: 0.3257 - val_accuracy: 0.8676\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2595 - accuracy: 0.9080 - val_loss: 0.3252 - val_accuracy: 0.8676\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2588 - accuracy: 0.9090 - val_loss: 0.3247 - val_accuracy: 0.8676\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2580 - accuracy: 0.9070 - val_loss: 0.3242 - val_accuracy: 0.8676\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2576 - accuracy: 0.9080 - val_loss: 0.3237 - val_accuracy: 0.8676\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2569 - accuracy: 0.9061 - val_loss: 0.3232 - val_accuracy: 0.8676\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2561 - accuracy: 0.9061 - val_loss: 0.3227 - val_accuracy: 0.8676\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2556 - accuracy: 0.9080 - val_loss: 0.3222 - val_accuracy: 0.8676\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 180us/step - loss: 0.2550 - accuracy: 0.9070 - val_loss: 0.3216 - val_accuracy: 0.8676\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2544 - accuracy: 0.9080 - val_loss: 0.3211 - val_accuracy: 0.8676\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.2538 - accuracy: 0.9070 - val_loss: 0.3206 - val_accuracy: 0.8676\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2531 - accuracy: 0.9080 - val_loss: 0.3200 - val_accuracy: 0.8676\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2526 - accuracy: 0.9070 - val_loss: 0.3196 - val_accuracy: 0.8676\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2521 - accuracy: 0.9080 - val_loss: 0.3192 - val_accuracy: 0.8676\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2516 - accuracy: 0.9080 - val_loss: 0.3186 - val_accuracy: 0.8676\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2509 - accuracy: 0.9090 - val_loss: 0.3180 - val_accuracy: 0.8721\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2504 - accuracy: 0.9080 - val_loss: 0.3175 - val_accuracy: 0.8721\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2499 - accuracy: 0.9090 - val_loss: 0.3171 - val_accuracy: 0.8721\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2492 - accuracy: 0.9100 - val_loss: 0.3166 - val_accuracy: 0.8721\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2487 - accuracy: 0.9110 - val_loss: 0.3161 - val_accuracy: 0.8721\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 874us/step - loss: 0.7259 - accuracy: 0.4550 - val_loss: 0.6570 - val_accuracy: 0.6301\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.6117 - accuracy: 0.7417 - val_loss: 0.5778 - val_accuracy: 0.8037\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.5389 - accuracy: 0.8278 - val_loss: 0.5224 - val_accuracy: 0.8402\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.4851 - accuracy: 0.8718 - val_loss: 0.4786 - val_accuracy: 0.8630\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.4419 - accuracy: 0.8904 - val_loss: 0.4435 - val_accuracy: 0.8539\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.4071 - accuracy: 0.8865 - val_loss: 0.4161 - val_accuracy: 0.8539\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.3790 - accuracy: 0.8894 - val_loss: 0.3943 - val_accuracy: 0.8584\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.3560 - accuracy: 0.8885 - val_loss: 0.3766 - val_accuracy: 0.8630\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.3371 - accuracy: 0.8943 - val_loss: 0.3624 - val_accuracy: 0.8721\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.3215 - accuracy: 0.8953 - val_loss: 0.3513 - val_accuracy: 0.8676\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.3086 - accuracy: 0.8992 - val_loss: 0.3420 - val_accuracy: 0.8721\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2981 - accuracy: 0.9002 - val_loss: 0.3349 - val_accuracy: 0.8767\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.2893 - accuracy: 0.9031 - val_loss: 0.3289 - val_accuracy: 0.8721\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2822 - accuracy: 0.9031 - val_loss: 0.3238 - val_accuracy: 0.8721\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2760 - accuracy: 0.9031 - val_loss: 0.3198 - val_accuracy: 0.8721\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2709 - accuracy: 0.9031 - val_loss: 0.3164 - val_accuracy: 0.8676\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2664 - accuracy: 0.9041 - val_loss: 0.3133 - val_accuracy: 0.8676\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2626 - accuracy: 0.9041 - val_loss: 0.3107 - val_accuracy: 0.8676\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2592 - accuracy: 0.9041 - val_loss: 0.3083 - val_accuracy: 0.8676\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2562 - accuracy: 0.9031 - val_loss: 0.3060 - val_accuracy: 0.8630\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2536 - accuracy: 0.9031 - val_loss: 0.3040 - val_accuracy: 0.8539\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2512 - accuracy: 0.9012 - val_loss: 0.3024 - val_accuracy: 0.8539\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2493 - accuracy: 0.9022 - val_loss: 0.3008 - val_accuracy: 0.8493\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2473 - accuracy: 0.9041 - val_loss: 0.2999 - val_accuracy: 0.8493\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2458 - accuracy: 0.9022 - val_loss: 0.2983 - val_accuracy: 0.8539\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2442 - accuracy: 0.9041 - val_loss: 0.2975 - val_accuracy: 0.8539\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2427 - accuracy: 0.9041 - val_loss: 0.2964 - val_accuracy: 0.8539\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2413 - accuracy: 0.9041 - val_loss: 0.2957 - val_accuracy: 0.8539\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2401 - accuracy: 0.9022 - val_loss: 0.2950 - val_accuracy: 0.8539\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2389 - accuracy: 0.9031 - val_loss: 0.2943 - val_accuracy: 0.8539\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2377 - accuracy: 0.9031 - val_loss: 0.2934 - val_accuracy: 0.8539\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2367 - accuracy: 0.9031 - val_loss: 0.2926 - val_accuracy: 0.8539\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2357 - accuracy: 0.9031 - val_loss: 0.2919 - val_accuracy: 0.8539\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2349 - accuracy: 0.9031 - val_loss: 0.2913 - val_accuracy: 0.8539\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2342 - accuracy: 0.9031 - val_loss: 0.2908 - val_accuracy: 0.8539\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2331 - accuracy: 0.9031 - val_loss: 0.2900 - val_accuracy: 0.8539\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2323 - accuracy: 0.9031 - val_loss: 0.2897 - val_accuracy: 0.8539\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2318 - accuracy: 0.9031 - val_loss: 0.2888 - val_accuracy: 0.8539\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.2308 - accuracy: 0.9041 - val_loss: 0.2888 - val_accuracy: 0.8539\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2301 - accuracy: 0.9041 - val_loss: 0.2883 - val_accuracy: 0.8539\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2294 - accuracy: 0.9041 - val_loss: 0.2880 - val_accuracy: 0.8584\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.2288 - accuracy: 0.9041 - val_loss: 0.2873 - val_accuracy: 0.8584\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2281 - accuracy: 0.9041 - val_loss: 0.2866 - val_accuracy: 0.8630\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2275 - accuracy: 0.9051 - val_loss: 0.2861 - val_accuracy: 0.8721\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2270 - accuracy: 0.9051 - val_loss: 0.2858 - val_accuracy: 0.8721\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2261 - accuracy: 0.9051 - val_loss: 0.2852 - val_accuracy: 0.8721\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2257 - accuracy: 0.9061 - val_loss: 0.2849 - val_accuracy: 0.8721\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2250 - accuracy: 0.9061 - val_loss: 0.2849 - val_accuracy: 0.8721\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2244 - accuracy: 0.9061 - val_loss: 0.2845 - val_accuracy: 0.8721\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2237 - accuracy: 0.9070 - val_loss: 0.2841 - val_accuracy: 0.8721\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2232 - accuracy: 0.9061 - val_loss: 0.2839 - val_accuracy: 0.8767\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2227 - accuracy: 0.9061 - val_loss: 0.2837 - val_accuracy: 0.8721\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2222 - accuracy: 0.9070 - val_loss: 0.2830 - val_accuracy: 0.8767\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2216 - accuracy: 0.9070 - val_loss: 0.2824 - val_accuracy: 0.8767\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2212 - accuracy: 0.9070 - val_loss: 0.2822 - val_accuracy: 0.8767\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2208 - accuracy: 0.9080 - val_loss: 0.2820 - val_accuracy: 0.8767\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2202 - accuracy: 0.9080 - val_loss: 0.2816 - val_accuracy: 0.8767\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2197 - accuracy: 0.9080 - val_loss: 0.2809 - val_accuracy: 0.8767\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 196us/step - loss: 0.2193 - accuracy: 0.9090 - val_loss: 0.2810 - val_accuracy: 0.8767\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.2188 - accuracy: 0.9100 - val_loss: 0.2810 - val_accuracy: 0.8767\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2183 - accuracy: 0.9090 - val_loss: 0.2807 - val_accuracy: 0.8767\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2180 - accuracy: 0.9080 - val_loss: 0.2804 - val_accuracy: 0.8767\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2174 - accuracy: 0.9100 - val_loss: 0.2805 - val_accuracy: 0.8721\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2170 - accuracy: 0.9090 - val_loss: 0.2801 - val_accuracy: 0.8676\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2166 - accuracy: 0.9100 - val_loss: 0.2798 - val_accuracy: 0.8676\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2160 - accuracy: 0.9090 - val_loss: 0.2794 - val_accuracy: 0.8676\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2156 - accuracy: 0.9100 - val_loss: 0.2794 - val_accuracy: 0.8676\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2152 - accuracy: 0.9090 - val_loss: 0.2789 - val_accuracy: 0.8676\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2148 - accuracy: 0.9090 - val_loss: 0.2787 - val_accuracy: 0.8676\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2144 - accuracy: 0.9110 - val_loss: 0.2781 - val_accuracy: 0.8676\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2139 - accuracy: 0.9100 - val_loss: 0.2776 - val_accuracy: 0.8721\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2134 - accuracy: 0.9100 - val_loss: 0.2774 - val_accuracy: 0.8721\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2133 - accuracy: 0.9080 - val_loss: 0.2774 - val_accuracy: 0.8676\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2127 - accuracy: 0.9090 - val_loss: 0.2776 - val_accuracy: 0.8676\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2125 - accuracy: 0.9100 - val_loss: 0.2772 - val_accuracy: 0.8676\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2119 - accuracy: 0.9100 - val_loss: 0.2771 - val_accuracy: 0.8676\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2117 - accuracy: 0.9090 - val_loss: 0.2766 - val_accuracy: 0.8676\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2112 - accuracy: 0.9110 - val_loss: 0.2759 - val_accuracy: 0.8721\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2108 - accuracy: 0.9110 - val_loss: 0.2759 - val_accuracy: 0.8676\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.2104 - accuracy: 0.9090 - val_loss: 0.2756 - val_accuracy: 0.8721\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2100 - accuracy: 0.9090 - val_loss: 0.2753 - val_accuracy: 0.8767\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.2097 - accuracy: 0.9110 - val_loss: 0.2752 - val_accuracy: 0.8721\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2092 - accuracy: 0.9100 - val_loss: 0.2750 - val_accuracy: 0.8767\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.2087 - accuracy: 0.9119 - val_loss: 0.2754 - val_accuracy: 0.8721\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2084 - accuracy: 0.9119 - val_loss: 0.2753 - val_accuracy: 0.8721\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2081 - accuracy: 0.9110 - val_loss: 0.2747 - val_accuracy: 0.8767\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2077 - accuracy: 0.9119 - val_loss: 0.2748 - val_accuracy: 0.8721\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2074 - accuracy: 0.9110 - val_loss: 0.2746 - val_accuracy: 0.8721\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2071 - accuracy: 0.9119 - val_loss: 0.2750 - val_accuracy: 0.8721\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2067 - accuracy: 0.9100 - val_loss: 0.2742 - val_accuracy: 0.8767\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2063 - accuracy: 0.9129 - val_loss: 0.2741 - val_accuracy: 0.8767\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2059 - accuracy: 0.9119 - val_loss: 0.2735 - val_accuracy: 0.8767\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2055 - accuracy: 0.9129 - val_loss: 0.2740 - val_accuracy: 0.8721\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2053 - accuracy: 0.9119 - val_loss: 0.2739 - val_accuracy: 0.8721\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2049 - accuracy: 0.9139 - val_loss: 0.2736 - val_accuracy: 0.8767\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2045 - accuracy: 0.9119 - val_loss: 0.2738 - val_accuracy: 0.8721\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2042 - accuracy: 0.9129 - val_loss: 0.2740 - val_accuracy: 0.8721\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2038 - accuracy: 0.9119 - val_loss: 0.2735 - val_accuracy: 0.8767\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2032 - accuracy: 0.9129 - val_loss: 0.2738 - val_accuracy: 0.8721\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2030 - accuracy: 0.9119 - val_loss: 0.2734 - val_accuracy: 0.8767\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 761us/step - loss: 0.5187 - accuracy: 0.7769 - val_loss: 0.5054 - val_accuracy: 0.8037\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.4714 - accuracy: 0.8288 - val_loss: 0.4664 - val_accuracy: 0.8311\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.4345 - accuracy: 0.8611 - val_loss: 0.4350 - val_accuracy: 0.8493\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.4046 - accuracy: 0.8767 - val_loss: 0.4094 - val_accuracy: 0.8402\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.3800 - accuracy: 0.8816 - val_loss: 0.3880 - val_accuracy: 0.8447\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.3594 - accuracy: 0.8875 - val_loss: 0.3702 - val_accuracy: 0.8539\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.3425 - accuracy: 0.8904 - val_loss: 0.3556 - val_accuracy: 0.8584\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.3284 - accuracy: 0.8914 - val_loss: 0.3435 - val_accuracy: 0.8676\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.3164 - accuracy: 0.8933 - val_loss: 0.3333 - val_accuracy: 0.8676\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.3061 - accuracy: 0.8953 - val_loss: 0.3250 - val_accuracy: 0.8676\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2973 - accuracy: 0.8953 - val_loss: 0.3181 - val_accuracy: 0.8676\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2896 - accuracy: 0.9002 - val_loss: 0.3122 - val_accuracy: 0.8676\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.2827 - accuracy: 0.9002 - val_loss: 0.3071 - val_accuracy: 0.8676\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.2769 - accuracy: 0.9002 - val_loss: 0.3031 - val_accuracy: 0.8721\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2718 - accuracy: 0.9031 - val_loss: 0.2997 - val_accuracy: 0.8721\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.2674 - accuracy: 0.9031 - val_loss: 0.2968 - val_accuracy: 0.8721\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2635 - accuracy: 0.9051 - val_loss: 0.2945 - val_accuracy: 0.8721\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2600 - accuracy: 0.9061 - val_loss: 0.2925 - val_accuracy: 0.8721\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2569 - accuracy: 0.9051 - val_loss: 0.2905 - val_accuracy: 0.8767\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2542 - accuracy: 0.9080 - val_loss: 0.2892 - val_accuracy: 0.8767\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2519 - accuracy: 0.9090 - val_loss: 0.2878 - val_accuracy: 0.8767\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2496 - accuracy: 0.9100 - val_loss: 0.2866 - val_accuracy: 0.8767\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.2475 - accuracy: 0.9100 - val_loss: 0.2857 - val_accuracy: 0.8767\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2458 - accuracy: 0.9090 - val_loss: 0.2847 - val_accuracy: 0.8676\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2440 - accuracy: 0.9080 - val_loss: 0.2842 - val_accuracy: 0.8721\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 171us/step - loss: 0.2426 - accuracy: 0.9070 - val_loss: 0.2835 - val_accuracy: 0.8721\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 166us/step - loss: 0.2411 - accuracy: 0.9061 - val_loss: 0.2828 - val_accuracy: 0.8767\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.2397 - accuracy: 0.9061 - val_loss: 0.2818 - val_accuracy: 0.8767\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2386 - accuracy: 0.9070 - val_loss: 0.2810 - val_accuracy: 0.8767\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2372 - accuracy: 0.9080 - val_loss: 0.2803 - val_accuracy: 0.8767\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2361 - accuracy: 0.9070 - val_loss: 0.2800 - val_accuracy: 0.8767\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2351 - accuracy: 0.9080 - val_loss: 0.2792 - val_accuracy: 0.8767\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2341 - accuracy: 0.9080 - val_loss: 0.2786 - val_accuracy: 0.8767\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 183us/step - loss: 0.2332 - accuracy: 0.9080 - val_loss: 0.2778 - val_accuracy: 0.8721\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 168us/step - loss: 0.2322 - accuracy: 0.9100 - val_loss: 0.2772 - val_accuracy: 0.8721\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2315 - accuracy: 0.9110 - val_loss: 0.2766 - val_accuracy: 0.8721\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2308 - accuracy: 0.9110 - val_loss: 0.2761 - val_accuracy: 0.8721\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2299 - accuracy: 0.9119 - val_loss: 0.2755 - val_accuracy: 0.8721\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.2292 - accuracy: 0.9119 - val_loss: 0.2750 - val_accuracy: 0.8721\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2286 - accuracy: 0.9129 - val_loss: 0.2747 - val_accuracy: 0.8676\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2278 - accuracy: 0.9129 - val_loss: 0.2742 - val_accuracy: 0.8676\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2272 - accuracy: 0.9129 - val_loss: 0.2740 - val_accuracy: 0.8676\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2265 - accuracy: 0.9139 - val_loss: 0.2735 - val_accuracy: 0.8676\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2260 - accuracy: 0.9149 - val_loss: 0.2731 - val_accuracy: 0.8676\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 225us/step - loss: 0.2253 - accuracy: 0.9119 - val_loss: 0.2726 - val_accuracy: 0.8676\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2249 - accuracy: 0.9149 - val_loss: 0.2725 - val_accuracy: 0.8676\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2242 - accuracy: 0.9159 - val_loss: 0.2724 - val_accuracy: 0.8676\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.2237 - accuracy: 0.9159 - val_loss: 0.2719 - val_accuracy: 0.8676\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 167us/step - loss: 0.2231 - accuracy: 0.9129 - val_loss: 0.2714 - val_accuracy: 0.8676\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2227 - accuracy: 0.9129 - val_loss: 0.2707 - val_accuracy: 0.8676\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 166us/step - loss: 0.2222 - accuracy: 0.9139 - val_loss: 0.2702 - val_accuracy: 0.8676\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 172us/step - loss: 0.2216 - accuracy: 0.9139 - val_loss: 0.2700 - val_accuracy: 0.8676\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2212 - accuracy: 0.9149 - val_loss: 0.2698 - val_accuracy: 0.8676\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2207 - accuracy: 0.9139 - val_loss: 0.2697 - val_accuracy: 0.8676\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2202 - accuracy: 0.9129 - val_loss: 0.2696 - val_accuracy: 0.8630\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2198 - accuracy: 0.9139 - val_loss: 0.2693 - val_accuracy: 0.8676\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2193 - accuracy: 0.9139 - val_loss: 0.2692 - val_accuracy: 0.8630\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2189 - accuracy: 0.9129 - val_loss: 0.2688 - val_accuracy: 0.8630\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.2185 - accuracy: 0.9139 - val_loss: 0.2684 - val_accuracy: 0.8721\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 166us/step - loss: 0.2180 - accuracy: 0.9149 - val_loss: 0.2683 - val_accuracy: 0.8676\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 171us/step - loss: 0.2176 - accuracy: 0.9139 - val_loss: 0.2680 - val_accuracy: 0.8584\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2171 - accuracy: 0.9129 - val_loss: 0.2679 - val_accuracy: 0.8630\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 173us/step - loss: 0.2168 - accuracy: 0.9139 - val_loss: 0.2674 - val_accuracy: 0.8630\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2165 - accuracy: 0.9149 - val_loss: 0.2670 - val_accuracy: 0.8630\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2161 - accuracy: 0.9139 - val_loss: 0.2667 - val_accuracy: 0.8630\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.2158 - accuracy: 0.9139 - val_loss: 0.2666 - val_accuracy: 0.8630\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2154 - accuracy: 0.9129 - val_loss: 0.2664 - val_accuracy: 0.8630\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2151 - accuracy: 0.9129 - val_loss: 0.2665 - val_accuracy: 0.8630\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2148 - accuracy: 0.9139 - val_loss: 0.2661 - val_accuracy: 0.8630\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2143 - accuracy: 0.9129 - val_loss: 0.2662 - val_accuracy: 0.8584\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.2141 - accuracy: 0.9139 - val_loss: 0.2659 - val_accuracy: 0.8584\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2138 - accuracy: 0.9129 - val_loss: 0.2658 - val_accuracy: 0.8584\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2135 - accuracy: 0.9129 - val_loss: 0.2657 - val_accuracy: 0.8630\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2129 - accuracy: 0.9129 - val_loss: 0.2658 - val_accuracy: 0.8584\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 195us/step - loss: 0.2128 - accuracy: 0.9139 - val_loss: 0.2655 - val_accuracy: 0.8630\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2124 - accuracy: 0.9139 - val_loss: 0.2655 - val_accuracy: 0.8630\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 428us/step - loss: 0.2120 - accuracy: 0.9129 - val_loss: 0.2649 - val_accuracy: 0.8630\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 260us/step - loss: 0.2118 - accuracy: 0.9110 - val_loss: 0.2650 - val_accuracy: 0.8630\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 210us/step - loss: 0.2116 - accuracy: 0.9129 - val_loss: 0.2647 - val_accuracy: 0.8630\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 207us/step - loss: 0.2112 - accuracy: 0.9129 - val_loss: 0.2644 - val_accuracy: 0.8630\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2110 - accuracy: 0.9139 - val_loss: 0.2643 - val_accuracy: 0.8630\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 216us/step - loss: 0.2105 - accuracy: 0.9139 - val_loss: 0.2642 - val_accuracy: 0.8676\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 173us/step - loss: 0.2104 - accuracy: 0.9139 - val_loss: 0.2646 - val_accuracy: 0.8630\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 198us/step - loss: 0.2100 - accuracy: 0.9119 - val_loss: 0.2645 - val_accuracy: 0.8630\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 233us/step - loss: 0.2099 - accuracy: 0.9129 - val_loss: 0.2642 - val_accuracy: 0.8676\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 207us/step - loss: 0.2096 - accuracy: 0.9129 - val_loss: 0.2640 - val_accuracy: 0.8676\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 232us/step - loss: 0.2092 - accuracy: 0.9119 - val_loss: 0.2639 - val_accuracy: 0.8676\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2089 - accuracy: 0.9129 - val_loss: 0.2637 - val_accuracy: 0.8721\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 379us/step - loss: 0.2087 - accuracy: 0.9129 - val_loss: 0.2633 - val_accuracy: 0.8721\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 412us/step - loss: 0.2082 - accuracy: 0.9129 - val_loss: 0.2634 - val_accuracy: 0.8721\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 203us/step - loss: 0.2081 - accuracy: 0.9168 - val_loss: 0.2631 - val_accuracy: 0.8721\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 377us/step - loss: 0.2078 - accuracy: 0.9129 - val_loss: 0.2630 - val_accuracy: 0.8721\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 219us/step - loss: 0.2075 - accuracy: 0.9159 - val_loss: 0.2629 - val_accuracy: 0.8721\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 302us/step - loss: 0.2073 - accuracy: 0.9149 - val_loss: 0.2628 - val_accuracy: 0.8721\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 306us/step - loss: 0.2070 - accuracy: 0.9159 - val_loss: 0.2623 - val_accuracy: 0.8721\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 304us/step - loss: 0.2067 - accuracy: 0.9159 - val_loss: 0.2625 - val_accuracy: 0.8721\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 295us/step - loss: 0.2064 - accuracy: 0.9149 - val_loss: 0.2623 - val_accuracy: 0.8721\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 379us/step - loss: 0.2061 - accuracy: 0.9168 - val_loss: 0.2620 - val_accuracy: 0.8721\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 281us/step - loss: 0.2060 - accuracy: 0.9168 - val_loss: 0.2619 - val_accuracy: 0.8721\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 182us/step - loss: 0.2056 - accuracy: 0.9168 - val_loss: 0.2621 - val_accuracy: 0.8721\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.6786 - accuracy: 0.5675 - val_loss: 0.6629 - val_accuracy: 0.6210\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 406us/step - loss: 0.6269 - accuracy: 0.6996 - val_loss: 0.6219 - val_accuracy: 0.7169\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 380us/step - loss: 0.5863 - accuracy: 0.7622 - val_loss: 0.5889 - val_accuracy: 0.7306\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 238us/step - loss: 0.5518 - accuracy: 0.7965 - val_loss: 0.5604 - val_accuracy: 0.7763\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 399us/step - loss: 0.5211 - accuracy: 0.8200 - val_loss: 0.5347 - val_accuracy: 0.7808\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 312us/step - loss: 0.4927 - accuracy: 0.8386 - val_loss: 0.5109 - val_accuracy: 0.7991\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 185us/step - loss: 0.4661 - accuracy: 0.8483 - val_loss: 0.4890 - val_accuracy: 0.8128\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 310us/step - loss: 0.4411 - accuracy: 0.8630 - val_loss: 0.4688 - val_accuracy: 0.8174\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 333us/step - loss: 0.4179 - accuracy: 0.8659 - val_loss: 0.4502 - val_accuracy: 0.8174\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 216us/step - loss: 0.3966 - accuracy: 0.8699 - val_loss: 0.4335 - val_accuracy: 0.8311\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 254us/step - loss: 0.3775 - accuracy: 0.8728 - val_loss: 0.4188 - val_accuracy: 0.8311\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 401us/step - loss: 0.3607 - accuracy: 0.8767 - val_loss: 0.4058 - val_accuracy: 0.8311\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 421us/step - loss: 0.3459 - accuracy: 0.8796 - val_loss: 0.3945 - val_accuracy: 0.8447\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 283us/step - loss: 0.3329 - accuracy: 0.8816 - val_loss: 0.3848 - val_accuracy: 0.8447\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 346us/step - loss: 0.3214 - accuracy: 0.8826 - val_loss: 0.3763 - val_accuracy: 0.8493\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 336us/step - loss: 0.3114 - accuracy: 0.8836 - val_loss: 0.3690 - val_accuracy: 0.8539\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 1s 501us/step - loss: 0.3028 - accuracy: 0.8845 - val_loss: 0.3627 - val_accuracy: 0.8539\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 247us/step - loss: 0.2951 - accuracy: 0.8875 - val_loss: 0.3571 - val_accuracy: 0.8539\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 427us/step - loss: 0.2885 - accuracy: 0.8904 - val_loss: 0.3521 - val_accuracy: 0.8539\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 327us/step - loss: 0.2825 - accuracy: 0.8894 - val_loss: 0.3473 - val_accuracy: 0.8539\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 250us/step - loss: 0.2769 - accuracy: 0.8894 - val_loss: 0.3429 - val_accuracy: 0.8539\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 483us/step - loss: 0.2721 - accuracy: 0.8904 - val_loss: 0.3387 - val_accuracy: 0.8402\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 326us/step - loss: 0.2676 - accuracy: 0.8885 - val_loss: 0.3350 - val_accuracy: 0.8402\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 184us/step - loss: 0.2637 - accuracy: 0.8904 - val_loss: 0.3314 - val_accuracy: 0.8402\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 189us/step - loss: 0.2603 - accuracy: 0.8914 - val_loss: 0.3284 - val_accuracy: 0.8447\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 293us/step - loss: 0.2569 - accuracy: 0.8924 - val_loss: 0.3257 - val_accuracy: 0.8447\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 185us/step - loss: 0.2541 - accuracy: 0.8924 - val_loss: 0.3231 - val_accuracy: 0.8447\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 225us/step - loss: 0.2515 - accuracy: 0.8914 - val_loss: 0.3207 - val_accuracy: 0.8493\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 179us/step - loss: 0.2491 - accuracy: 0.8914 - val_loss: 0.3184 - val_accuracy: 0.8447\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 223us/step - loss: 0.2468 - accuracy: 0.8914 - val_loss: 0.3162 - val_accuracy: 0.8447\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 210us/step - loss: 0.2447 - accuracy: 0.8924 - val_loss: 0.3144 - val_accuracy: 0.8493\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 197us/step - loss: 0.2430 - accuracy: 0.8924 - val_loss: 0.3125 - val_accuracy: 0.8447\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 388us/step - loss: 0.2411 - accuracy: 0.8924 - val_loss: 0.3107 - val_accuracy: 0.8447\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 340us/step - loss: 0.2397 - accuracy: 0.8924 - val_loss: 0.3090 - val_accuracy: 0.8447\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 343us/step - loss: 0.2381 - accuracy: 0.8943 - val_loss: 0.3077 - val_accuracy: 0.8493\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 288us/step - loss: 0.2367 - accuracy: 0.8982 - val_loss: 0.3064 - val_accuracy: 0.8493\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 197us/step - loss: 0.2355 - accuracy: 0.8992 - val_loss: 0.3052 - val_accuracy: 0.8493\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 270us/step - loss: 0.2342 - accuracy: 0.9002 - val_loss: 0.3039 - val_accuracy: 0.8493\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 259us/step - loss: 0.2331 - accuracy: 0.9012 - val_loss: 0.3027 - val_accuracy: 0.8539\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 316us/step - loss: 0.2321 - accuracy: 0.9022 - val_loss: 0.3016 - val_accuracy: 0.8539\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 268us/step - loss: 0.2311 - accuracy: 0.9041 - val_loss: 0.3006 - val_accuracy: 0.8539\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 290us/step - loss: 0.2301 - accuracy: 0.9031 - val_loss: 0.2995 - val_accuracy: 0.8584\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 464us/step - loss: 0.2291 - accuracy: 0.9041 - val_loss: 0.2986 - val_accuracy: 0.8584\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 229us/step - loss: 0.2283 - accuracy: 0.9041 - val_loss: 0.2977 - val_accuracy: 0.8584\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 167us/step - loss: 0.2275 - accuracy: 0.9070 - val_loss: 0.2968 - val_accuracy: 0.8584\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2266 - accuracy: 0.9070 - val_loss: 0.2959 - val_accuracy: 0.8584\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 247us/step - loss: 0.2258 - accuracy: 0.9080 - val_loss: 0.2951 - val_accuracy: 0.8584\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 187us/step - loss: 0.2250 - accuracy: 0.9061 - val_loss: 0.2944 - val_accuracy: 0.8584\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 170us/step - loss: 0.2243 - accuracy: 0.9080 - val_loss: 0.2937 - val_accuracy: 0.8584\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 186us/step - loss: 0.2236 - accuracy: 0.9061 - val_loss: 0.2929 - val_accuracy: 0.8584\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 177us/step - loss: 0.2227 - accuracy: 0.9090 - val_loss: 0.2923 - val_accuracy: 0.8584\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2222 - accuracy: 0.9100 - val_loss: 0.2914 - val_accuracy: 0.8584\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 193us/step - loss: 0.2214 - accuracy: 0.9090 - val_loss: 0.2907 - val_accuracy: 0.8584\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.2208 - accuracy: 0.9100 - val_loss: 0.2900 - val_accuracy: 0.8584\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 183us/step - loss: 0.2201 - accuracy: 0.9080 - val_loss: 0.2894 - val_accuracy: 0.8539\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 212us/step - loss: 0.2196 - accuracy: 0.9100 - val_loss: 0.2887 - val_accuracy: 0.8539\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 260us/step - loss: 0.2189 - accuracy: 0.9090 - val_loss: 0.2881 - val_accuracy: 0.8539\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 212us/step - loss: 0.2182 - accuracy: 0.9110 - val_loss: 0.2875 - val_accuracy: 0.8539\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 231us/step - loss: 0.2177 - accuracy: 0.9100 - val_loss: 0.2868 - val_accuracy: 0.8584\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 191us/step - loss: 0.2171 - accuracy: 0.9110 - val_loss: 0.2862 - val_accuracy: 0.8584\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 194us/step - loss: 0.2167 - accuracy: 0.9110 - val_loss: 0.2857 - val_accuracy: 0.8584\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 84us/step - loss: 0.2161 - accuracy: 0.9100 - val_loss: 0.2850 - val_accuracy: 0.8584\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 88us/step - loss: 0.2156 - accuracy: 0.9110 - val_loss: 0.2843 - val_accuracy: 0.8584\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 354us/step - loss: 0.2152 - accuracy: 0.9080 - val_loss: 0.2836 - val_accuracy: 0.8584\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 214us/step - loss: 0.2146 - accuracy: 0.9110 - val_loss: 0.2829 - val_accuracy: 0.8584\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 287us/step - loss: 0.2141 - accuracy: 0.9090 - val_loss: 0.2826 - val_accuracy: 0.8630\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 191us/step - loss: 0.2136 - accuracy: 0.9080 - val_loss: 0.2821 - val_accuracy: 0.8584\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 227us/step - loss: 0.2131 - accuracy: 0.9090 - val_loss: 0.2815 - val_accuracy: 0.8630\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 232us/step - loss: 0.2126 - accuracy: 0.9080 - val_loss: 0.2810 - val_accuracy: 0.8630\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 235us/step - loss: 0.2123 - accuracy: 0.9100 - val_loss: 0.2806 - val_accuracy: 0.8630\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 330us/step - loss: 0.2117 - accuracy: 0.9110 - val_loss: 0.2801 - val_accuracy: 0.8630\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 221us/step - loss: 0.2113 - accuracy: 0.9080 - val_loss: 0.2796 - val_accuracy: 0.8630\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 198us/step - loss: 0.2109 - accuracy: 0.9080 - val_loss: 0.2792 - val_accuracy: 0.8676\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 200us/step - loss: 0.2104 - accuracy: 0.9100 - val_loss: 0.2789 - val_accuracy: 0.8676\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 224us/step - loss: 0.2101 - accuracy: 0.9090 - val_loss: 0.2784 - val_accuracy: 0.8676\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 183us/step - loss: 0.2095 - accuracy: 0.9100 - val_loss: 0.2780 - val_accuracy: 0.8676\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 217us/step - loss: 0.2093 - accuracy: 0.9090 - val_loss: 0.2776 - val_accuracy: 0.8721\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 214us/step - loss: 0.2086 - accuracy: 0.9119 - val_loss: 0.2773 - val_accuracy: 0.8676\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 174us/step - loss: 0.2083 - accuracy: 0.9100 - val_loss: 0.2767 - val_accuracy: 0.8676\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2078 - accuracy: 0.9110 - val_loss: 0.2763 - val_accuracy: 0.8676\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 173us/step - loss: 0.2074 - accuracy: 0.9100 - val_loss: 0.2758 - val_accuracy: 0.8676\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 190us/step - loss: 0.2070 - accuracy: 0.9110 - val_loss: 0.2755 - val_accuracy: 0.8676\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 182us/step - loss: 0.2066 - accuracy: 0.9090 - val_loss: 0.2748 - val_accuracy: 0.8676\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 171us/step - loss: 0.2063 - accuracy: 0.9100 - val_loss: 0.2744 - val_accuracy: 0.8676\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 189us/step - loss: 0.2058 - accuracy: 0.9100 - val_loss: 0.2739 - val_accuracy: 0.8676\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 249us/step - loss: 0.2055 - accuracy: 0.9110 - val_loss: 0.2738 - val_accuracy: 0.8676\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 219us/step - loss: 0.2052 - accuracy: 0.9090 - val_loss: 0.2732 - val_accuracy: 0.8676\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 216us/step - loss: 0.2048 - accuracy: 0.9110 - val_loss: 0.2729 - val_accuracy: 0.8676\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 216us/step - loss: 0.2046 - accuracy: 0.9100 - val_loss: 0.2725 - val_accuracy: 0.8676\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 175us/step - loss: 0.2042 - accuracy: 0.9110 - val_loss: 0.2721 - val_accuracy: 0.8676\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 184us/step - loss: 0.2038 - accuracy: 0.9100 - val_loss: 0.2717 - val_accuracy: 0.8676\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 211us/step - loss: 0.2033 - accuracy: 0.9110 - val_loss: 0.2714 - val_accuracy: 0.8676\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 169us/step - loss: 0.2030 - accuracy: 0.9110 - val_loss: 0.2712 - val_accuracy: 0.8676\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 177us/step - loss: 0.2028 - accuracy: 0.9100 - val_loss: 0.2708 - val_accuracy: 0.8676\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 208us/step - loss: 0.2024 - accuracy: 0.9119 - val_loss: 0.2707 - val_accuracy: 0.8676\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.2020 - accuracy: 0.9119 - val_loss: 0.2702 - val_accuracy: 0.8676\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 182us/step - loss: 0.2017 - accuracy: 0.9100 - val_loss: 0.2697 - val_accuracy: 0.8676\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 357us/step - loss: 0.2015 - accuracy: 0.9119 - val_loss: 0.2695 - val_accuracy: 0.8676\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 215us/step - loss: 0.2011 - accuracy: 0.9129 - val_loss: 0.2693 - val_accuracy: 0.8721\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 202us/step - loss: 0.2008 - accuracy: 0.9129 - val_loss: 0.2689 - val_accuracy: 0.8721\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 876us/step - loss: 0.6201 - accuracy: 0.7368 - val_loss: 0.5787 - val_accuracy: 0.8356\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.5447 - accuracy: 0.8327 - val_loss: 0.5198 - val_accuracy: 0.8584\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.4848 - accuracy: 0.8650 - val_loss: 0.4724 - val_accuracy: 0.8539\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.4360 - accuracy: 0.8816 - val_loss: 0.4343 - val_accuracy: 0.8539\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.3973 - accuracy: 0.8865 - val_loss: 0.4041 - val_accuracy: 0.8447\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.3668 - accuracy: 0.8885 - val_loss: 0.3805 - val_accuracy: 0.8493\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.3427 - accuracy: 0.8885 - val_loss: 0.3623 - val_accuracy: 0.8539\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.3238 - accuracy: 0.8865 - val_loss: 0.3484 - val_accuracy: 0.8493\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.3085 - accuracy: 0.8914 - val_loss: 0.3373 - val_accuracy: 0.8584\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2963 - accuracy: 0.8904 - val_loss: 0.3288 - val_accuracy: 0.8630\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2864 - accuracy: 0.8904 - val_loss: 0.3221 - val_accuracy: 0.8584\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2782 - accuracy: 0.8914 - val_loss: 0.3169 - val_accuracy: 0.8539\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2713 - accuracy: 0.8904 - val_loss: 0.3127 - val_accuracy: 0.8539\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.2656 - accuracy: 0.8933 - val_loss: 0.3094 - val_accuracy: 0.8539\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2607 - accuracy: 0.8973 - val_loss: 0.3066 - val_accuracy: 0.8584\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 171us/step - loss: 0.2565 - accuracy: 0.8973 - val_loss: 0.3042 - val_accuracy: 0.8584\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 172us/step - loss: 0.2529 - accuracy: 0.8963 - val_loss: 0.3025 - val_accuracy: 0.8630\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2498 - accuracy: 0.9002 - val_loss: 0.3008 - val_accuracy: 0.8630\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2471 - accuracy: 0.8982 - val_loss: 0.2993 - val_accuracy: 0.8630\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2446 - accuracy: 0.8992 - val_loss: 0.2979 - val_accuracy: 0.8630\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2425 - accuracy: 0.8982 - val_loss: 0.2967 - val_accuracy: 0.8630\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2406 - accuracy: 0.8992 - val_loss: 0.2955 - val_accuracy: 0.8630\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2389 - accuracy: 0.8982 - val_loss: 0.2945 - val_accuracy: 0.8630\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2373 - accuracy: 0.9002 - val_loss: 0.2937 - val_accuracy: 0.8630\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2359 - accuracy: 0.9012 - val_loss: 0.2928 - val_accuracy: 0.8630\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2345 - accuracy: 0.9022 - val_loss: 0.2920 - val_accuracy: 0.8676\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2334 - accuracy: 0.9022 - val_loss: 0.2912 - val_accuracy: 0.8676\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2324 - accuracy: 0.9031 - val_loss: 0.2906 - val_accuracy: 0.8676\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2312 - accuracy: 0.9012 - val_loss: 0.2899 - val_accuracy: 0.8676\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.2302 - accuracy: 0.9012 - val_loss: 0.2892 - val_accuracy: 0.8676\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 184us/step - loss: 0.2292 - accuracy: 0.9031 - val_loss: 0.2887 - val_accuracy: 0.8676\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2285 - accuracy: 0.9022 - val_loss: 0.2882 - val_accuracy: 0.8676\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2276 - accuracy: 0.9041 - val_loss: 0.2875 - val_accuracy: 0.8676\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2269 - accuracy: 0.9051 - val_loss: 0.2869 - val_accuracy: 0.8676\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2260 - accuracy: 0.9031 - val_loss: 0.2863 - val_accuracy: 0.8676\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2254 - accuracy: 0.9070 - val_loss: 0.2858 - val_accuracy: 0.8676\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2248 - accuracy: 0.9061 - val_loss: 0.2854 - val_accuracy: 0.8676\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2240 - accuracy: 0.9061 - val_loss: 0.2850 - val_accuracy: 0.8676\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.2234 - accuracy: 0.9051 - val_loss: 0.2845 - val_accuracy: 0.8676\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.2228 - accuracy: 0.9061 - val_loss: 0.2841 - val_accuracy: 0.8676\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2221 - accuracy: 0.9080 - val_loss: 0.2837 - val_accuracy: 0.8676\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2215 - accuracy: 0.9080 - val_loss: 0.2833 - val_accuracy: 0.8676\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 100us/step - loss: 0.2210 - accuracy: 0.9080 - val_loss: 0.2827 - val_accuracy: 0.8676\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2204 - accuracy: 0.9080 - val_loss: 0.2823 - val_accuracy: 0.8676\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2198 - accuracy: 0.9090 - val_loss: 0.2819 - val_accuracy: 0.8676\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2193 - accuracy: 0.9090 - val_loss: 0.2816 - val_accuracy: 0.8676\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.2188 - accuracy: 0.9090 - val_loss: 0.2812 - val_accuracy: 0.8721\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2183 - accuracy: 0.9070 - val_loss: 0.2809 - val_accuracy: 0.8721\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2179 - accuracy: 0.9100 - val_loss: 0.2806 - val_accuracy: 0.8721\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2175 - accuracy: 0.9110 - val_loss: 0.2802 - val_accuracy: 0.8721\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2169 - accuracy: 0.9110 - val_loss: 0.2798 - val_accuracy: 0.8721\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2165 - accuracy: 0.9100 - val_loss: 0.2794 - val_accuracy: 0.8721\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.2161 - accuracy: 0.9100 - val_loss: 0.2792 - val_accuracy: 0.8676\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2157 - accuracy: 0.9110 - val_loss: 0.2787 - val_accuracy: 0.8676\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2152 - accuracy: 0.9110 - val_loss: 0.2785 - val_accuracy: 0.8676\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.2148 - accuracy: 0.9119 - val_loss: 0.2782 - val_accuracy: 0.8676\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2144 - accuracy: 0.9110 - val_loss: 0.2779 - val_accuracy: 0.8676\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2139 - accuracy: 0.9100 - val_loss: 0.2776 - val_accuracy: 0.8676\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2138 - accuracy: 0.9100 - val_loss: 0.2774 - val_accuracy: 0.8676\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2132 - accuracy: 0.9110 - val_loss: 0.2772 - val_accuracy: 0.8721\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2129 - accuracy: 0.9100 - val_loss: 0.2769 - val_accuracy: 0.8721\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2125 - accuracy: 0.9100 - val_loss: 0.2767 - val_accuracy: 0.8721\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.2122 - accuracy: 0.9080 - val_loss: 0.2765 - val_accuracy: 0.8721\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2119 - accuracy: 0.9100 - val_loss: 0.2763 - val_accuracy: 0.8767\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2115 - accuracy: 0.9090 - val_loss: 0.2761 - val_accuracy: 0.8767\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2110 - accuracy: 0.9090 - val_loss: 0.2760 - val_accuracy: 0.8767\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.2107 - accuracy: 0.9119 - val_loss: 0.2757 - val_accuracy: 0.8767\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2105 - accuracy: 0.9110 - val_loss: 0.2756 - val_accuracy: 0.8767\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.2101 - accuracy: 0.9110 - val_loss: 0.2756 - val_accuracy: 0.8767\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2099 - accuracy: 0.9100 - val_loss: 0.2754 - val_accuracy: 0.8767\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2094 - accuracy: 0.9100 - val_loss: 0.2754 - val_accuracy: 0.8767\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2092 - accuracy: 0.9100 - val_loss: 0.2753 - val_accuracy: 0.8767\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2089 - accuracy: 0.9090 - val_loss: 0.2752 - val_accuracy: 0.8767\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.2087 - accuracy: 0.9100 - val_loss: 0.2751 - val_accuracy: 0.8721\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.2083 - accuracy: 0.9110 - val_loss: 0.2749 - val_accuracy: 0.8721\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2082 - accuracy: 0.9110 - val_loss: 0.2747 - val_accuracy: 0.8721\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2078 - accuracy: 0.9110 - val_loss: 0.2745 - val_accuracy: 0.8721\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2075 - accuracy: 0.9119 - val_loss: 0.2744 - val_accuracy: 0.8721\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2072 - accuracy: 0.9090 - val_loss: 0.2743 - val_accuracy: 0.8721\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2069 - accuracy: 0.9110 - val_loss: 0.2742 - val_accuracy: 0.8721\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - ETA: 0s - loss: 0.2235 - accuracy: 0.90 - 0s 133us/step - loss: 0.2067 - accuracy: 0.9110 - val_loss: 0.2741 - val_accuracy: 0.8721\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2064 - accuracy: 0.9129 - val_loss: 0.2739 - val_accuracy: 0.8721\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2062 - accuracy: 0.9119 - val_loss: 0.2738 - val_accuracy: 0.8721\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2060 - accuracy: 0.9129 - val_loss: 0.2736 - val_accuracy: 0.8676\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2056 - accuracy: 0.9110 - val_loss: 0.2734 - val_accuracy: 0.8676\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2054 - accuracy: 0.9100 - val_loss: 0.2734 - val_accuracy: 0.8676\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2051 - accuracy: 0.9129 - val_loss: 0.2733 - val_accuracy: 0.8676\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2050 - accuracy: 0.9110 - val_loss: 0.2731 - val_accuracy: 0.8676\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2046 - accuracy: 0.9110 - val_loss: 0.2730 - val_accuracy: 0.8676\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.2044 - accuracy: 0.9139 - val_loss: 0.2728 - val_accuracy: 0.8676\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2041 - accuracy: 0.9129 - val_loss: 0.2727 - val_accuracy: 0.8676\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2041 - accuracy: 0.9110 - val_loss: 0.2725 - val_accuracy: 0.8676\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.2037 - accuracy: 0.9139 - val_loss: 0.2723 - val_accuracy: 0.8676\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2035 - accuracy: 0.9149 - val_loss: 0.2723 - val_accuracy: 0.8676\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2032 - accuracy: 0.9129 - val_loss: 0.2721 - val_accuracy: 0.8676\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2030 - accuracy: 0.9149 - val_loss: 0.2719 - val_accuracy: 0.8676\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 172us/step - loss: 0.2026 - accuracy: 0.9139 - val_loss: 0.2718 - val_accuracy: 0.8676\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 167us/step - loss: 0.2025 - accuracy: 0.9139 - val_loss: 0.2717 - val_accuracy: 0.8676\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2023 - accuracy: 0.9129 - val_loss: 0.2717 - val_accuracy: 0.8676\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2022 - accuracy: 0.9159 - val_loss: 0.2716 - val_accuracy: 0.8676\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 765us/step - loss: 0.5925 - accuracy: 0.7339 - val_loss: 0.5622 - val_accuracy: 0.8356\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.5335 - accuracy: 0.8405 - val_loss: 0.5194 - val_accuracy: 0.8402\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.4889 - accuracy: 0.8611 - val_loss: 0.4848 - val_accuracy: 0.8493\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.4514 - accuracy: 0.8718 - val_loss: 0.4548 - val_accuracy: 0.8539\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.4192 - accuracy: 0.8748 - val_loss: 0.4294 - val_accuracy: 0.8584\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.3918 - accuracy: 0.8796 - val_loss: 0.4082 - val_accuracy: 0.8676\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.3686 - accuracy: 0.8845 - val_loss: 0.3906 - val_accuracy: 0.8676\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.3491 - accuracy: 0.8836 - val_loss: 0.3762 - val_accuracy: 0.8630\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.3331 - accuracy: 0.8845 - val_loss: 0.3645 - val_accuracy: 0.8630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.3196 - accuracy: 0.8855 - val_loss: 0.3551 - val_accuracy: 0.8584\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.3083 - accuracy: 0.8875 - val_loss: 0.3473 - val_accuracy: 0.8584\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.2988 - accuracy: 0.8865 - val_loss: 0.3408 - val_accuracy: 0.8447\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2906 - accuracy: 0.8875 - val_loss: 0.3356 - val_accuracy: 0.8447\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2836 - accuracy: 0.8865 - val_loss: 0.3311 - val_accuracy: 0.8493\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2775 - accuracy: 0.8865 - val_loss: 0.3272 - val_accuracy: 0.8493\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2722 - accuracy: 0.8904 - val_loss: 0.3239 - val_accuracy: 0.8493\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2675 - accuracy: 0.8924 - val_loss: 0.3210 - val_accuracy: 0.8493\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.2633 - accuracy: 0.8914 - val_loss: 0.3184 - val_accuracy: 0.8539\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2597 - accuracy: 0.8953 - val_loss: 0.3163 - val_accuracy: 0.8539\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2564 - accuracy: 0.8963 - val_loss: 0.3142 - val_accuracy: 0.8539\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2534 - accuracy: 0.8982 - val_loss: 0.3122 - val_accuracy: 0.8493\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2505 - accuracy: 0.8973 - val_loss: 0.3105 - val_accuracy: 0.8493\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2481 - accuracy: 0.8992 - val_loss: 0.3089 - val_accuracy: 0.8539\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2458 - accuracy: 0.8982 - val_loss: 0.3074 - val_accuracy: 0.8630\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2437 - accuracy: 0.9002 - val_loss: 0.3060 - val_accuracy: 0.8630\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2418 - accuracy: 0.9002 - val_loss: 0.3046 - val_accuracy: 0.8630\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2401 - accuracy: 0.9012 - val_loss: 0.3034 - val_accuracy: 0.8630\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2384 - accuracy: 0.9012 - val_loss: 0.3023 - val_accuracy: 0.8630\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2370 - accuracy: 0.9041 - val_loss: 0.3011 - val_accuracy: 0.8630\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2357 - accuracy: 0.9041 - val_loss: 0.3002 - val_accuracy: 0.8630\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2344 - accuracy: 0.9041 - val_loss: 0.2991 - val_accuracy: 0.8676\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2332 - accuracy: 0.9051 - val_loss: 0.2979 - val_accuracy: 0.8721\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2320 - accuracy: 0.9070 - val_loss: 0.2969 - val_accuracy: 0.8721\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2310 - accuracy: 0.9080 - val_loss: 0.2961 - val_accuracy: 0.8721\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 169us/step - loss: 0.2299 - accuracy: 0.9100 - val_loss: 0.2952 - val_accuracy: 0.8721\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 179us/step - loss: 0.2290 - accuracy: 0.9100 - val_loss: 0.2944 - val_accuracy: 0.8721\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2280 - accuracy: 0.9090 - val_loss: 0.2935 - val_accuracy: 0.8721\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2273 - accuracy: 0.9090 - val_loss: 0.2927 - val_accuracy: 0.8721\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2264 - accuracy: 0.9090 - val_loss: 0.2921 - val_accuracy: 0.8721\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 176us/step - loss: 0.2256 - accuracy: 0.9070 - val_loss: 0.2912 - val_accuracy: 0.8721\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 173us/step - loss: 0.2248 - accuracy: 0.9090 - val_loss: 0.2907 - val_accuracy: 0.8767\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2242 - accuracy: 0.9061 - val_loss: 0.2897 - val_accuracy: 0.8767\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2235 - accuracy: 0.9061 - val_loss: 0.2890 - val_accuracy: 0.8767\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2228 - accuracy: 0.9070 - val_loss: 0.2884 - val_accuracy: 0.8767\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2221 - accuracy: 0.9070 - val_loss: 0.2878 - val_accuracy: 0.8767\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 176us/step - loss: 0.2215 - accuracy: 0.9080 - val_loss: 0.2871 - val_accuracy: 0.8767\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 173us/step - loss: 0.2209 - accuracy: 0.9100 - val_loss: 0.2866 - val_accuracy: 0.8767\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.2203 - accuracy: 0.9100 - val_loss: 0.2861 - val_accuracy: 0.8767\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2197 - accuracy: 0.9080 - val_loss: 0.2854 - val_accuracy: 0.8767\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2192 - accuracy: 0.9090 - val_loss: 0.2848 - val_accuracy: 0.8767\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2187 - accuracy: 0.9090 - val_loss: 0.2843 - val_accuracy: 0.8767\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.2182 - accuracy: 0.9100 - val_loss: 0.2838 - val_accuracy: 0.8767\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.2177 - accuracy: 0.9080 - val_loss: 0.2830 - val_accuracy: 0.8767\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2171 - accuracy: 0.9090 - val_loss: 0.2824 - val_accuracy: 0.8767\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2166 - accuracy: 0.9100 - val_loss: 0.2820 - val_accuracy: 0.8767\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2160 - accuracy: 0.9110 - val_loss: 0.2816 - val_accuracy: 0.8721\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2157 - accuracy: 0.9100 - val_loss: 0.2810 - val_accuracy: 0.8767\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2152 - accuracy: 0.9119 - val_loss: 0.2807 - val_accuracy: 0.8767\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2147 - accuracy: 0.9110 - val_loss: 0.2802 - val_accuracy: 0.8767\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2142 - accuracy: 0.9100 - val_loss: 0.2795 - val_accuracy: 0.8813\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2139 - accuracy: 0.9110 - val_loss: 0.2790 - val_accuracy: 0.8813\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2133 - accuracy: 0.9110 - val_loss: 0.2785 - val_accuracy: 0.8813\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2130 - accuracy: 0.9110 - val_loss: 0.2780 - val_accuracy: 0.8813\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2125 - accuracy: 0.9110 - val_loss: 0.2777 - val_accuracy: 0.8813\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2123 - accuracy: 0.9110 - val_loss: 0.2772 - val_accuracy: 0.8813\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2116 - accuracy: 0.9110 - val_loss: 0.2768 - val_accuracy: 0.8813\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.2112 - accuracy: 0.9119 - val_loss: 0.2764 - val_accuracy: 0.8813\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2108 - accuracy: 0.9119 - val_loss: 0.2760 - val_accuracy: 0.8813\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2104 - accuracy: 0.9110 - val_loss: 0.2754 - val_accuracy: 0.8813\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2100 - accuracy: 0.9119 - val_loss: 0.2749 - val_accuracy: 0.8813\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2095 - accuracy: 0.9119 - val_loss: 0.2746 - val_accuracy: 0.8813\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2092 - accuracy: 0.9100 - val_loss: 0.2743 - val_accuracy: 0.8813\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2088 - accuracy: 0.9110 - val_loss: 0.2738 - val_accuracy: 0.8813\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2085 - accuracy: 0.9100 - val_loss: 0.2735 - val_accuracy: 0.8813\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2080 - accuracy: 0.9119 - val_loss: 0.2731 - val_accuracy: 0.8813\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 166us/step - loss: 0.2077 - accuracy: 0.9110 - val_loss: 0.2728 - val_accuracy: 0.8813\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2072 - accuracy: 0.9110 - val_loss: 0.2723 - val_accuracy: 0.8813\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 209us/step - loss: 0.2069 - accuracy: 0.9119 - val_loss: 0.2720 - val_accuracy: 0.8813\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 166us/step - loss: 0.2066 - accuracy: 0.9100 - val_loss: 0.2717 - val_accuracy: 0.8813\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.2062 - accuracy: 0.9110 - val_loss: 0.2713 - val_accuracy: 0.8813\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2058 - accuracy: 0.9100 - val_loss: 0.2711 - val_accuracy: 0.8813\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2055 - accuracy: 0.9100 - val_loss: 0.2707 - val_accuracy: 0.8813\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2050 - accuracy: 0.9100 - val_loss: 0.2703 - val_accuracy: 0.8813\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2047 - accuracy: 0.9110 - val_loss: 0.2700 - val_accuracy: 0.8813\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2044 - accuracy: 0.9119 - val_loss: 0.2697 - val_accuracy: 0.8813\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2041 - accuracy: 0.9119 - val_loss: 0.2695 - val_accuracy: 0.8813\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2036 - accuracy: 0.9100 - val_loss: 0.2693 - val_accuracy: 0.8813\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2033 - accuracy: 0.9119 - val_loss: 0.2690 - val_accuracy: 0.8767\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.2030 - accuracy: 0.9119 - val_loss: 0.2687 - val_accuracy: 0.8767\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2028 - accuracy: 0.9119 - val_loss: 0.2685 - val_accuracy: 0.8813\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2024 - accuracy: 0.9119 - val_loss: 0.2682 - val_accuracy: 0.8767\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2018 - accuracy: 0.9129 - val_loss: 0.2679 - val_accuracy: 0.8813\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2017 - accuracy: 0.9129 - val_loss: 0.2676 - val_accuracy: 0.8813\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2014 - accuracy: 0.9129 - val_loss: 0.2672 - val_accuracy: 0.8813\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2009 - accuracy: 0.9119 - val_loss: 0.2670 - val_accuracy: 0.8813\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2007 - accuracy: 0.9110 - val_loss: 0.2668 - val_accuracy: 0.8813\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2004 - accuracy: 0.9129 - val_loss: 0.2664 - val_accuracy: 0.8813\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2001 - accuracy: 0.9129 - val_loss: 0.2664 - val_accuracy: 0.8813\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.1997 - accuracy: 0.9139 - val_loss: 0.2663 - val_accuracy: 0.8813\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.1995 - accuracy: 0.9110 - val_loss: 0.2661 - val_accuracy: 0.8813\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 793us/step - loss: 0.5878 - accuracy: 0.7554 - val_loss: 0.5467 - val_accuracy: 0.8128\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.5075 - accuracy: 0.8562 - val_loss: 0.4912 - val_accuracy: 0.8447\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.4540 - accuracy: 0.8650 - val_loss: 0.4509 - val_accuracy: 0.8676\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.4146 - accuracy: 0.8748 - val_loss: 0.4213 - val_accuracy: 0.8676\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.3846 - accuracy: 0.8806 - val_loss: 0.3992 - val_accuracy: 0.8676\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.3615 - accuracy: 0.8787 - val_loss: 0.3827 - val_accuracy: 0.8630\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 164us/step - loss: 0.3434 - accuracy: 0.8836 - val_loss: 0.3696 - val_accuracy: 0.8630\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.3290 - accuracy: 0.8875 - val_loss: 0.3593 - val_accuracy: 0.8630\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.3172 - accuracy: 0.8845 - val_loss: 0.3508 - val_accuracy: 0.8630\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.3076 - accuracy: 0.8885 - val_loss: 0.3440 - val_accuracy: 0.8630\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2993 - accuracy: 0.8885 - val_loss: 0.3379 - val_accuracy: 0.8584\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2922 - accuracy: 0.8914 - val_loss: 0.3330 - val_accuracy: 0.8584\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2863 - accuracy: 0.8924 - val_loss: 0.3286 - val_accuracy: 0.8630\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2810 - accuracy: 0.8963 - val_loss: 0.3247 - val_accuracy: 0.8630\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2764 - accuracy: 0.8914 - val_loss: 0.3217 - val_accuracy: 0.8630\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 176us/step - loss: 0.2724 - accuracy: 0.8943 - val_loss: 0.3187 - val_accuracy: 0.8630\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2687 - accuracy: 0.8982 - val_loss: 0.3162 - val_accuracy: 0.8630\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2655 - accuracy: 0.8963 - val_loss: 0.3140 - val_accuracy: 0.8630\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2626 - accuracy: 0.9002 - val_loss: 0.3118 - val_accuracy: 0.8630\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2599 - accuracy: 0.9002 - val_loss: 0.3099 - val_accuracy: 0.8630\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2575 - accuracy: 0.9002 - val_loss: 0.3083 - val_accuracy: 0.8676\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.2553 - accuracy: 0.9012 - val_loss: 0.3067 - val_accuracy: 0.8676\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2535 - accuracy: 0.9012 - val_loss: 0.3053 - val_accuracy: 0.8676\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2516 - accuracy: 0.9031 - val_loss: 0.3039 - val_accuracy: 0.8676\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2499 - accuracy: 0.9031 - val_loss: 0.3024 - val_accuracy: 0.8676\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2483 - accuracy: 0.9031 - val_loss: 0.3012 - val_accuracy: 0.8721\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2470 - accuracy: 0.9041 - val_loss: 0.3002 - val_accuracy: 0.8721\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2457 - accuracy: 0.9061 - val_loss: 0.2993 - val_accuracy: 0.8721\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2443 - accuracy: 0.9051 - val_loss: 0.2982 - val_accuracy: 0.8721\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2432 - accuracy: 0.9061 - val_loss: 0.2971 - val_accuracy: 0.8721\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.2422 - accuracy: 0.9031 - val_loss: 0.2964 - val_accuracy: 0.8721\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 166us/step - loss: 0.2412 - accuracy: 0.9051 - val_loss: 0.2955 - val_accuracy: 0.8721\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2403 - accuracy: 0.9041 - val_loss: 0.2948 - val_accuracy: 0.8721\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.2395 - accuracy: 0.9070 - val_loss: 0.2940 - val_accuracy: 0.8721\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 192us/step - loss: 0.2386 - accuracy: 0.9051 - val_loss: 0.2933 - val_accuracy: 0.8721\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 190us/step - loss: 0.2378 - accuracy: 0.9061 - val_loss: 0.2927 - val_accuracy: 0.8721\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2369 - accuracy: 0.9061 - val_loss: 0.2924 - val_accuracy: 0.8721\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 184us/step - loss: 0.2364 - accuracy: 0.9041 - val_loss: 0.2919 - val_accuracy: 0.8721\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.2357 - accuracy: 0.9070 - val_loss: 0.2913 - val_accuracy: 0.8630\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 173us/step - loss: 0.2350 - accuracy: 0.9070 - val_loss: 0.2908 - val_accuracy: 0.8630\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2343 - accuracy: 0.9070 - val_loss: 0.2904 - val_accuracy: 0.8630\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2336 - accuracy: 0.9061 - val_loss: 0.2898 - val_accuracy: 0.8630\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2331 - accuracy: 0.9061 - val_loss: 0.2893 - val_accuracy: 0.8630\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 178us/step - loss: 0.2326 - accuracy: 0.9070 - val_loss: 0.2890 - val_accuracy: 0.8630\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.2320 - accuracy: 0.9061 - val_loss: 0.2883 - val_accuracy: 0.8630\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 197us/step - loss: 0.2315 - accuracy: 0.9080 - val_loss: 0.2879 - val_accuracy: 0.8630\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2308 - accuracy: 0.9080 - val_loss: 0.2875 - val_accuracy: 0.8676\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 164us/step - loss: 0.2303 - accuracy: 0.9061 - val_loss: 0.2871 - val_accuracy: 0.8676\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 197us/step - loss: 0.2299 - accuracy: 0.9070 - val_loss: 0.2868 - val_accuracy: 0.8676\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.2292 - accuracy: 0.9070 - val_loss: 0.2863 - val_accuracy: 0.8676\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 177us/step - loss: 0.2288 - accuracy: 0.9080 - val_loss: 0.2858 - val_accuracy: 0.8676\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2282 - accuracy: 0.9070 - val_loss: 0.2856 - val_accuracy: 0.8676\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2278 - accuracy: 0.9080 - val_loss: 0.2852 - val_accuracy: 0.8721\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2273 - accuracy: 0.9080 - val_loss: 0.2849 - val_accuracy: 0.8721\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2267 - accuracy: 0.9080 - val_loss: 0.2846 - val_accuracy: 0.8721\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2262 - accuracy: 0.9080 - val_loss: 0.2842 - val_accuracy: 0.8721\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2258 - accuracy: 0.9080 - val_loss: 0.2839 - val_accuracy: 0.8721\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2255 - accuracy: 0.9080 - val_loss: 0.2835 - val_accuracy: 0.8767\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 168us/step - loss: 0.2249 - accuracy: 0.9080 - val_loss: 0.2833 - val_accuracy: 0.8767\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2244 - accuracy: 0.9070 - val_loss: 0.2832 - val_accuracy: 0.8767\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 176us/step - loss: 0.2240 - accuracy: 0.9070 - val_loss: 0.2830 - val_accuracy: 0.8767\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 184us/step - loss: 0.2237 - accuracy: 0.9080 - val_loss: 0.2828 - val_accuracy: 0.8721\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 166us/step - loss: 0.2232 - accuracy: 0.9080 - val_loss: 0.2825 - val_accuracy: 0.8721\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.2228 - accuracy: 0.9080 - val_loss: 0.2822 - val_accuracy: 0.8721\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 193us/step - loss: 0.2225 - accuracy: 0.9090 - val_loss: 0.2818 - val_accuracy: 0.8721\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.2221 - accuracy: 0.9090 - val_loss: 0.2817 - val_accuracy: 0.8721\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 185us/step - loss: 0.2216 - accuracy: 0.9070 - val_loss: 0.2815 - val_accuracy: 0.8721\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 215us/step - loss: 0.2213 - accuracy: 0.9090 - val_loss: 0.2812 - val_accuracy: 0.8721\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 183us/step - loss: 0.2210 - accuracy: 0.9100 - val_loss: 0.2808 - val_accuracy: 0.8721\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 1s 598us/step - loss: 0.2206 - accuracy: 0.9110 - val_loss: 0.2806 - val_accuracy: 0.8721\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 1s 619us/step - loss: 0.2202 - accuracy: 0.9090 - val_loss: 0.2804 - val_accuracy: 0.8767\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 1s 561us/step - loss: 0.2199 - accuracy: 0.9090 - val_loss: 0.2802 - val_accuracy: 0.8767\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 206us/step - loss: 0.2195 - accuracy: 0.9090 - val_loss: 0.2801 - val_accuracy: 0.8767\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2191 - accuracy: 0.9100 - val_loss: 0.2797 - val_accuracy: 0.8767\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2189 - accuracy: 0.9110 - val_loss: 0.2796 - val_accuracy: 0.8767\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2184 - accuracy: 0.9100 - val_loss: 0.2794 - val_accuracy: 0.8767\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2183 - accuracy: 0.9090 - val_loss: 0.2794 - val_accuracy: 0.8767\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2179 - accuracy: 0.9090 - val_loss: 0.2793 - val_accuracy: 0.8767\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2176 - accuracy: 0.9100 - val_loss: 0.2793 - val_accuracy: 0.8721\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2172 - accuracy: 0.9080 - val_loss: 0.2790 - val_accuracy: 0.8721\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2168 - accuracy: 0.9080 - val_loss: 0.2787 - val_accuracy: 0.8767\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2165 - accuracy: 0.9080 - val_loss: 0.2786 - val_accuracy: 0.8721\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2162 - accuracy: 0.9080 - val_loss: 0.2783 - val_accuracy: 0.8813\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2159 - accuracy: 0.9080 - val_loss: 0.2781 - val_accuracy: 0.8813\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2156 - accuracy: 0.9100 - val_loss: 0.2780 - val_accuracy: 0.8767\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2152 - accuracy: 0.9090 - val_loss: 0.2782 - val_accuracy: 0.8767\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2150 - accuracy: 0.9080 - val_loss: 0.2780 - val_accuracy: 0.8767\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2145 - accuracy: 0.9080 - val_loss: 0.2777 - val_accuracy: 0.8767\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2143 - accuracy: 0.9090 - val_loss: 0.2776 - val_accuracy: 0.8767\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2140 - accuracy: 0.9100 - val_loss: 0.2777 - val_accuracy: 0.8767\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2137 - accuracy: 0.9080 - val_loss: 0.2775 - val_accuracy: 0.8767\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2133 - accuracy: 0.9100 - val_loss: 0.2773 - val_accuracy: 0.8767\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2130 - accuracy: 0.9090 - val_loss: 0.2773 - val_accuracy: 0.8767\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2126 - accuracy: 0.9080 - val_loss: 0.2771 - val_accuracy: 0.8767\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.2122 - accuracy: 0.9100 - val_loss: 0.2768 - val_accuracy: 0.8767\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2119 - accuracy: 0.9090 - val_loss: 0.2769 - val_accuracy: 0.8767\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2116 - accuracy: 0.9100 - val_loss: 0.2770 - val_accuracy: 0.8767\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2112 - accuracy: 0.9090 - val_loss: 0.2770 - val_accuracy: 0.8767\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2110 - accuracy: 0.9100 - val_loss: 0.2768 - val_accuracy: 0.8767\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2108 - accuracy: 0.9100 - val_loss: 0.2766 - val_accuracy: 0.8767\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 879us/step - loss: 0.6178 - accuracy: 0.7387 - val_loss: 0.5855 - val_accuracy: 0.8128\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.5542 - accuracy: 0.8415 - val_loss: 0.5342 - val_accuracy: 0.8174\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 181us/step - loss: 0.4996 - accuracy: 0.8630 - val_loss: 0.4898 - val_accuracy: 0.8402\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.4527 - accuracy: 0.8728 - val_loss: 0.4526 - val_accuracy: 0.8447\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.4136 - accuracy: 0.8836 - val_loss: 0.4219 - val_accuracy: 0.8539\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.3817 - accuracy: 0.8894 - val_loss: 0.3971 - val_accuracy: 0.8539\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.3559 - accuracy: 0.8924 - val_loss: 0.3776 - val_accuracy: 0.8584\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.3354 - accuracy: 0.8943 - val_loss: 0.3624 - val_accuracy: 0.8630\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.3188 - accuracy: 0.8953 - val_loss: 0.3504 - val_accuracy: 0.8630\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.3054 - accuracy: 0.8973 - val_loss: 0.3411 - val_accuracy: 0.8630\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2946 - accuracy: 0.8963 - val_loss: 0.3337 - val_accuracy: 0.8630\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2856 - accuracy: 0.8973 - val_loss: 0.3278 - val_accuracy: 0.8584\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2782 - accuracy: 0.8992 - val_loss: 0.3231 - val_accuracy: 0.8584\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 164us/step - loss: 0.2721 - accuracy: 0.9012 - val_loss: 0.3192 - val_accuracy: 0.8584\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2669 - accuracy: 0.9041 - val_loss: 0.3160 - val_accuracy: 0.8584\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2625 - accuracy: 0.9031 - val_loss: 0.3133 - val_accuracy: 0.8584\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.2587 - accuracy: 0.9041 - val_loss: 0.3110 - val_accuracy: 0.8584\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2555 - accuracy: 0.9061 - val_loss: 0.3090 - val_accuracy: 0.8584\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2527 - accuracy: 0.9031 - val_loss: 0.3073 - val_accuracy: 0.8584\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2501 - accuracy: 0.9012 - val_loss: 0.3058 - val_accuracy: 0.8584\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 170us/step - loss: 0.2480 - accuracy: 0.9022 - val_loss: 0.3044 - val_accuracy: 0.8584\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 185us/step - loss: 0.2460 - accuracy: 0.9022 - val_loss: 0.3032 - val_accuracy: 0.8539\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2442 - accuracy: 0.9031 - val_loss: 0.3021 - val_accuracy: 0.8630\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 170us/step - loss: 0.2424 - accuracy: 0.9041 - val_loss: 0.3009 - val_accuracy: 0.8630\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.2410 - accuracy: 0.9041 - val_loss: 0.2999 - val_accuracy: 0.8630\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 178us/step - loss: 0.2396 - accuracy: 0.9041 - val_loss: 0.2989 - val_accuracy: 0.8630\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.2382 - accuracy: 0.9070 - val_loss: 0.2980 - val_accuracy: 0.8630\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.2370 - accuracy: 0.9051 - val_loss: 0.2971 - val_accuracy: 0.8630\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 164us/step - loss: 0.2359 - accuracy: 0.9080 - val_loss: 0.2962 - val_accuracy: 0.8630\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 164us/step - loss: 0.2348 - accuracy: 0.9080 - val_loss: 0.2954 - val_accuracy: 0.8630\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2338 - accuracy: 0.9070 - val_loss: 0.2946 - val_accuracy: 0.8630\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2328 - accuracy: 0.9080 - val_loss: 0.2938 - val_accuracy: 0.8630\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2319 - accuracy: 0.9070 - val_loss: 0.2931 - val_accuracy: 0.8630\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2311 - accuracy: 0.9080 - val_loss: 0.2924 - val_accuracy: 0.8630\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2303 - accuracy: 0.9080 - val_loss: 0.2917 - val_accuracy: 0.8630\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2296 - accuracy: 0.9100 - val_loss: 0.2909 - val_accuracy: 0.8630\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2287 - accuracy: 0.9100 - val_loss: 0.2903 - val_accuracy: 0.8630\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2280 - accuracy: 0.9100 - val_loss: 0.2897 - val_accuracy: 0.8630\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.2274 - accuracy: 0.9100 - val_loss: 0.2891 - val_accuracy: 0.8630\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2268 - accuracy: 0.9139 - val_loss: 0.2884 - val_accuracy: 0.8630\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2261 - accuracy: 0.9129 - val_loss: 0.2878 - val_accuracy: 0.8630\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2254 - accuracy: 0.9139 - val_loss: 0.2872 - val_accuracy: 0.8630\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2248 - accuracy: 0.9129 - val_loss: 0.2867 - val_accuracy: 0.8630\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2242 - accuracy: 0.9149 - val_loss: 0.2861 - val_accuracy: 0.8630\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2238 - accuracy: 0.9139 - val_loss: 0.2856 - val_accuracy: 0.8630\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.2231 - accuracy: 0.9149 - val_loss: 0.2852 - val_accuracy: 0.8630\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2227 - accuracy: 0.9139 - val_loss: 0.2847 - val_accuracy: 0.8630\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 179us/step - loss: 0.2221 - accuracy: 0.9139 - val_loss: 0.2842 - val_accuracy: 0.8676\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.2215 - accuracy: 0.9139 - val_loss: 0.2838 - val_accuracy: 0.8676\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.2211 - accuracy: 0.9119 - val_loss: 0.2833 - val_accuracy: 0.8676\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 166us/step - loss: 0.2205 - accuracy: 0.9129 - val_loss: 0.2828 - val_accuracy: 0.8721\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 189us/step - loss: 0.2201 - accuracy: 0.9119 - val_loss: 0.2824 - val_accuracy: 0.8721\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2197 - accuracy: 0.9119 - val_loss: 0.2820 - val_accuracy: 0.8721\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2191 - accuracy: 0.9129 - val_loss: 0.2815 - val_accuracy: 0.8721\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2187 - accuracy: 0.9129 - val_loss: 0.2811 - val_accuracy: 0.8721\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2182 - accuracy: 0.9129 - val_loss: 0.2807 - val_accuracy: 0.8767\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2178 - accuracy: 0.9129 - val_loss: 0.2803 - val_accuracy: 0.8767\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2173 - accuracy: 0.9129 - val_loss: 0.2800 - val_accuracy: 0.8767\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2170 - accuracy: 0.9139 - val_loss: 0.2795 - val_accuracy: 0.8767\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2165 - accuracy: 0.9129 - val_loss: 0.2792 - val_accuracy: 0.8767\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2162 - accuracy: 0.9129 - val_loss: 0.2789 - val_accuracy: 0.8767\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2159 - accuracy: 0.9129 - val_loss: 0.2786 - val_accuracy: 0.8767\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2154 - accuracy: 0.9129 - val_loss: 0.2784 - val_accuracy: 0.8767\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2150 - accuracy: 0.9129 - val_loss: 0.2780 - val_accuracy: 0.8767\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2146 - accuracy: 0.9129 - val_loss: 0.2777 - val_accuracy: 0.8767\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2143 - accuracy: 0.9129 - val_loss: 0.2774 - val_accuracy: 0.8767\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2139 - accuracy: 0.9129 - val_loss: 0.2770 - val_accuracy: 0.8767\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2136 - accuracy: 0.9129 - val_loss: 0.2768 - val_accuracy: 0.8767\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2131 - accuracy: 0.9129 - val_loss: 0.2764 - val_accuracy: 0.8813\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2127 - accuracy: 0.9139 - val_loss: 0.2762 - val_accuracy: 0.8813\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2125 - accuracy: 0.9159 - val_loss: 0.2759 - val_accuracy: 0.8858\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.2122 - accuracy: 0.9149 - val_loss: 0.2756 - val_accuracy: 0.8858\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 164us/step - loss: 0.2118 - accuracy: 0.9149 - val_loss: 0.2754 - val_accuracy: 0.8858\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2115 - accuracy: 0.9139 - val_loss: 0.2751 - val_accuracy: 0.8858\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2112 - accuracy: 0.9159 - val_loss: 0.2748 - val_accuracy: 0.8858\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2108 - accuracy: 0.9159 - val_loss: 0.2746 - val_accuracy: 0.8858\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2104 - accuracy: 0.9149 - val_loss: 0.2746 - val_accuracy: 0.8858\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2101 - accuracy: 0.9139 - val_loss: 0.2743 - val_accuracy: 0.8858\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2098 - accuracy: 0.9139 - val_loss: 0.2739 - val_accuracy: 0.8858\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2096 - accuracy: 0.9168 - val_loss: 0.2738 - val_accuracy: 0.8858\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.2093 - accuracy: 0.9159 - val_loss: 0.2735 - val_accuracy: 0.8858\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2090 - accuracy: 0.9168 - val_loss: 0.2733 - val_accuracy: 0.8858\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 249us/step - loss: 0.2086 - accuracy: 0.9149 - val_loss: 0.2732 - val_accuracy: 0.8858\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2082 - accuracy: 0.9159 - val_loss: 0.2729 - val_accuracy: 0.8858\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2079 - accuracy: 0.9149 - val_loss: 0.2726 - val_accuracy: 0.8858\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2076 - accuracy: 0.9159 - val_loss: 0.2724 - val_accuracy: 0.8858\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2073 - accuracy: 0.9168 - val_loss: 0.2722 - val_accuracy: 0.8858\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2071 - accuracy: 0.9178 - val_loss: 0.2719 - val_accuracy: 0.8858\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2068 - accuracy: 0.9168 - val_loss: 0.2718 - val_accuracy: 0.8858\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2065 - accuracy: 0.9168 - val_loss: 0.2716 - val_accuracy: 0.8858\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2062 - accuracy: 0.9188 - val_loss: 0.2715 - val_accuracy: 0.8858\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2059 - accuracy: 0.9178 - val_loss: 0.2713 - val_accuracy: 0.8858\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2057 - accuracy: 0.9178 - val_loss: 0.2711 - val_accuracy: 0.8858\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.2053 - accuracy: 0.9178 - val_loss: 0.2707 - val_accuracy: 0.8858\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2051 - accuracy: 0.9207 - val_loss: 0.2703 - val_accuracy: 0.8858\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.2049 - accuracy: 0.9188 - val_loss: 0.2702 - val_accuracy: 0.8858\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2046 - accuracy: 0.9198 - val_loss: 0.2701 - val_accuracy: 0.8858\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.2043 - accuracy: 0.9178 - val_loss: 0.2701 - val_accuracy: 0.8858\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2041 - accuracy: 0.9198 - val_loss: 0.2700 - val_accuracy: 0.8858\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2038 - accuracy: 0.9198 - val_loss: 0.2696 - val_accuracy: 0.8858\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 833us/step - loss: 0.7144 - accuracy: 0.4188 - val_loss: 0.7003 - val_accuracy: 0.4475\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 181us/step - loss: 0.7035 - accuracy: 0.4384 - val_loss: 0.6934 - val_accuracy: 0.4658\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 207us/step - loss: 0.6965 - accuracy: 0.4609 - val_loss: 0.6885 - val_accuracy: 0.4932\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 207us/step - loss: 0.6912 - accuracy: 0.5049 - val_loss: 0.6842 - val_accuracy: 0.5342\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.6866 - accuracy: 0.5470 - val_loss: 0.6801 - val_accuracy: 0.5753\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 190us/step - loss: 0.6821 - accuracy: 0.5920 - val_loss: 0.6755 - val_accuracy: 0.6256\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.6770 - accuracy: 0.6321 - val_loss: 0.6702 - val_accuracy: 0.6621\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.6709 - accuracy: 0.6732 - val_loss: 0.6636 - val_accuracy: 0.7123\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.6635 - accuracy: 0.6977 - val_loss: 0.6557 - val_accuracy: 0.7443\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.6546 - accuracy: 0.7182 - val_loss: 0.6462 - val_accuracy: 0.7671\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.6436 - accuracy: 0.7466 - val_loss: 0.6347 - val_accuracy: 0.7717\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.6305 - accuracy: 0.7632 - val_loss: 0.6216 - val_accuracy: 0.7900\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.6152 - accuracy: 0.7828 - val_loss: 0.6065 - val_accuracy: 0.7991\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 167us/step - loss: 0.5977 - accuracy: 0.7965 - val_loss: 0.5898 - val_accuracy: 0.7991\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.5786 - accuracy: 0.8112 - val_loss: 0.5721 - val_accuracy: 0.8037\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.5584 - accuracy: 0.8249 - val_loss: 0.5538 - val_accuracy: 0.8265\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.5379 - accuracy: 0.8405 - val_loss: 0.5355 - val_accuracy: 0.8265\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.5178 - accuracy: 0.8464 - val_loss: 0.5180 - val_accuracy: 0.8356\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.4989 - accuracy: 0.8581 - val_loss: 0.5015 - val_accuracy: 0.8402\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.4812 - accuracy: 0.8689 - val_loss: 0.4863 - val_accuracy: 0.8493\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.4649 - accuracy: 0.8767 - val_loss: 0.4722 - val_accuracy: 0.8539\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.4499 - accuracy: 0.8836 - val_loss: 0.4594 - val_accuracy: 0.8584\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.4364 - accuracy: 0.8855 - val_loss: 0.4478 - val_accuracy: 0.8630\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.4241 - accuracy: 0.8885 - val_loss: 0.4372 - val_accuracy: 0.8630\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.4128 - accuracy: 0.8924 - val_loss: 0.4274 - val_accuracy: 0.8584\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.4023 - accuracy: 0.8914 - val_loss: 0.4184 - val_accuracy: 0.8584\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.3928 - accuracy: 0.8953 - val_loss: 0.4101 - val_accuracy: 0.8584\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.3840 - accuracy: 0.8943 - val_loss: 0.4026 - val_accuracy: 0.8584\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 176us/step - loss: 0.3758 - accuracy: 0.8933 - val_loss: 0.3956 - val_accuracy: 0.8630\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 174us/step - loss: 0.3682 - accuracy: 0.8943 - val_loss: 0.3892 - val_accuracy: 0.8630\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.3612 - accuracy: 0.8953 - val_loss: 0.3832 - val_accuracy: 0.8630\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.3546 - accuracy: 0.9002 - val_loss: 0.3778 - val_accuracy: 0.8630\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.3485 - accuracy: 0.9002 - val_loss: 0.3727 - val_accuracy: 0.8630\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.3428 - accuracy: 0.8982 - val_loss: 0.3680 - val_accuracy: 0.8539\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.3374 - accuracy: 0.9012 - val_loss: 0.3636 - val_accuracy: 0.8539\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.3324 - accuracy: 0.9002 - val_loss: 0.3594 - val_accuracy: 0.8584\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 101us/step - loss: 0.3277 - accuracy: 0.9012 - val_loss: 0.3555 - val_accuracy: 0.8584\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.3232 - accuracy: 0.9022 - val_loss: 0.3518 - val_accuracy: 0.8584\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.3190 - accuracy: 0.9012 - val_loss: 0.3484 - val_accuracy: 0.8584\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.3150 - accuracy: 0.9031 - val_loss: 0.3452 - val_accuracy: 0.8539\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.3113 - accuracy: 0.9041 - val_loss: 0.3421 - val_accuracy: 0.8539\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.3078 - accuracy: 0.9041 - val_loss: 0.3393 - val_accuracy: 0.8539\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.3045 - accuracy: 0.9041 - val_loss: 0.3368 - val_accuracy: 0.8539\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.3013 - accuracy: 0.9080 - val_loss: 0.3343 - val_accuracy: 0.8539\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2983 - accuracy: 0.9070 - val_loss: 0.3319 - val_accuracy: 0.8539\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2954 - accuracy: 0.9080 - val_loss: 0.3295 - val_accuracy: 0.8584\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2927 - accuracy: 0.9070 - val_loss: 0.3274 - val_accuracy: 0.8584\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2900 - accuracy: 0.9080 - val_loss: 0.3252 - val_accuracy: 0.8584\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2876 - accuracy: 0.9080 - val_loss: 0.3233 - val_accuracy: 0.8584\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2852 - accuracy: 0.9070 - val_loss: 0.3214 - val_accuracy: 0.8584\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2830 - accuracy: 0.9080 - val_loss: 0.3197 - val_accuracy: 0.8584\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2809 - accuracy: 0.9100 - val_loss: 0.3180 - val_accuracy: 0.8630\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2788 - accuracy: 0.9100 - val_loss: 0.3164 - val_accuracy: 0.8630\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2769 - accuracy: 0.9100 - val_loss: 0.3148 - val_accuracy: 0.8630\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2749 - accuracy: 0.9100 - val_loss: 0.3134 - val_accuracy: 0.8630\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.2732 - accuracy: 0.9100 - val_loss: 0.3118 - val_accuracy: 0.8630\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.2714 - accuracy: 0.9110 - val_loss: 0.3104 - val_accuracy: 0.8630\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2697 - accuracy: 0.9110 - val_loss: 0.3090 - val_accuracy: 0.8676\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2681 - accuracy: 0.9119 - val_loss: 0.3079 - val_accuracy: 0.8676\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2665 - accuracy: 0.9119 - val_loss: 0.3064 - val_accuracy: 0.8676\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2651 - accuracy: 0.9119 - val_loss: 0.3054 - val_accuracy: 0.8676\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2635 - accuracy: 0.9149 - val_loss: 0.3041 - val_accuracy: 0.8676\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2621 - accuracy: 0.9129 - val_loss: 0.3028 - val_accuracy: 0.8676\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2608 - accuracy: 0.9139 - val_loss: 0.3017 - val_accuracy: 0.8676\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2594 - accuracy: 0.9139 - val_loss: 0.3006 - val_accuracy: 0.8676\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2582 - accuracy: 0.9139 - val_loss: 0.2996 - val_accuracy: 0.8676\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2569 - accuracy: 0.9139 - val_loss: 0.2987 - val_accuracy: 0.8676\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2556 - accuracy: 0.9149 - val_loss: 0.2977 - val_accuracy: 0.8676\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2545 - accuracy: 0.9139 - val_loss: 0.2969 - val_accuracy: 0.8676\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2533 - accuracy: 0.9149 - val_loss: 0.2959 - val_accuracy: 0.8676\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2523 - accuracy: 0.9139 - val_loss: 0.2950 - val_accuracy: 0.8676\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2513 - accuracy: 0.9149 - val_loss: 0.2941 - val_accuracy: 0.8676\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2502 - accuracy: 0.9139 - val_loss: 0.2932 - val_accuracy: 0.8676\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2493 - accuracy: 0.9139 - val_loss: 0.2924 - val_accuracy: 0.8676\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.2482 - accuracy: 0.9139 - val_loss: 0.2916 - val_accuracy: 0.8676\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.2473 - accuracy: 0.9139 - val_loss: 0.2909 - val_accuracy: 0.8676\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2463 - accuracy: 0.9139 - val_loss: 0.2901 - val_accuracy: 0.8676\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.2455 - accuracy: 0.9139 - val_loss: 0.2893 - val_accuracy: 0.8676\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2445 - accuracy: 0.9149 - val_loss: 0.2885 - val_accuracy: 0.8676\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2436 - accuracy: 0.9139 - val_loss: 0.2875 - val_accuracy: 0.8676\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2429 - accuracy: 0.9139 - val_loss: 0.2868 - val_accuracy: 0.8676\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2421 - accuracy: 0.9119 - val_loss: 0.2863 - val_accuracy: 0.8676\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2412 - accuracy: 0.9139 - val_loss: 0.2858 - val_accuracy: 0.8676\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2404 - accuracy: 0.9159 - val_loss: 0.2851 - val_accuracy: 0.8676\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2397 - accuracy: 0.9139 - val_loss: 0.2844 - val_accuracy: 0.8676\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2389 - accuracy: 0.9149 - val_loss: 0.2836 - val_accuracy: 0.8676\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2381 - accuracy: 0.9149 - val_loss: 0.2829 - val_accuracy: 0.8676\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2374 - accuracy: 0.9168 - val_loss: 0.2823 - val_accuracy: 0.8676\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2367 - accuracy: 0.9149 - val_loss: 0.2818 - val_accuracy: 0.8676\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2361 - accuracy: 0.9149 - val_loss: 0.2811 - val_accuracy: 0.8676\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2353 - accuracy: 0.9159 - val_loss: 0.2808 - val_accuracy: 0.8676\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - ETA: 0s - loss: 0.2352 - accuracy: 0.91 - 0s 155us/step - loss: 0.2348 - accuracy: 0.9159 - val_loss: 0.2802 - val_accuracy: 0.8676\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2340 - accuracy: 0.9139 - val_loss: 0.2798 - val_accuracy: 0.8676\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2334 - accuracy: 0.9159 - val_loss: 0.2792 - val_accuracy: 0.8676\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2328 - accuracy: 0.9159 - val_loss: 0.2786 - val_accuracy: 0.8676\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2321 - accuracy: 0.9139 - val_loss: 0.2781 - val_accuracy: 0.8721\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2315 - accuracy: 0.9149 - val_loss: 0.2777 - val_accuracy: 0.8721\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2311 - accuracy: 0.9149 - val_loss: 0.2773 - val_accuracy: 0.8721\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2303 - accuracy: 0.9149 - val_loss: 0.2768 - val_accuracy: 0.8721\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2298 - accuracy: 0.9149 - val_loss: 0.2764 - val_accuracy: 0.8721\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 788us/step - loss: 0.6480 - accuracy: 0.5636 - val_loss: 0.6366 - val_accuracy: 0.5479\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 172us/step - loss: 0.6070 - accuracy: 0.6272 - val_loss: 0.6067 - val_accuracy: 0.6393\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.5747 - accuracy: 0.7025 - val_loss: 0.5782 - val_accuracy: 0.6941\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 180us/step - loss: 0.5420 - accuracy: 0.7554 - val_loss: 0.5479 - val_accuracy: 0.7717\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.5092 - accuracy: 0.7965 - val_loss: 0.5175 - val_accuracy: 0.7808\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 178us/step - loss: 0.4777 - accuracy: 0.8200 - val_loss: 0.4886 - val_accuracy: 0.8082\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.4495 - accuracy: 0.8268 - val_loss: 0.4639 - val_accuracy: 0.8174\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.4255 - accuracy: 0.8337 - val_loss: 0.4422 - val_accuracy: 0.8311\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.4044 - accuracy: 0.8454 - val_loss: 0.4228 - val_accuracy: 0.8402\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.3854 - accuracy: 0.8503 - val_loss: 0.4053 - val_accuracy: 0.8402\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.3682 - accuracy: 0.8591 - val_loss: 0.3899 - val_accuracy: 0.8356\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.3528 - accuracy: 0.8591 - val_loss: 0.3754 - val_accuracy: 0.8219\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.3388 - accuracy: 0.8669 - val_loss: 0.3628 - val_accuracy: 0.8265\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.3264 - accuracy: 0.8748 - val_loss: 0.3519 - val_accuracy: 0.8402\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.3151 - accuracy: 0.8806 - val_loss: 0.3421 - val_accuracy: 0.8402\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.3048 - accuracy: 0.8875 - val_loss: 0.3337 - val_accuracy: 0.8493\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2957 - accuracy: 0.8894 - val_loss: 0.3266 - val_accuracy: 0.8539\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2877 - accuracy: 0.8933 - val_loss: 0.3203 - val_accuracy: 0.8539\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2809 - accuracy: 0.8982 - val_loss: 0.3149 - val_accuracy: 0.8584\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2749 - accuracy: 0.8973 - val_loss: 0.3102 - val_accuracy: 0.8584\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2697 - accuracy: 0.9002 - val_loss: 0.3062 - val_accuracy: 0.8676\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2650 - accuracy: 0.9012 - val_loss: 0.3027 - val_accuracy: 0.8721\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2609 - accuracy: 0.9041 - val_loss: 0.2998 - val_accuracy: 0.8676\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.2572 - accuracy: 0.9051 - val_loss: 0.2973 - val_accuracy: 0.8721\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2539 - accuracy: 0.9051 - val_loss: 0.2950 - val_accuracy: 0.8767\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2510 - accuracy: 0.9080 - val_loss: 0.2929 - val_accuracy: 0.8767\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2482 - accuracy: 0.9070 - val_loss: 0.2910 - val_accuracy: 0.8813\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2459 - accuracy: 0.9080 - val_loss: 0.2893 - val_accuracy: 0.8813\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2435 - accuracy: 0.9090 - val_loss: 0.2878 - val_accuracy: 0.8813\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2416 - accuracy: 0.9100 - val_loss: 0.2865 - val_accuracy: 0.8813\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2398 - accuracy: 0.9100 - val_loss: 0.2854 - val_accuracy: 0.8813\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 170us/step - loss: 0.2382 - accuracy: 0.9061 - val_loss: 0.2844 - val_accuracy: 0.8813\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2368 - accuracy: 0.9070 - val_loss: 0.2835 - val_accuracy: 0.8858\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2355 - accuracy: 0.9070 - val_loss: 0.2827 - val_accuracy: 0.8813\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 179us/step - loss: 0.2343 - accuracy: 0.9080 - val_loss: 0.2820 - val_accuracy: 0.8813\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2333 - accuracy: 0.9090 - val_loss: 0.2813 - val_accuracy: 0.8813\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2322 - accuracy: 0.9090 - val_loss: 0.2806 - val_accuracy: 0.8858\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 92us/step - loss: 0.2314 - accuracy: 0.9090 - val_loss: 0.2800 - val_accuracy: 0.8904\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2305 - accuracy: 0.9080 - val_loss: 0.2794 - val_accuracy: 0.8858\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2296 - accuracy: 0.9090 - val_loss: 0.2789 - val_accuracy: 0.8858\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2287 - accuracy: 0.9090 - val_loss: 0.2784 - val_accuracy: 0.8858\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2280 - accuracy: 0.9070 - val_loss: 0.2779 - val_accuracy: 0.8858\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2274 - accuracy: 0.9080 - val_loss: 0.2773 - val_accuracy: 0.8858\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2266 - accuracy: 0.9090 - val_loss: 0.2768 - val_accuracy: 0.8858\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2260 - accuracy: 0.9070 - val_loss: 0.2763 - val_accuracy: 0.8767\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.2255 - accuracy: 0.9051 - val_loss: 0.2759 - val_accuracy: 0.8767\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 195us/step - loss: 0.2248 - accuracy: 0.9080 - val_loss: 0.2756 - val_accuracy: 0.8767\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 216us/step - loss: 0.2244 - accuracy: 0.9061 - val_loss: 0.2752 - val_accuracy: 0.8767\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 201us/step - loss: 0.2238 - accuracy: 0.9061 - val_loss: 0.2747 - val_accuracy: 0.8721\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 183us/step - loss: 0.2233 - accuracy: 0.9070 - val_loss: 0.2745 - val_accuracy: 0.8721\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.2228 - accuracy: 0.9061 - val_loss: 0.2742 - val_accuracy: 0.8721\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.2223 - accuracy: 0.9061 - val_loss: 0.2740 - val_accuracy: 0.8721\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2219 - accuracy: 0.9070 - val_loss: 0.2738 - val_accuracy: 0.8767\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2214 - accuracy: 0.9041 - val_loss: 0.2734 - val_accuracy: 0.8767\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2210 - accuracy: 0.9070 - val_loss: 0.2733 - val_accuracy: 0.8767\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2205 - accuracy: 0.9041 - val_loss: 0.2730 - val_accuracy: 0.8767\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2201 - accuracy: 0.9041 - val_loss: 0.2726 - val_accuracy: 0.8767\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2197 - accuracy: 0.9051 - val_loss: 0.2724 - val_accuracy: 0.8767\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.2194 - accuracy: 0.9051 - val_loss: 0.2721 - val_accuracy: 0.8767\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2190 - accuracy: 0.9051 - val_loss: 0.2719 - val_accuracy: 0.8767\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 169us/step - loss: 0.2186 - accuracy: 0.9051 - val_loss: 0.2717 - val_accuracy: 0.8767\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 488us/step - loss: 0.2181 - accuracy: 0.9051 - val_loss: 0.2715 - val_accuracy: 0.8767\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 169us/step - loss: 0.2178 - accuracy: 0.9051 - val_loss: 0.2712 - val_accuracy: 0.8767\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2174 - accuracy: 0.9051 - val_loss: 0.2710 - val_accuracy: 0.8767\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2172 - accuracy: 0.9051 - val_loss: 0.2707 - val_accuracy: 0.8767\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.2166 - accuracy: 0.9051 - val_loss: 0.2705 - val_accuracy: 0.8767\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2164 - accuracy: 0.9051 - val_loss: 0.2703 - val_accuracy: 0.8767\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2160 - accuracy: 0.9051 - val_loss: 0.2699 - val_accuracy: 0.8767\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.2157 - accuracy: 0.9051 - val_loss: 0.2696 - val_accuracy: 0.8767\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2154 - accuracy: 0.9051 - val_loss: 0.2696 - val_accuracy: 0.8767\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2151 - accuracy: 0.9070 - val_loss: 0.2694 - val_accuracy: 0.8767\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.2149 - accuracy: 0.9061 - val_loss: 0.2692 - val_accuracy: 0.8767\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2143 - accuracy: 0.9080 - val_loss: 0.2689 - val_accuracy: 0.8767\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2142 - accuracy: 0.9080 - val_loss: 0.2686 - val_accuracy: 0.8767\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2137 - accuracy: 0.9090 - val_loss: 0.2685 - val_accuracy: 0.8767\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2136 - accuracy: 0.9110 - val_loss: 0.2683 - val_accuracy: 0.8767\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2132 - accuracy: 0.9119 - val_loss: 0.2683 - val_accuracy: 0.8767\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2129 - accuracy: 0.9119 - val_loss: 0.2681 - val_accuracy: 0.8767\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2126 - accuracy: 0.9110 - val_loss: 0.2681 - val_accuracy: 0.8767\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2123 - accuracy: 0.9139 - val_loss: 0.2678 - val_accuracy: 0.8767\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2119 - accuracy: 0.9129 - val_loss: 0.2676 - val_accuracy: 0.8767\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2116 - accuracy: 0.9129 - val_loss: 0.2672 - val_accuracy: 0.8767\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2114 - accuracy: 0.9139 - val_loss: 0.2671 - val_accuracy: 0.8767\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2111 - accuracy: 0.9149 - val_loss: 0.2669 - val_accuracy: 0.8767\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2109 - accuracy: 0.9129 - val_loss: 0.2667 - val_accuracy: 0.8767\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2105 - accuracy: 0.9139 - val_loss: 0.2666 - val_accuracy: 0.8767\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2103 - accuracy: 0.9129 - val_loss: 0.2664 - val_accuracy: 0.8767\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.2101 - accuracy: 0.9129 - val_loss: 0.2662 - val_accuracy: 0.8767\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2097 - accuracy: 0.9139 - val_loss: 0.2660 - val_accuracy: 0.8767\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2094 - accuracy: 0.9149 - val_loss: 0.2660 - val_accuracy: 0.8767\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2092 - accuracy: 0.9149 - val_loss: 0.2658 - val_accuracy: 0.8767\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2089 - accuracy: 0.9139 - val_loss: 0.2655 - val_accuracy: 0.8767\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2086 - accuracy: 0.9139 - val_loss: 0.2654 - val_accuracy: 0.8767\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 186us/step - loss: 0.2084 - accuracy: 0.9119 - val_loss: 0.2653 - val_accuracy: 0.8767\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.2081 - accuracy: 0.9139 - val_loss: 0.2651 - val_accuracy: 0.8767\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2079 - accuracy: 0.9129 - val_loss: 0.2649 - val_accuracy: 0.8767\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2076 - accuracy: 0.9139 - val_loss: 0.2648 - val_accuracy: 0.8767\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2073 - accuracy: 0.9139 - val_loss: 0.2648 - val_accuracy: 0.8767\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2072 - accuracy: 0.9139 - val_loss: 0.2645 - val_accuracy: 0.8767\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2067 - accuracy: 0.9149 - val_loss: 0.2643 - val_accuracy: 0.8767\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 895us/step - loss: 0.7346 - accuracy: 0.4765 - val_loss: 0.6868 - val_accuracy: 0.5662\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.6612 - accuracy: 0.6663 - val_loss: 0.6387 - val_accuracy: 0.7260\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 167us/step - loss: 0.6130 - accuracy: 0.7701 - val_loss: 0.6000 - val_accuracy: 0.8037\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.5720 - accuracy: 0.8278 - val_loss: 0.5629 - val_accuracy: 0.8584\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.5326 - accuracy: 0.8523 - val_loss: 0.5269 - val_accuracy: 0.8493\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.4949 - accuracy: 0.8630 - val_loss: 0.4926 - val_accuracy: 0.8539\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.4596 - accuracy: 0.8728 - val_loss: 0.4611 - val_accuracy: 0.8493\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.4280 - accuracy: 0.8767 - val_loss: 0.4332 - val_accuracy: 0.8447\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.4000 - accuracy: 0.8796 - val_loss: 0.4089 - val_accuracy: 0.8447\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.3757 - accuracy: 0.8836 - val_loss: 0.3884 - val_accuracy: 0.8402\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.3549 - accuracy: 0.8865 - val_loss: 0.3711 - val_accuracy: 0.8402\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.3372 - accuracy: 0.8904 - val_loss: 0.3564 - val_accuracy: 0.8493\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.3223 - accuracy: 0.8885 - val_loss: 0.3441 - val_accuracy: 0.8493\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.3098 - accuracy: 0.8914 - val_loss: 0.3344 - val_accuracy: 0.8584\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2993 - accuracy: 0.8933 - val_loss: 0.3263 - val_accuracy: 0.8539\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2905 - accuracy: 0.8943 - val_loss: 0.3196 - val_accuracy: 0.8584\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2830 - accuracy: 0.8963 - val_loss: 0.3143 - val_accuracy: 0.8584\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2766 - accuracy: 0.8963 - val_loss: 0.3098 - val_accuracy: 0.8676\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2712 - accuracy: 0.8973 - val_loss: 0.3061 - val_accuracy: 0.8676\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2666 - accuracy: 0.8982 - val_loss: 0.3031 - val_accuracy: 0.8676\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2626 - accuracy: 0.8973 - val_loss: 0.3004 - val_accuracy: 0.8676\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2589 - accuracy: 0.9012 - val_loss: 0.2982 - val_accuracy: 0.8630\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2559 - accuracy: 0.9002 - val_loss: 0.2965 - val_accuracy: 0.8676\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2530 - accuracy: 0.9041 - val_loss: 0.2949 - val_accuracy: 0.8721\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2505 - accuracy: 0.9051 - val_loss: 0.2935 - val_accuracy: 0.8767\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2483 - accuracy: 0.9031 - val_loss: 0.2922 - val_accuracy: 0.8767\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2464 - accuracy: 0.9041 - val_loss: 0.2912 - val_accuracy: 0.8767\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2445 - accuracy: 0.9041 - val_loss: 0.2902 - val_accuracy: 0.8767\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2428 - accuracy: 0.9031 - val_loss: 0.2891 - val_accuracy: 0.8767\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2414 - accuracy: 0.9041 - val_loss: 0.2883 - val_accuracy: 0.8767\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2400 - accuracy: 0.9031 - val_loss: 0.2874 - val_accuracy: 0.8767\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2387 - accuracy: 0.9022 - val_loss: 0.2867 - val_accuracy: 0.8767\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2375 - accuracy: 0.9031 - val_loss: 0.2858 - val_accuracy: 0.8767\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2364 - accuracy: 0.9051 - val_loss: 0.2851 - val_accuracy: 0.8767\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2353 - accuracy: 0.9051 - val_loss: 0.2845 - val_accuracy: 0.8767\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2343 - accuracy: 0.9051 - val_loss: 0.2838 - val_accuracy: 0.8767\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2333 - accuracy: 0.9061 - val_loss: 0.2830 - val_accuracy: 0.8767\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2324 - accuracy: 0.9051 - val_loss: 0.2824 - val_accuracy: 0.8767\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2315 - accuracy: 0.9061 - val_loss: 0.2817 - val_accuracy: 0.8767\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2307 - accuracy: 0.9061 - val_loss: 0.2811 - val_accuracy: 0.8767\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2300 - accuracy: 0.9070 - val_loss: 0.2805 - val_accuracy: 0.8858\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2293 - accuracy: 0.9051 - val_loss: 0.2799 - val_accuracy: 0.8858\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2285 - accuracy: 0.9051 - val_loss: 0.2794 - val_accuracy: 0.8813\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2280 - accuracy: 0.9061 - val_loss: 0.2789 - val_accuracy: 0.8813\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2272 - accuracy: 0.9061 - val_loss: 0.2785 - val_accuracy: 0.8813\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2265 - accuracy: 0.9061 - val_loss: 0.2778 - val_accuracy: 0.8858\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2259 - accuracy: 0.9061 - val_loss: 0.2772 - val_accuracy: 0.8858\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2253 - accuracy: 0.9041 - val_loss: 0.2766 - val_accuracy: 0.8858\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2247 - accuracy: 0.9061 - val_loss: 0.2760 - val_accuracy: 0.8858\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2240 - accuracy: 0.9070 - val_loss: 0.2755 - val_accuracy: 0.8858\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2234 - accuracy: 0.9051 - val_loss: 0.2751 - val_accuracy: 0.8858\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2228 - accuracy: 0.9051 - val_loss: 0.2746 - val_accuracy: 0.8858\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2223 - accuracy: 0.9041 - val_loss: 0.2741 - val_accuracy: 0.8858\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2217 - accuracy: 0.9051 - val_loss: 0.2735 - val_accuracy: 0.8858\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2211 - accuracy: 0.9041 - val_loss: 0.2731 - val_accuracy: 0.8813\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2206 - accuracy: 0.9051 - val_loss: 0.2725 - val_accuracy: 0.8813\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2200 - accuracy: 0.9041 - val_loss: 0.2721 - val_accuracy: 0.8813\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2196 - accuracy: 0.9041 - val_loss: 0.2716 - val_accuracy: 0.8813\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2189 - accuracy: 0.9051 - val_loss: 0.2712 - val_accuracy: 0.8813\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.2184 - accuracy: 0.9051 - val_loss: 0.2709 - val_accuracy: 0.8813\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2179 - accuracy: 0.9051 - val_loss: 0.2706 - val_accuracy: 0.8767\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2174 - accuracy: 0.9051 - val_loss: 0.2701 - val_accuracy: 0.8767\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2168 - accuracy: 0.9061 - val_loss: 0.2697 - val_accuracy: 0.8767\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2164 - accuracy: 0.9061 - val_loss: 0.2694 - val_accuracy: 0.8767\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2158 - accuracy: 0.9061 - val_loss: 0.2690 - val_accuracy: 0.8767\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2153 - accuracy: 0.9070 - val_loss: 0.2688 - val_accuracy: 0.8767\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2147 - accuracy: 0.9051 - val_loss: 0.2684 - val_accuracy: 0.8767\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2144 - accuracy: 0.9051 - val_loss: 0.2679 - val_accuracy: 0.8767\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2138 - accuracy: 0.9061 - val_loss: 0.2676 - val_accuracy: 0.8767\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2133 - accuracy: 0.9080 - val_loss: 0.2672 - val_accuracy: 0.8767\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2128 - accuracy: 0.9070 - val_loss: 0.2670 - val_accuracy: 0.8767\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 172us/step - loss: 0.2125 - accuracy: 0.9061 - val_loss: 0.2667 - val_accuracy: 0.8767\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 180us/step - loss: 0.2119 - accuracy: 0.9070 - val_loss: 0.2663 - val_accuracy: 0.8813\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2116 - accuracy: 0.9100 - val_loss: 0.2661 - val_accuracy: 0.8813\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2111 - accuracy: 0.9090 - val_loss: 0.2655 - val_accuracy: 0.8813\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2106 - accuracy: 0.9080 - val_loss: 0.2652 - val_accuracy: 0.8813\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 175us/step - loss: 0.2102 - accuracy: 0.9080 - val_loss: 0.2650 - val_accuracy: 0.8813\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2097 - accuracy: 0.9100 - val_loss: 0.2647 - val_accuracy: 0.8813\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2093 - accuracy: 0.9090 - val_loss: 0.2644 - val_accuracy: 0.8813\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2088 - accuracy: 0.9090 - val_loss: 0.2640 - val_accuracy: 0.8813\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 278us/step - loss: 0.2085 - accuracy: 0.9080 - val_loss: 0.2636 - val_accuracy: 0.8813\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 262us/step - loss: 0.2080 - accuracy: 0.9100 - val_loss: 0.2634 - val_accuracy: 0.8813\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2076 - accuracy: 0.9090 - val_loss: 0.2630 - val_accuracy: 0.8813\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2073 - accuracy: 0.9090 - val_loss: 0.2628 - val_accuracy: 0.8813\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2068 - accuracy: 0.9080 - val_loss: 0.2624 - val_accuracy: 0.8813\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2064 - accuracy: 0.9090 - val_loss: 0.2621 - val_accuracy: 0.8813\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.2060 - accuracy: 0.9100 - val_loss: 0.2617 - val_accuracy: 0.8813\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2056 - accuracy: 0.9090 - val_loss: 0.2617 - val_accuracy: 0.8813\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2052 - accuracy: 0.9090 - val_loss: 0.2615 - val_accuracy: 0.8813\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2048 - accuracy: 0.9100 - val_loss: 0.2612 - val_accuracy: 0.8813\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2044 - accuracy: 0.9100 - val_loss: 0.2611 - val_accuracy: 0.8813\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.2040 - accuracy: 0.9110 - val_loss: 0.2610 - val_accuracy: 0.8813\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2037 - accuracy: 0.9100 - val_loss: 0.2608 - val_accuracy: 0.8858\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2034 - accuracy: 0.9090 - val_loss: 0.2605 - val_accuracy: 0.8858\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2029 - accuracy: 0.9100 - val_loss: 0.2602 - val_accuracy: 0.8858\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 194us/step - loss: 0.2026 - accuracy: 0.9110 - val_loss: 0.2600 - val_accuracy: 0.8858\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2022 - accuracy: 0.9110 - val_loss: 0.2599 - val_accuracy: 0.8858\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2018 - accuracy: 0.9119 - val_loss: 0.2599 - val_accuracy: 0.8858\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2015 - accuracy: 0.9119 - val_loss: 0.2598 - val_accuracy: 0.8858\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2010 - accuracy: 0.9119 - val_loss: 0.2596 - val_accuracy: 0.8813\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 773us/step - loss: 0.6720 - accuracy: 0.5489 - val_loss: 0.6407 - val_accuracy: 0.6256\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 172us/step - loss: 0.5973 - accuracy: 0.7456 - val_loss: 0.5777 - val_accuracy: 0.7945\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.5366 - accuracy: 0.8131 - val_loss: 0.5240 - val_accuracy: 0.8265\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 223us/step - loss: 0.4849 - accuracy: 0.8454 - val_loss: 0.4776 - val_accuracy: 0.8584\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 164us/step - loss: 0.4405 - accuracy: 0.8718 - val_loss: 0.4378 - val_accuracy: 0.8584\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 199us/step - loss: 0.4029 - accuracy: 0.8796 - val_loss: 0.4044 - val_accuracy: 0.8539\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.3716 - accuracy: 0.8894 - val_loss: 0.3771 - val_accuracy: 0.8539\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.3458 - accuracy: 0.8924 - val_loss: 0.3549 - val_accuracy: 0.8584\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.3244 - accuracy: 0.8904 - val_loss: 0.3370 - val_accuracy: 0.8584\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 166us/step - loss: 0.3070 - accuracy: 0.8933 - val_loss: 0.3228 - val_accuracy: 0.8630\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 168us/step - loss: 0.2928 - accuracy: 0.8963 - val_loss: 0.3118 - val_accuracy: 0.8676\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 167us/step - loss: 0.2813 - accuracy: 0.8973 - val_loss: 0.3030 - val_accuracy: 0.8676\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 168us/step - loss: 0.2719 - accuracy: 0.8992 - val_loss: 0.2960 - val_accuracy: 0.8721\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 169us/step - loss: 0.2641 - accuracy: 0.8992 - val_loss: 0.2905 - val_accuracy: 0.8676\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 171us/step - loss: 0.2576 - accuracy: 0.9022 - val_loss: 0.2863 - val_accuracy: 0.8676\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2523 - accuracy: 0.9031 - val_loss: 0.2829 - val_accuracy: 0.8676\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 182us/step - loss: 0.2477 - accuracy: 0.9031 - val_loss: 0.2803 - val_accuracy: 0.8676\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 176us/step - loss: 0.2440 - accuracy: 0.9022 - val_loss: 0.2782 - val_accuracy: 0.8676\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 197us/step - loss: 0.2408 - accuracy: 0.9012 - val_loss: 0.2765 - val_accuracy: 0.8676\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 170us/step - loss: 0.2380 - accuracy: 0.9012 - val_loss: 0.2751 - val_accuracy: 0.8676\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 181us/step - loss: 0.2356 - accuracy: 0.9022 - val_loss: 0.2742 - val_accuracy: 0.8676\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2335 - accuracy: 0.9031 - val_loss: 0.2732 - val_accuracy: 0.8676\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 211us/step - loss: 0.2318 - accuracy: 0.9022 - val_loss: 0.2724 - val_accuracy: 0.8676\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 212us/step - loss: 0.2299 - accuracy: 0.9022 - val_loss: 0.2717 - val_accuracy: 0.8676\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 219us/step - loss: 0.2286 - accuracy: 0.9012 - val_loss: 0.2711 - val_accuracy: 0.8676\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 170us/step - loss: 0.2272 - accuracy: 0.9022 - val_loss: 0.2706 - val_accuracy: 0.8676\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2261 - accuracy: 0.9012 - val_loss: 0.2701 - val_accuracy: 0.8676\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2249 - accuracy: 0.9012 - val_loss: 0.2698 - val_accuracy: 0.8676\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 213us/step - loss: 0.2240 - accuracy: 0.9031 - val_loss: 0.2695 - val_accuracy: 0.8584\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 219us/step - loss: 0.2230 - accuracy: 0.9012 - val_loss: 0.2691 - val_accuracy: 0.8584\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 224us/step - loss: 0.2222 - accuracy: 0.9022 - val_loss: 0.2688 - val_accuracy: 0.8584\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2214 - accuracy: 0.9022 - val_loss: 0.2685 - val_accuracy: 0.8584\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.2207 - accuracy: 0.9022 - val_loss: 0.2683 - val_accuracy: 0.8584\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2199 - accuracy: 0.9022 - val_loss: 0.2681 - val_accuracy: 0.8584\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 171us/step - loss: 0.2191 - accuracy: 0.9031 - val_loss: 0.2677 - val_accuracy: 0.8676\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2186 - accuracy: 0.9022 - val_loss: 0.2675 - val_accuracy: 0.8676\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2180 - accuracy: 0.9031 - val_loss: 0.2674 - val_accuracy: 0.8676\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2173 - accuracy: 0.9022 - val_loss: 0.2671 - val_accuracy: 0.8676\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.2169 - accuracy: 0.9031 - val_loss: 0.2670 - val_accuracy: 0.8676\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 179us/step - loss: 0.2161 - accuracy: 0.9031 - val_loss: 0.2668 - val_accuracy: 0.8676\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2158 - accuracy: 0.9022 - val_loss: 0.2668 - val_accuracy: 0.8676\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 173us/step - loss: 0.2151 - accuracy: 0.9031 - val_loss: 0.2666 - val_accuracy: 0.8721\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 169us/step - loss: 0.2146 - accuracy: 0.9022 - val_loss: 0.2664 - val_accuracy: 0.8721\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 172us/step - loss: 0.2142 - accuracy: 0.9031 - val_loss: 0.2662 - val_accuracy: 0.8721\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.2137 - accuracy: 0.9041 - val_loss: 0.2661 - val_accuracy: 0.8721\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2132 - accuracy: 0.9061 - val_loss: 0.2659 - val_accuracy: 0.8721\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2126 - accuracy: 0.9070 - val_loss: 0.2657 - val_accuracy: 0.8721\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2122 - accuracy: 0.9061 - val_loss: 0.2656 - val_accuracy: 0.8721\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2118 - accuracy: 0.9051 - val_loss: 0.2653 - val_accuracy: 0.8721\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 178us/step - loss: 0.2113 - accuracy: 0.9070 - val_loss: 0.2652 - val_accuracy: 0.8721\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2108 - accuracy: 0.9061 - val_loss: 0.2651 - val_accuracy: 0.8721\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2103 - accuracy: 0.9070 - val_loss: 0.2650 - val_accuracy: 0.8721\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2100 - accuracy: 0.9070 - val_loss: 0.2647 - val_accuracy: 0.8767\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2096 - accuracy: 0.9061 - val_loss: 0.2645 - val_accuracy: 0.8767\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 171us/step - loss: 0.2092 - accuracy: 0.9070 - val_loss: 0.2645 - val_accuracy: 0.8767\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.2087 - accuracy: 0.9070 - val_loss: 0.2643 - val_accuracy: 0.8767\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2084 - accuracy: 0.9080 - val_loss: 0.2642 - val_accuracy: 0.8767\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 177us/step - loss: 0.2079 - accuracy: 0.9070 - val_loss: 0.2640 - val_accuracy: 0.8767\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 175us/step - loss: 0.2075 - accuracy: 0.9080 - val_loss: 0.2637 - val_accuracy: 0.8767\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2071 - accuracy: 0.9070 - val_loss: 0.2635 - val_accuracy: 0.8767\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.2067 - accuracy: 0.9080 - val_loss: 0.2634 - val_accuracy: 0.8767\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2064 - accuracy: 0.9080 - val_loss: 0.2633 - val_accuracy: 0.8767\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 189us/step - loss: 0.2059 - accuracy: 0.9070 - val_loss: 0.2631 - val_accuracy: 0.8767\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 171us/step - loss: 0.2056 - accuracy: 0.9100 - val_loss: 0.2629 - val_accuracy: 0.8767\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2052 - accuracy: 0.9110 - val_loss: 0.2628 - val_accuracy: 0.8767\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2049 - accuracy: 0.9090 - val_loss: 0.2626 - val_accuracy: 0.8767\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2046 - accuracy: 0.9090 - val_loss: 0.2625 - val_accuracy: 0.8767\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2041 - accuracy: 0.9110 - val_loss: 0.2624 - val_accuracy: 0.8767\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2038 - accuracy: 0.9110 - val_loss: 0.2624 - val_accuracy: 0.8767\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.2034 - accuracy: 0.9110 - val_loss: 0.2623 - val_accuracy: 0.8767\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2032 - accuracy: 0.9100 - val_loss: 0.2622 - val_accuracy: 0.8767\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2028 - accuracy: 0.9100 - val_loss: 0.2619 - val_accuracy: 0.8767\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2024 - accuracy: 0.9119 - val_loss: 0.2619 - val_accuracy: 0.8767\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2021 - accuracy: 0.9110 - val_loss: 0.2618 - val_accuracy: 0.8767\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2017 - accuracy: 0.9129 - val_loss: 0.2617 - val_accuracy: 0.8767\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 202us/step - loss: 0.2015 - accuracy: 0.9139 - val_loss: 0.2615 - val_accuracy: 0.8767\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2011 - accuracy: 0.9129 - val_loss: 0.2613 - val_accuracy: 0.8813\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2007 - accuracy: 0.9139 - val_loss: 0.2613 - val_accuracy: 0.8813\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2004 - accuracy: 0.9129 - val_loss: 0.2612 - val_accuracy: 0.8813\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2001 - accuracy: 0.9139 - val_loss: 0.2611 - val_accuracy: 0.8813\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.1999 - accuracy: 0.9139 - val_loss: 0.2609 - val_accuracy: 0.8813\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.1996 - accuracy: 0.9149 - val_loss: 0.2608 - val_accuracy: 0.8813\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.1991 - accuracy: 0.9149 - val_loss: 0.2606 - val_accuracy: 0.8813\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.1988 - accuracy: 0.9129 - val_loss: 0.2607 - val_accuracy: 0.8813\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.1985 - accuracy: 0.9168 - val_loss: 0.2604 - val_accuracy: 0.8813\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.1982 - accuracy: 0.9159 - val_loss: 0.2603 - val_accuracy: 0.8813\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.1979 - accuracy: 0.9149 - val_loss: 0.2602 - val_accuracy: 0.8813\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.1975 - accuracy: 0.9159 - val_loss: 0.2600 - val_accuracy: 0.8813\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.1973 - accuracy: 0.9168 - val_loss: 0.2599 - val_accuracy: 0.8813\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.1970 - accuracy: 0.9159 - val_loss: 0.2598 - val_accuracy: 0.8813\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.1967 - accuracy: 0.9149 - val_loss: 0.2598 - val_accuracy: 0.8813\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 198us/step - loss: 0.1965 - accuracy: 0.9168 - val_loss: 0.2596 - val_accuracy: 0.8813\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.1962 - accuracy: 0.9168 - val_loss: 0.2595 - val_accuracy: 0.8813\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.1958 - accuracy: 0.9159 - val_loss: 0.2594 - val_accuracy: 0.8813\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 170us/step - loss: 0.1955 - accuracy: 0.9159 - val_loss: 0.2595 - val_accuracy: 0.8813\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 180us/step - loss: 0.1952 - accuracy: 0.9168 - val_loss: 0.2593 - val_accuracy: 0.8813\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.1950 - accuracy: 0.9159 - val_loss: 0.2592 - val_accuracy: 0.8813\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 209us/step - loss: 0.1946 - accuracy: 0.9168 - val_loss: 0.2593 - val_accuracy: 0.8813\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 171us/step - loss: 0.1943 - accuracy: 0.9188 - val_loss: 0.2592 - val_accuracy: 0.8813\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.1940 - accuracy: 0.9168 - val_loss: 0.2591 - val_accuracy: 0.8813\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 885us/step - loss: 0.6669 - accuracy: 0.5783 - val_loss: 0.6356 - val_accuracy: 0.6941\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 169us/step - loss: 0.6135 - accuracy: 0.7407 - val_loss: 0.5923 - val_accuracy: 0.7808\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.5684 - accuracy: 0.8092 - val_loss: 0.5544 - val_accuracy: 0.8174\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.5276 - accuracy: 0.8405 - val_loss: 0.5200 - val_accuracy: 0.8402\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.4900 - accuracy: 0.8562 - val_loss: 0.4882 - val_accuracy: 0.8493\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.4551 - accuracy: 0.8659 - val_loss: 0.4592 - val_accuracy: 0.8493\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.4234 - accuracy: 0.8650 - val_loss: 0.4337 - val_accuracy: 0.8493\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.3953 - accuracy: 0.8689 - val_loss: 0.4119 - val_accuracy: 0.8493\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.3707 - accuracy: 0.8748 - val_loss: 0.3936 - val_accuracy: 0.8493\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.3498 - accuracy: 0.8748 - val_loss: 0.3784 - val_accuracy: 0.8630\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.3322 - accuracy: 0.8777 - val_loss: 0.3660 - val_accuracy: 0.8630\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.3173 - accuracy: 0.8816 - val_loss: 0.3559 - val_accuracy: 0.8630\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.3048 - accuracy: 0.8836 - val_loss: 0.3479 - val_accuracy: 0.8630\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2942 - accuracy: 0.8845 - val_loss: 0.3414 - val_accuracy: 0.8676\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.2854 - accuracy: 0.8855 - val_loss: 0.3363 - val_accuracy: 0.8676\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 181us/step - loss: 0.2779 - accuracy: 0.8904 - val_loss: 0.3322 - val_accuracy: 0.8676\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 187us/step - loss: 0.2717 - accuracy: 0.8904 - val_loss: 0.3289 - val_accuracy: 0.8721\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.2663 - accuracy: 0.8933 - val_loss: 0.3262 - val_accuracy: 0.8721\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 167us/step - loss: 0.2618 - accuracy: 0.8933 - val_loss: 0.3240 - val_accuracy: 0.8721\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 168us/step - loss: 0.2579 - accuracy: 0.8924 - val_loss: 0.3220 - val_accuracy: 0.8676\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 184us/step - loss: 0.2545 - accuracy: 0.8953 - val_loss: 0.3203 - val_accuracy: 0.8676\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2513 - accuracy: 0.8943 - val_loss: 0.3188 - val_accuracy: 0.8584\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 170us/step - loss: 0.2486 - accuracy: 0.8933 - val_loss: 0.3175 - val_accuracy: 0.8584\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2463 - accuracy: 0.8943 - val_loss: 0.3163 - val_accuracy: 0.8584\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2442 - accuracy: 0.8953 - val_loss: 0.3151 - val_accuracy: 0.8584\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2421 - accuracy: 0.8953 - val_loss: 0.3140 - val_accuracy: 0.8584\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2404 - accuracy: 0.8963 - val_loss: 0.3130 - val_accuracy: 0.8584\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2387 - accuracy: 0.8953 - val_loss: 0.3120 - val_accuracy: 0.8584\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 214us/step - loss: 0.2372 - accuracy: 0.8973 - val_loss: 0.3110 - val_accuracy: 0.8584\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 164us/step - loss: 0.2357 - accuracy: 0.8982 - val_loss: 0.3100 - val_accuracy: 0.8584\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 186us/step - loss: 0.2345 - accuracy: 0.8992 - val_loss: 0.3090 - val_accuracy: 0.8584\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2333 - accuracy: 0.9012 - val_loss: 0.3081 - val_accuracy: 0.8584\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 182us/step - loss: 0.2321 - accuracy: 0.8992 - val_loss: 0.3071 - val_accuracy: 0.8584\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 188us/step - loss: 0.2310 - accuracy: 0.9002 - val_loss: 0.3063 - val_accuracy: 0.8584\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2300 - accuracy: 0.9012 - val_loss: 0.3055 - val_accuracy: 0.8584\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 189us/step - loss: 0.2290 - accuracy: 0.9031 - val_loss: 0.3047 - val_accuracy: 0.8584\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.2282 - accuracy: 0.9002 - val_loss: 0.3038 - val_accuracy: 0.8584\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.2273 - accuracy: 0.9002 - val_loss: 0.3031 - val_accuracy: 0.8584\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 169us/step - loss: 0.2265 - accuracy: 0.9002 - val_loss: 0.3023 - val_accuracy: 0.8584\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2257 - accuracy: 0.9002 - val_loss: 0.3016 - val_accuracy: 0.8584\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.2249 - accuracy: 0.9002 - val_loss: 0.3008 - val_accuracy: 0.8584\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.2241 - accuracy: 0.9002 - val_loss: 0.3001 - val_accuracy: 0.8584\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.2234 - accuracy: 0.9012 - val_loss: 0.2994 - val_accuracy: 0.8584\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2227 - accuracy: 0.9002 - val_loss: 0.2986 - val_accuracy: 0.8584\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2220 - accuracy: 0.9012 - val_loss: 0.2978 - val_accuracy: 0.8584\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2213 - accuracy: 0.9002 - val_loss: 0.2971 - val_accuracy: 0.8584\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2207 - accuracy: 0.9022 - val_loss: 0.2963 - val_accuracy: 0.8584\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2201 - accuracy: 0.9031 - val_loss: 0.2956 - val_accuracy: 0.8584\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2195 - accuracy: 0.9031 - val_loss: 0.2949 - val_accuracy: 0.8584\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2189 - accuracy: 0.9051 - val_loss: 0.2941 - val_accuracy: 0.8584\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2183 - accuracy: 0.9061 - val_loss: 0.2935 - val_accuracy: 0.8584\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2176 - accuracy: 0.9051 - val_loss: 0.2929 - val_accuracy: 0.8584\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2171 - accuracy: 0.9070 - val_loss: 0.2923 - val_accuracy: 0.8584\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2167 - accuracy: 0.9070 - val_loss: 0.2917 - val_accuracy: 0.8584\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2161 - accuracy: 0.9061 - val_loss: 0.2912 - val_accuracy: 0.8584\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.2157 - accuracy: 0.9061 - val_loss: 0.2907 - val_accuracy: 0.8584\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2152 - accuracy: 0.9061 - val_loss: 0.2902 - val_accuracy: 0.8584\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2146 - accuracy: 0.9061 - val_loss: 0.2897 - val_accuracy: 0.8584\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2142 - accuracy: 0.9051 - val_loss: 0.2893 - val_accuracy: 0.8584\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2138 - accuracy: 0.9051 - val_loss: 0.2887 - val_accuracy: 0.8584\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2133 - accuracy: 0.9061 - val_loss: 0.2883 - val_accuracy: 0.8584\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2129 - accuracy: 0.9070 - val_loss: 0.2877 - val_accuracy: 0.8584\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2125 - accuracy: 0.9051 - val_loss: 0.2873 - val_accuracy: 0.8584\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2120 - accuracy: 0.9061 - val_loss: 0.2867 - val_accuracy: 0.8584\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2116 - accuracy: 0.9080 - val_loss: 0.2863 - val_accuracy: 0.8584\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2111 - accuracy: 0.9061 - val_loss: 0.2860 - val_accuracy: 0.8584\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 171us/step - loss: 0.2107 - accuracy: 0.9080 - val_loss: 0.2856 - val_accuracy: 0.8584\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2103 - accuracy: 0.9080 - val_loss: 0.2853 - val_accuracy: 0.8584\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2100 - accuracy: 0.9070 - val_loss: 0.2849 - val_accuracy: 0.8584\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2095 - accuracy: 0.9100 - val_loss: 0.2846 - val_accuracy: 0.8584\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.2091 - accuracy: 0.9100 - val_loss: 0.2842 - val_accuracy: 0.8584\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2087 - accuracy: 0.9090 - val_loss: 0.2838 - val_accuracy: 0.8584\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.2084 - accuracy: 0.9090 - val_loss: 0.2836 - val_accuracy: 0.8630\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2080 - accuracy: 0.9100 - val_loss: 0.2833 - val_accuracy: 0.8584\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2076 - accuracy: 0.9100 - val_loss: 0.2829 - val_accuracy: 0.8584\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2073 - accuracy: 0.9080 - val_loss: 0.2826 - val_accuracy: 0.8630\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2068 - accuracy: 0.9110 - val_loss: 0.2823 - val_accuracy: 0.8630\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 167us/step - loss: 0.2064 - accuracy: 0.9110 - val_loss: 0.2820 - val_accuracy: 0.8630\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.2061 - accuracy: 0.9110 - val_loss: 0.2818 - val_accuracy: 0.8630\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2058 - accuracy: 0.9080 - val_loss: 0.2816 - val_accuracy: 0.8630\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2055 - accuracy: 0.9090 - val_loss: 0.2813 - val_accuracy: 0.8630\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2051 - accuracy: 0.9110 - val_loss: 0.2811 - val_accuracy: 0.8630\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2047 - accuracy: 0.9110 - val_loss: 0.2809 - val_accuracy: 0.8630\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2045 - accuracy: 0.9119 - val_loss: 0.2805 - val_accuracy: 0.8630\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2041 - accuracy: 0.9100 - val_loss: 0.2804 - val_accuracy: 0.8630\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.2038 - accuracy: 0.9110 - val_loss: 0.2801 - val_accuracy: 0.8630\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2035 - accuracy: 0.9129 - val_loss: 0.2799 - val_accuracy: 0.8630\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.2031 - accuracy: 0.9119 - val_loss: 0.2796 - val_accuracy: 0.8630\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 198us/step - loss: 0.2028 - accuracy: 0.9119 - val_loss: 0.2794 - val_accuracy: 0.8630\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2025 - accuracy: 0.9110 - val_loss: 0.2792 - val_accuracy: 0.8584\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2022 - accuracy: 0.9110 - val_loss: 0.2790 - val_accuracy: 0.8584\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2018 - accuracy: 0.9129 - val_loss: 0.2788 - val_accuracy: 0.8584\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2015 - accuracy: 0.9110 - val_loss: 0.2787 - val_accuracy: 0.8584\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2012 - accuracy: 0.9129 - val_loss: 0.2785 - val_accuracy: 0.8584\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2009 - accuracy: 0.9110 - val_loss: 0.2782 - val_accuracy: 0.8584\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2007 - accuracy: 0.9119 - val_loss: 0.2779 - val_accuracy: 0.8584\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2003 - accuracy: 0.9159 - val_loss: 0.2777 - val_accuracy: 0.8584\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.1999 - accuracy: 0.9129 - val_loss: 0.2775 - val_accuracy: 0.8584\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.1996 - accuracy: 0.9129 - val_loss: 0.2773 - val_accuracy: 0.8584\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.1993 - accuracy: 0.9110 - val_loss: 0.2771 - val_accuracy: 0.8584\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 895us/step - loss: 0.6471 - accuracy: 0.6517 - val_loss: 0.6263 - val_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.5766 - accuracy: 0.7691 - val_loss: 0.5687 - val_accuracy: 0.7626\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.5213 - accuracy: 0.8141 - val_loss: 0.5222 - val_accuracy: 0.7945\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.4759 - accuracy: 0.8386 - val_loss: 0.4836 - val_accuracy: 0.8311\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.4381 - accuracy: 0.8571 - val_loss: 0.4520 - val_accuracy: 0.8311\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.4066 - accuracy: 0.8640 - val_loss: 0.4259 - val_accuracy: 0.8311\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 189us/step - loss: 0.3799 - accuracy: 0.8708 - val_loss: 0.4044 - val_accuracy: 0.8311\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 192us/step - loss: 0.3577 - accuracy: 0.8787 - val_loss: 0.3868 - val_accuracy: 0.8311\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 167us/step - loss: 0.3391 - accuracy: 0.8855 - val_loss: 0.3726 - val_accuracy: 0.8311\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 191us/step - loss: 0.3235 - accuracy: 0.8894 - val_loss: 0.3610 - val_accuracy: 0.8356\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.3102 - accuracy: 0.8963 - val_loss: 0.3514 - val_accuracy: 0.8402\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 193us/step - loss: 0.2989 - accuracy: 0.9002 - val_loss: 0.3434 - val_accuracy: 0.8447\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2895 - accuracy: 0.9002 - val_loss: 0.3370 - val_accuracy: 0.8447\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 168us/step - loss: 0.2812 - accuracy: 0.9041 - val_loss: 0.3314 - val_accuracy: 0.8493\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 167us/step - loss: 0.2742 - accuracy: 0.9061 - val_loss: 0.3267 - val_accuracy: 0.8539\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.2681 - accuracy: 0.9119 - val_loss: 0.3226 - val_accuracy: 0.8539\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2629 - accuracy: 0.9090 - val_loss: 0.3193 - val_accuracy: 0.8584\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2584 - accuracy: 0.9070 - val_loss: 0.3165 - val_accuracy: 0.8584\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.2544 - accuracy: 0.9139 - val_loss: 0.3139 - val_accuracy: 0.8584\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 182us/step - loss: 0.2511 - accuracy: 0.9119 - val_loss: 0.3117 - val_accuracy: 0.8584\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2481 - accuracy: 0.9139 - val_loss: 0.3097 - val_accuracy: 0.8584\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.2453 - accuracy: 0.9139 - val_loss: 0.3079 - val_accuracy: 0.8584\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2428 - accuracy: 0.9159 - val_loss: 0.3063 - val_accuracy: 0.8584\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2407 - accuracy: 0.9139 - val_loss: 0.3049 - val_accuracy: 0.8630\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2389 - accuracy: 0.9139 - val_loss: 0.3036 - val_accuracy: 0.8539\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2371 - accuracy: 0.9139 - val_loss: 0.3024 - val_accuracy: 0.8539\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2356 - accuracy: 0.9139 - val_loss: 0.3013 - val_accuracy: 0.8539\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2341 - accuracy: 0.9129 - val_loss: 0.3004 - val_accuracy: 0.8584\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2328 - accuracy: 0.9139 - val_loss: 0.2995 - val_accuracy: 0.8584\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2318 - accuracy: 0.9159 - val_loss: 0.2984 - val_accuracy: 0.8630\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2306 - accuracy: 0.9139 - val_loss: 0.2976 - val_accuracy: 0.8630\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2295 - accuracy: 0.9159 - val_loss: 0.2968 - val_accuracy: 0.8676\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 235us/step - loss: 0.2286 - accuracy: 0.9159 - val_loss: 0.2960 - val_accuracy: 0.8676\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 234us/step - loss: 0.2276 - accuracy: 0.9159 - val_loss: 0.2952 - val_accuracy: 0.8676\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 201us/step - loss: 0.2270 - accuracy: 0.9168 - val_loss: 0.2945 - val_accuracy: 0.8676\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2261 - accuracy: 0.9139 - val_loss: 0.2939 - val_accuracy: 0.8676\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2255 - accuracy: 0.9139 - val_loss: 0.2932 - val_accuracy: 0.8721\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2248 - accuracy: 0.9149 - val_loss: 0.2925 - val_accuracy: 0.8676\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2241 - accuracy: 0.9159 - val_loss: 0.2919 - val_accuracy: 0.8676\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2234 - accuracy: 0.9149 - val_loss: 0.2914 - val_accuracy: 0.8676\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2227 - accuracy: 0.9159 - val_loss: 0.2908 - val_accuracy: 0.8676\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2222 - accuracy: 0.9168 - val_loss: 0.2902 - val_accuracy: 0.8676\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2216 - accuracy: 0.9159 - val_loss: 0.2896 - val_accuracy: 0.8676\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2211 - accuracy: 0.9159 - val_loss: 0.2890 - val_accuracy: 0.8721\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2205 - accuracy: 0.9139 - val_loss: 0.2885 - val_accuracy: 0.8721\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2199 - accuracy: 0.9139 - val_loss: 0.2880 - val_accuracy: 0.8721\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2194 - accuracy: 0.9149 - val_loss: 0.2875 - val_accuracy: 0.8721\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2189 - accuracy: 0.9139 - val_loss: 0.2871 - val_accuracy: 0.8721\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2183 - accuracy: 0.9149 - val_loss: 0.2866 - val_accuracy: 0.8721\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2180 - accuracy: 0.9149 - val_loss: 0.2860 - val_accuracy: 0.8721\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2176 - accuracy: 0.9139 - val_loss: 0.2855 - val_accuracy: 0.8721\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2171 - accuracy: 0.9129 - val_loss: 0.2851 - val_accuracy: 0.8721\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2165 - accuracy: 0.9139 - val_loss: 0.2847 - val_accuracy: 0.8721\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.2160 - accuracy: 0.9149 - val_loss: 0.2843 - val_accuracy: 0.8721\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2156 - accuracy: 0.9149 - val_loss: 0.2839 - val_accuracy: 0.8721\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2152 - accuracy: 0.9139 - val_loss: 0.2834 - val_accuracy: 0.8721\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2147 - accuracy: 0.9149 - val_loss: 0.2829 - val_accuracy: 0.8721\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2143 - accuracy: 0.9139 - val_loss: 0.2826 - val_accuracy: 0.8721\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2139 - accuracy: 0.9139 - val_loss: 0.2823 - val_accuracy: 0.8721\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2136 - accuracy: 0.9139 - val_loss: 0.2820 - val_accuracy: 0.8721\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2131 - accuracy: 0.9149 - val_loss: 0.2816 - val_accuracy: 0.8721\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2128 - accuracy: 0.9139 - val_loss: 0.2814 - val_accuracy: 0.8721\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2122 - accuracy: 0.9139 - val_loss: 0.2811 - val_accuracy: 0.8721\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2120 - accuracy: 0.9139 - val_loss: 0.2807 - val_accuracy: 0.8721\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.2116 - accuracy: 0.9139 - val_loss: 0.2805 - val_accuracy: 0.8721\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2111 - accuracy: 0.9139 - val_loss: 0.2801 - val_accuracy: 0.8721\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2108 - accuracy: 0.9139 - val_loss: 0.2797 - val_accuracy: 0.8721\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.2103 - accuracy: 0.9139 - val_loss: 0.2794 - val_accuracy: 0.8721\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2101 - accuracy: 0.9139 - val_loss: 0.2790 - val_accuracy: 0.8721\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.2097 - accuracy: 0.9139 - val_loss: 0.2787 - val_accuracy: 0.8721\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2093 - accuracy: 0.9119 - val_loss: 0.2784 - val_accuracy: 0.8721\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2090 - accuracy: 0.9149 - val_loss: 0.2781 - val_accuracy: 0.8721\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2086 - accuracy: 0.9129 - val_loss: 0.2778 - val_accuracy: 0.8767\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 164us/step - loss: 0.2083 - accuracy: 0.9139 - val_loss: 0.2776 - val_accuracy: 0.8767\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.2079 - accuracy: 0.9139 - val_loss: 0.2774 - val_accuracy: 0.8767\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.2075 - accuracy: 0.9129 - val_loss: 0.2770 - val_accuracy: 0.8767\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2072 - accuracy: 0.9139 - val_loss: 0.2767 - val_accuracy: 0.8767\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2067 - accuracy: 0.9149 - val_loss: 0.2763 - val_accuracy: 0.8767\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2065 - accuracy: 0.9149 - val_loss: 0.2761 - val_accuracy: 0.8813\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 168us/step - loss: 0.2061 - accuracy: 0.9139 - val_loss: 0.2760 - val_accuracy: 0.8813\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2057 - accuracy: 0.9149 - val_loss: 0.2757 - val_accuracy: 0.8858\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.2054 - accuracy: 0.9129 - val_loss: 0.2755 - val_accuracy: 0.8858\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2050 - accuracy: 0.9139 - val_loss: 0.2753 - val_accuracy: 0.8858\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2047 - accuracy: 0.9139 - val_loss: 0.2751 - val_accuracy: 0.8858\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2043 - accuracy: 0.9139 - val_loss: 0.2747 - val_accuracy: 0.8858\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2041 - accuracy: 0.9159 - val_loss: 0.2745 - val_accuracy: 0.8858\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.2036 - accuracy: 0.9139 - val_loss: 0.2742 - val_accuracy: 0.8858\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.2033 - accuracy: 0.9149 - val_loss: 0.2740 - val_accuracy: 0.8858\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2029 - accuracy: 0.9149 - val_loss: 0.2737 - val_accuracy: 0.8858\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2028 - accuracy: 0.9159 - val_loss: 0.2734 - val_accuracy: 0.8858\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2023 - accuracy: 0.9139 - val_loss: 0.2732 - val_accuracy: 0.8858\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.2020 - accuracy: 0.9149 - val_loss: 0.2730 - val_accuracy: 0.8858\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2016 - accuracy: 0.9129 - val_loss: 0.2729 - val_accuracy: 0.8858\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2013 - accuracy: 0.9168 - val_loss: 0.2724 - val_accuracy: 0.8858\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2009 - accuracy: 0.9149 - val_loss: 0.2723 - val_accuracy: 0.8858\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2006 - accuracy: 0.9159 - val_loss: 0.2720 - val_accuracy: 0.8858\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2004 - accuracy: 0.9159 - val_loss: 0.2716 - val_accuracy: 0.8858\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2000 - accuracy: 0.9168 - val_loss: 0.2713 - val_accuracy: 0.8858\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.1996 - accuracy: 0.9168 - val_loss: 0.2710 - val_accuracy: 0.8858\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.1993 - accuracy: 0.9159 - val_loss: 0.2709 - val_accuracy: 0.8858\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 897us/step - loss: 0.6845 - accuracy: 0.5538 - val_loss: 0.6245 - val_accuracy: 0.6849\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 213us/step - loss: 0.6066 - accuracy: 0.7299 - val_loss: 0.5681 - val_accuracy: 0.7808\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.5495 - accuracy: 0.8141 - val_loss: 0.5226 - val_accuracy: 0.8037\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.5027 - accuracy: 0.8434 - val_loss: 0.4839 - val_accuracy: 0.8447\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.4632 - accuracy: 0.8601 - val_loss: 0.4506 - val_accuracy: 0.8630\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.4292 - accuracy: 0.8767 - val_loss: 0.4221 - val_accuracy: 0.8813\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.3999 - accuracy: 0.8836 - val_loss: 0.3978 - val_accuracy: 0.8767\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.3750 - accuracy: 0.8796 - val_loss: 0.3771 - val_accuracy: 0.8813\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.3536 - accuracy: 0.8845 - val_loss: 0.3597 - val_accuracy: 0.8813\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.3356 - accuracy: 0.8855 - val_loss: 0.3452 - val_accuracy: 0.8813\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.3206 - accuracy: 0.8875 - val_loss: 0.3331 - val_accuracy: 0.8813\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.3078 - accuracy: 0.8885 - val_loss: 0.3230 - val_accuracy: 0.8813\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2970 - accuracy: 0.8875 - val_loss: 0.3148 - val_accuracy: 0.8721\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2879 - accuracy: 0.8914 - val_loss: 0.3081 - val_accuracy: 0.8721\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2800 - accuracy: 0.8914 - val_loss: 0.3025 - val_accuracy: 0.8721\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2735 - accuracy: 0.8924 - val_loss: 0.2980 - val_accuracy: 0.8676\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2679 - accuracy: 0.8953 - val_loss: 0.2943 - val_accuracy: 0.8676\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2629 - accuracy: 0.8963 - val_loss: 0.2909 - val_accuracy: 0.8676\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2587 - accuracy: 0.9002 - val_loss: 0.2884 - val_accuracy: 0.8676\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2551 - accuracy: 0.9012 - val_loss: 0.2862 - val_accuracy: 0.8630\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2518 - accuracy: 0.8992 - val_loss: 0.2843 - val_accuracy: 0.8630\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 170us/step - loss: 0.2490 - accuracy: 0.8992 - val_loss: 0.2827 - val_accuracy: 0.8630\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 182us/step - loss: 0.2465 - accuracy: 0.9002 - val_loss: 0.2814 - val_accuracy: 0.8676\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2443 - accuracy: 0.9002 - val_loss: 0.2804 - val_accuracy: 0.8630\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 166us/step - loss: 0.2423 - accuracy: 0.9002 - val_loss: 0.2793 - val_accuracy: 0.8630\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.2405 - accuracy: 0.9022 - val_loss: 0.2783 - val_accuracy: 0.8630\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2390 - accuracy: 0.9022 - val_loss: 0.2777 - val_accuracy: 0.8630\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2375 - accuracy: 0.9012 - val_loss: 0.2771 - val_accuracy: 0.8584\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.2362 - accuracy: 0.9002 - val_loss: 0.2764 - val_accuracy: 0.8584\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.2349 - accuracy: 0.9022 - val_loss: 0.2758 - val_accuracy: 0.8584\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2339 - accuracy: 0.9022 - val_loss: 0.2753 - val_accuracy: 0.8584\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.2328 - accuracy: 0.9012 - val_loss: 0.2748 - val_accuracy: 0.8630\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2318 - accuracy: 0.9022 - val_loss: 0.2744 - val_accuracy: 0.8630\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2309 - accuracy: 0.9022 - val_loss: 0.2740 - val_accuracy: 0.8630\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 186us/step - loss: 0.2301 - accuracy: 0.9041 - val_loss: 0.2737 - val_accuracy: 0.8630\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 189us/step - loss: 0.2292 - accuracy: 0.9061 - val_loss: 0.2734 - val_accuracy: 0.8676\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2285 - accuracy: 0.9051 - val_loss: 0.2732 - val_accuracy: 0.8676\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2276 - accuracy: 0.9070 - val_loss: 0.2729 - val_accuracy: 0.8676\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2270 - accuracy: 0.9070 - val_loss: 0.2726 - val_accuracy: 0.8676\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2262 - accuracy: 0.9080 - val_loss: 0.2721 - val_accuracy: 0.8676\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2257 - accuracy: 0.9080 - val_loss: 0.2717 - val_accuracy: 0.8676\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2250 - accuracy: 0.9090 - val_loss: 0.2713 - val_accuracy: 0.8676\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2243 - accuracy: 0.9080 - val_loss: 0.2711 - val_accuracy: 0.8676\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 174us/step - loss: 0.2238 - accuracy: 0.9090 - val_loss: 0.2707 - val_accuracy: 0.8676\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2232 - accuracy: 0.9080 - val_loss: 0.2704 - val_accuracy: 0.8676\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2227 - accuracy: 0.9090 - val_loss: 0.2702 - val_accuracy: 0.8676\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2221 - accuracy: 0.9090 - val_loss: 0.2700 - val_accuracy: 0.8676\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2215 - accuracy: 0.9080 - val_loss: 0.2699 - val_accuracy: 0.8676\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.2210 - accuracy: 0.9100 - val_loss: 0.2693 - val_accuracy: 0.8676\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2205 - accuracy: 0.9090 - val_loss: 0.2690 - val_accuracy: 0.8676\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2199 - accuracy: 0.9100 - val_loss: 0.2685 - val_accuracy: 0.8721\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.2195 - accuracy: 0.9090 - val_loss: 0.2681 - val_accuracy: 0.8767\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2190 - accuracy: 0.9080 - val_loss: 0.2680 - val_accuracy: 0.8767\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2185 - accuracy: 0.9090 - val_loss: 0.2677 - val_accuracy: 0.8813\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2180 - accuracy: 0.9100 - val_loss: 0.2675 - val_accuracy: 0.8813\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.2176 - accuracy: 0.9100 - val_loss: 0.2671 - val_accuracy: 0.8813\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2171 - accuracy: 0.9090 - val_loss: 0.2670 - val_accuracy: 0.8813\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2166 - accuracy: 0.9090 - val_loss: 0.2668 - val_accuracy: 0.8813\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2162 - accuracy: 0.9090 - val_loss: 0.2666 - val_accuracy: 0.8813\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2157 - accuracy: 0.9090 - val_loss: 0.2663 - val_accuracy: 0.8813\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2153 - accuracy: 0.9090 - val_loss: 0.2661 - val_accuracy: 0.8813\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 188us/step - loss: 0.2148 - accuracy: 0.9100 - val_loss: 0.2660 - val_accuracy: 0.8813\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 167us/step - loss: 0.2144 - accuracy: 0.9100 - val_loss: 0.2655 - val_accuracy: 0.8813\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2140 - accuracy: 0.9100 - val_loss: 0.2653 - val_accuracy: 0.8813\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2135 - accuracy: 0.9119 - val_loss: 0.2651 - val_accuracy: 0.8813\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.2131 - accuracy: 0.9100 - val_loss: 0.2647 - val_accuracy: 0.8813\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.2128 - accuracy: 0.9090 - val_loss: 0.2643 - val_accuracy: 0.8813\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2123 - accuracy: 0.9080 - val_loss: 0.2638 - val_accuracy: 0.8813\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2120 - accuracy: 0.9100 - val_loss: 0.2636 - val_accuracy: 0.8813\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 184us/step - loss: 0.2115 - accuracy: 0.9100 - val_loss: 0.2632 - val_accuracy: 0.8813\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 176us/step - loss: 0.2111 - accuracy: 0.9100 - val_loss: 0.2631 - val_accuracy: 0.8813\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2107 - accuracy: 0.9110 - val_loss: 0.2630 - val_accuracy: 0.8858\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 196us/step - loss: 0.2104 - accuracy: 0.9100 - val_loss: 0.2626 - val_accuracy: 0.8858\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.2100 - accuracy: 0.9110 - val_loss: 0.2623 - val_accuracy: 0.8858\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2096 - accuracy: 0.9110 - val_loss: 0.2621 - val_accuracy: 0.8858\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2093 - accuracy: 0.9100 - val_loss: 0.2621 - val_accuracy: 0.8858\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 164us/step - loss: 0.2090 - accuracy: 0.9080 - val_loss: 0.2621 - val_accuracy: 0.8858\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2085 - accuracy: 0.9110 - val_loss: 0.2618 - val_accuracy: 0.8858\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.2082 - accuracy: 0.9110 - val_loss: 0.2616 - val_accuracy: 0.8858\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2079 - accuracy: 0.9119 - val_loss: 0.2612 - val_accuracy: 0.8858\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2076 - accuracy: 0.9119 - val_loss: 0.2608 - val_accuracy: 0.8858\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2072 - accuracy: 0.9090 - val_loss: 0.2607 - val_accuracy: 0.8858\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2068 - accuracy: 0.9080 - val_loss: 0.2608 - val_accuracy: 0.8858\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2065 - accuracy: 0.9090 - val_loss: 0.2606 - val_accuracy: 0.8858\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2061 - accuracy: 0.9110 - val_loss: 0.2604 - val_accuracy: 0.8858\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2059 - accuracy: 0.9090 - val_loss: 0.2603 - val_accuracy: 0.8858\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.2055 - accuracy: 0.9119 - val_loss: 0.2600 - val_accuracy: 0.8858\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2052 - accuracy: 0.9110 - val_loss: 0.2598 - val_accuracy: 0.8858\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2048 - accuracy: 0.9129 - val_loss: 0.2595 - val_accuracy: 0.8858\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2046 - accuracy: 0.9139 - val_loss: 0.2593 - val_accuracy: 0.8858\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2042 - accuracy: 0.9159 - val_loss: 0.2591 - val_accuracy: 0.8858\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2038 - accuracy: 0.9139 - val_loss: 0.2589 - val_accuracy: 0.8858\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2036 - accuracy: 0.9149 - val_loss: 0.2586 - val_accuracy: 0.8858\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2033 - accuracy: 0.9149 - val_loss: 0.2583 - val_accuracy: 0.8858\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2029 - accuracy: 0.9129 - val_loss: 0.2580 - val_accuracy: 0.8904\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2026 - accuracy: 0.9139 - val_loss: 0.2578 - val_accuracy: 0.8904\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2023 - accuracy: 0.9139 - val_loss: 0.2578 - val_accuracy: 0.8858\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2021 - accuracy: 0.9159 - val_loss: 0.2577 - val_accuracy: 0.8813\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 171us/step - loss: 0.2018 - accuracy: 0.9168 - val_loss: 0.2574 - val_accuracy: 0.8858\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 213us/step - loss: 0.2015 - accuracy: 0.9159 - val_loss: 0.2572 - val_accuracy: 0.8858\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 799us/step - loss: 0.6872 - accuracy: 0.5479 - val_loss: 0.6517 - val_accuracy: 0.6119\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.6108 - accuracy: 0.7456 - val_loss: 0.5903 - val_accuracy: 0.7854\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.5521 - accuracy: 0.8337 - val_loss: 0.5409 - val_accuracy: 0.8174\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.5038 - accuracy: 0.8669 - val_loss: 0.4995 - val_accuracy: 0.8311\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.4626 - accuracy: 0.8738 - val_loss: 0.4643 - val_accuracy: 0.8356\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.4277 - accuracy: 0.8855 - val_loss: 0.4349 - val_accuracy: 0.8311\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.3983 - accuracy: 0.8904 - val_loss: 0.4108 - val_accuracy: 0.8447\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.3739 - accuracy: 0.8924 - val_loss: 0.3911 - val_accuracy: 0.8493\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.3533 - accuracy: 0.8933 - val_loss: 0.3750 - val_accuracy: 0.8539\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.3360 - accuracy: 0.8963 - val_loss: 0.3620 - val_accuracy: 0.8584\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.3214 - accuracy: 0.8943 - val_loss: 0.3516 - val_accuracy: 0.8539\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.3093 - accuracy: 0.8953 - val_loss: 0.3432 - val_accuracy: 0.8539\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2991 - accuracy: 0.8953 - val_loss: 0.3365 - val_accuracy: 0.8539\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.2906 - accuracy: 0.8973 - val_loss: 0.3312 - val_accuracy: 0.8539\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2834 - accuracy: 0.9031 - val_loss: 0.3269 - val_accuracy: 0.8539\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2772 - accuracy: 0.9031 - val_loss: 0.3235 - val_accuracy: 0.8584\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.2719 - accuracy: 0.9051 - val_loss: 0.3206 - val_accuracy: 0.8539\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2674 - accuracy: 0.9061 - val_loss: 0.3184 - val_accuracy: 0.8584\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2635 - accuracy: 0.9080 - val_loss: 0.3167 - val_accuracy: 0.8539\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2599 - accuracy: 0.9061 - val_loss: 0.3151 - val_accuracy: 0.8493\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2568 - accuracy: 0.9070 - val_loss: 0.3138 - val_accuracy: 0.8539\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2541 - accuracy: 0.9051 - val_loss: 0.3128 - val_accuracy: 0.8539\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2517 - accuracy: 0.9051 - val_loss: 0.3118 - val_accuracy: 0.8539\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2495 - accuracy: 0.9061 - val_loss: 0.3109 - val_accuracy: 0.8539\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2474 - accuracy: 0.9061 - val_loss: 0.3101 - val_accuracy: 0.8493\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2458 - accuracy: 0.9061 - val_loss: 0.3093 - val_accuracy: 0.8493\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2440 - accuracy: 0.9070 - val_loss: 0.3086 - val_accuracy: 0.8493\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2425 - accuracy: 0.9061 - val_loss: 0.3079 - val_accuracy: 0.8447\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.2411 - accuracy: 0.9080 - val_loss: 0.3072 - val_accuracy: 0.8447\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2397 - accuracy: 0.9070 - val_loss: 0.3065 - val_accuracy: 0.8493\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.2386 - accuracy: 0.9090 - val_loss: 0.3060 - val_accuracy: 0.8493\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2373 - accuracy: 0.9070 - val_loss: 0.3054 - val_accuracy: 0.8493\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2363 - accuracy: 0.9061 - val_loss: 0.3048 - val_accuracy: 0.8493\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.2353 - accuracy: 0.9051 - val_loss: 0.3042 - val_accuracy: 0.8493\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2344 - accuracy: 0.9051 - val_loss: 0.3035 - val_accuracy: 0.8493\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2335 - accuracy: 0.9051 - val_loss: 0.3029 - val_accuracy: 0.8493\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.2326 - accuracy: 0.9061 - val_loss: 0.3022 - val_accuracy: 0.8493\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2318 - accuracy: 0.9041 - val_loss: 0.3016 - val_accuracy: 0.8493\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2310 - accuracy: 0.9070 - val_loss: 0.3010 - val_accuracy: 0.8493\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2302 - accuracy: 0.9061 - val_loss: 0.3005 - val_accuracy: 0.8493\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2296 - accuracy: 0.9041 - val_loss: 0.2998 - val_accuracy: 0.8493\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2289 - accuracy: 0.9051 - val_loss: 0.2993 - val_accuracy: 0.8493\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2282 - accuracy: 0.9051 - val_loss: 0.2986 - val_accuracy: 0.8493\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2276 - accuracy: 0.9070 - val_loss: 0.2980 - val_accuracy: 0.8493\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2270 - accuracy: 0.9070 - val_loss: 0.2974 - val_accuracy: 0.8493\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2264 - accuracy: 0.9100 - val_loss: 0.2969 - val_accuracy: 0.8493\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.2257 - accuracy: 0.9090 - val_loss: 0.2963 - val_accuracy: 0.8493\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 166us/step - loss: 0.2251 - accuracy: 0.9080 - val_loss: 0.2959 - val_accuracy: 0.8493\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2246 - accuracy: 0.9070 - val_loss: 0.2953 - val_accuracy: 0.8493\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 193us/step - loss: 0.2240 - accuracy: 0.9070 - val_loss: 0.2948 - val_accuracy: 0.8493\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2234 - accuracy: 0.9070 - val_loss: 0.2941 - val_accuracy: 0.8539\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2229 - accuracy: 0.9070 - val_loss: 0.2935 - val_accuracy: 0.8539\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2224 - accuracy: 0.9070 - val_loss: 0.2930 - val_accuracy: 0.8539\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2219 - accuracy: 0.9061 - val_loss: 0.2925 - val_accuracy: 0.8539\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 203us/step - loss: 0.2214 - accuracy: 0.9080 - val_loss: 0.2921 - val_accuracy: 0.8539\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2209 - accuracy: 0.9070 - val_loss: 0.2916 - val_accuracy: 0.8539\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2204 - accuracy: 0.9090 - val_loss: 0.2912 - val_accuracy: 0.8539\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2200 - accuracy: 0.9090 - val_loss: 0.2908 - val_accuracy: 0.8539\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2196 - accuracy: 0.9070 - val_loss: 0.2903 - val_accuracy: 0.8584\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 167us/step - loss: 0.2190 - accuracy: 0.9090 - val_loss: 0.2898 - val_accuracy: 0.8584\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2187 - accuracy: 0.9090 - val_loss: 0.2892 - val_accuracy: 0.8584\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2181 - accuracy: 0.9090 - val_loss: 0.2888 - val_accuracy: 0.8630\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2178 - accuracy: 0.9080 - val_loss: 0.2884 - val_accuracy: 0.8630\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2174 - accuracy: 0.9100 - val_loss: 0.2880 - val_accuracy: 0.8630\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2170 - accuracy: 0.9090 - val_loss: 0.2876 - val_accuracy: 0.8630\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2165 - accuracy: 0.9100 - val_loss: 0.2872 - val_accuracy: 0.8676\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2163 - accuracy: 0.9100 - val_loss: 0.2869 - val_accuracy: 0.8676\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2158 - accuracy: 0.9090 - val_loss: 0.2866 - val_accuracy: 0.8676\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2154 - accuracy: 0.9100 - val_loss: 0.2863 - val_accuracy: 0.8676\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2151 - accuracy: 0.9100 - val_loss: 0.2861 - val_accuracy: 0.8676\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2147 - accuracy: 0.9090 - val_loss: 0.2857 - val_accuracy: 0.8676\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2143 - accuracy: 0.9100 - val_loss: 0.2853 - val_accuracy: 0.8676\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2139 - accuracy: 0.9100 - val_loss: 0.2850 - val_accuracy: 0.8676\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.2136 - accuracy: 0.9100 - val_loss: 0.2846 - val_accuracy: 0.8676\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2133 - accuracy: 0.9100 - val_loss: 0.2842 - val_accuracy: 0.8676\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.2129 - accuracy: 0.9100 - val_loss: 0.2837 - val_accuracy: 0.8676\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.2125 - accuracy: 0.9110 - val_loss: 0.2834 - val_accuracy: 0.8676\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2122 - accuracy: 0.9110 - val_loss: 0.2831 - val_accuracy: 0.8676\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.2119 - accuracy: 0.9119 - val_loss: 0.2829 - val_accuracy: 0.8676\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 166us/step - loss: 0.2115 - accuracy: 0.9110 - val_loss: 0.2826 - val_accuracy: 0.8676\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2112 - accuracy: 0.9110 - val_loss: 0.2823 - val_accuracy: 0.8676\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.2109 - accuracy: 0.9119 - val_loss: 0.2819 - val_accuracy: 0.8767\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.2106 - accuracy: 0.9119 - val_loss: 0.2817 - val_accuracy: 0.8767\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.2102 - accuracy: 0.9129 - val_loss: 0.2815 - val_accuracy: 0.8767\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 166us/step - loss: 0.2100 - accuracy: 0.9139 - val_loss: 0.2813 - val_accuracy: 0.8721\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 185us/step - loss: 0.2095 - accuracy: 0.9119 - val_loss: 0.2810 - val_accuracy: 0.8721\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2093 - accuracy: 0.9129 - val_loss: 0.2807 - val_accuracy: 0.8767\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2089 - accuracy: 0.9129 - val_loss: 0.2804 - val_accuracy: 0.8767\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.2086 - accuracy: 0.9139 - val_loss: 0.2801 - val_accuracy: 0.8767\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2084 - accuracy: 0.9139 - val_loss: 0.2799 - val_accuracy: 0.8767\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2081 - accuracy: 0.9139 - val_loss: 0.2795 - val_accuracy: 0.8813\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2079 - accuracy: 0.9149 - val_loss: 0.2793 - val_accuracy: 0.8813\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2075 - accuracy: 0.9149 - val_loss: 0.2790 - val_accuracy: 0.8813\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2072 - accuracy: 0.9149 - val_loss: 0.2788 - val_accuracy: 0.8813\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2070 - accuracy: 0.9139 - val_loss: 0.2786 - val_accuracy: 0.8813\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2066 - accuracy: 0.9139 - val_loss: 0.2783 - val_accuracy: 0.8767\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2064 - accuracy: 0.9159 - val_loss: 0.2780 - val_accuracy: 0.8767\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2062 - accuracy: 0.9149 - val_loss: 0.2779 - val_accuracy: 0.8767\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2058 - accuracy: 0.9149 - val_loss: 0.2776 - val_accuracy: 0.8767\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2055 - accuracy: 0.9149 - val_loss: 0.2774 - val_accuracy: 0.8767\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 813us/step - loss: 0.6989 - accuracy: 0.3454 - val_loss: 0.6974 - val_accuracy: 0.4932\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.6970 - accuracy: 0.4716 - val_loss: 0.6961 - val_accuracy: 0.4932\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - ETA: 0s - loss: 0.6956 - accuracy: 0.48 - 0s 117us/step - loss: 0.6957 - accuracy: 0.4843 - val_loss: 0.6951 - val_accuracy: 0.4932\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.6946 - accuracy: 0.5098 - val_loss: 0.6942 - val_accuracy: 0.4932\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.6937 - accuracy: 0.5098 - val_loss: 0.6935 - val_accuracy: 0.4932\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.6928 - accuracy: 0.5098 - val_loss: 0.6929 - val_accuracy: 0.4932\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.6920 - accuracy: 0.5176 - val_loss: 0.6921 - val_accuracy: 0.5023\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.6911 - accuracy: 0.5861 - val_loss: 0.6913 - val_accuracy: 0.5753\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.6901 - accuracy: 0.6233 - val_loss: 0.6903 - val_accuracy: 0.6347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.6887 - accuracy: 0.6683 - val_loss: 0.6889 - val_accuracy: 0.6438\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.6868 - accuracy: 0.6928 - val_loss: 0.6872 - val_accuracy: 0.6530\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.6841 - accuracy: 0.7084 - val_loss: 0.6841 - val_accuracy: 0.6986\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.6797 - accuracy: 0.7221 - val_loss: 0.6788 - val_accuracy: 0.7169\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.6716 - accuracy: 0.7886 - val_loss: 0.6696 - val_accuracy: 0.7626\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.6582 - accuracy: 0.8053 - val_loss: 0.6553 - val_accuracy: 0.7808\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.6375 - accuracy: 0.8180 - val_loss: 0.6340 - val_accuracy: 0.7991\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.6074 - accuracy: 0.8249 - val_loss: 0.6043 - val_accuracy: 0.8174\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.5729 - accuracy: 0.8395 - val_loss: 0.5715 - val_accuracy: 0.8128\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.5355 - accuracy: 0.8513 - val_loss: 0.5391 - val_accuracy: 0.8356\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 176us/step - loss: 0.4981 - accuracy: 0.8611 - val_loss: 0.5086 - val_accuracy: 0.8356\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.4632 - accuracy: 0.8728 - val_loss: 0.4812 - val_accuracy: 0.8356\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 176us/step - loss: 0.4316 - accuracy: 0.8738 - val_loss: 0.4563 - val_accuracy: 0.8402\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 177us/step - loss: 0.4030 - accuracy: 0.8836 - val_loss: 0.4341 - val_accuracy: 0.8447\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 200us/step - loss: 0.3777 - accuracy: 0.8914 - val_loss: 0.4148 - val_accuracy: 0.8539\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.3556 - accuracy: 0.8914 - val_loss: 0.3983 - val_accuracy: 0.8493\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 233us/step - loss: 0.3366 - accuracy: 0.8924 - val_loss: 0.3846 - val_accuracy: 0.8584\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.3206 - accuracy: 0.8914 - val_loss: 0.3730 - val_accuracy: 0.8584\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.3071 - accuracy: 0.8963 - val_loss: 0.3638 - val_accuracy: 0.8584\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2959 - accuracy: 0.8973 - val_loss: 0.3561 - val_accuracy: 0.8584\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2867 - accuracy: 0.8963 - val_loss: 0.3497 - val_accuracy: 0.8676\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 171us/step - loss: 0.2786 - accuracy: 0.8963 - val_loss: 0.3441 - val_accuracy: 0.8676\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 164us/step - loss: 0.2718 - accuracy: 0.8982 - val_loss: 0.3393 - val_accuracy: 0.8676\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2660 - accuracy: 0.9002 - val_loss: 0.3351 - val_accuracy: 0.8630\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2611 - accuracy: 0.9012 - val_loss: 0.3316 - val_accuracy: 0.8630\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2568 - accuracy: 0.9022 - val_loss: 0.3285 - val_accuracy: 0.8676\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 223us/step - loss: 0.2532 - accuracy: 0.9022 - val_loss: 0.3260 - val_accuracy: 0.8676\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2500 - accuracy: 0.9031 - val_loss: 0.3237 - val_accuracy: 0.8676\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.2473 - accuracy: 0.9041 - val_loss: 0.3218 - val_accuracy: 0.8676\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2450 - accuracy: 0.9051 - val_loss: 0.3199 - val_accuracy: 0.8721\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.2429 - accuracy: 0.9051 - val_loss: 0.3183 - val_accuracy: 0.8630\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 101us/step - loss: 0.2410 - accuracy: 0.9031 - val_loss: 0.3168 - val_accuracy: 0.8630\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2394 - accuracy: 0.9031 - val_loss: 0.3156 - val_accuracy: 0.8630\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 185us/step - loss: 0.2379 - accuracy: 0.9051 - val_loss: 0.3143 - val_accuracy: 0.8630\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 172us/step - loss: 0.2365 - accuracy: 0.9051 - val_loss: 0.3131 - val_accuracy: 0.8630\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2354 - accuracy: 0.9061 - val_loss: 0.3120 - val_accuracy: 0.8676\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 184us/step - loss: 0.2343 - accuracy: 0.9051 - val_loss: 0.3110 - val_accuracy: 0.8721\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2332 - accuracy: 0.9061 - val_loss: 0.3097 - val_accuracy: 0.8721\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 223us/step - loss: 0.2321 - accuracy: 0.9051 - val_loss: 0.3087 - val_accuracy: 0.8676\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 186us/step - loss: 0.2312 - accuracy: 0.9061 - val_loss: 0.3077 - val_accuracy: 0.8676\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.2304 - accuracy: 0.9061 - val_loss: 0.3066 - val_accuracy: 0.8721\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 209us/step - loss: 0.2297 - accuracy: 0.9061 - val_loss: 0.3057 - val_accuracy: 0.8721\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 212us/step - loss: 0.2289 - accuracy: 0.9051 - val_loss: 0.3049 - val_accuracy: 0.8721\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 329us/step - loss: 0.2282 - accuracy: 0.9061 - val_loss: 0.3040 - val_accuracy: 0.8721\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 191us/step - loss: 0.2275 - accuracy: 0.9041 - val_loss: 0.3031 - val_accuracy: 0.8721\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 268us/step - loss: 0.2268 - accuracy: 0.9031 - val_loss: 0.3023 - val_accuracy: 0.8721\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 311us/step - loss: 0.2263 - accuracy: 0.9051 - val_loss: 0.3015 - val_accuracy: 0.8721\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 195us/step - loss: 0.2256 - accuracy: 0.9051 - val_loss: 0.3007 - val_accuracy: 0.8676\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 170us/step - loss: 0.2251 - accuracy: 0.9051 - val_loss: 0.3000 - val_accuracy: 0.8676\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 457us/step - loss: 0.2246 - accuracy: 0.9061 - val_loss: 0.2993 - val_accuracy: 0.8676\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 211us/step - loss: 0.2240 - accuracy: 0.9061 - val_loss: 0.2985 - val_accuracy: 0.8676\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 182us/step - loss: 0.2235 - accuracy: 0.9061 - val_loss: 0.2978 - val_accuracy: 0.8676\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2231 - accuracy: 0.9061 - val_loss: 0.2971 - val_accuracy: 0.8676\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2226 - accuracy: 0.9070 - val_loss: 0.2964 - val_accuracy: 0.8676\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2222 - accuracy: 0.9061 - val_loss: 0.2958 - val_accuracy: 0.8676\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.2217 - accuracy: 0.9061 - val_loss: 0.2953 - val_accuracy: 0.8676\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2213 - accuracy: 0.9070 - val_loss: 0.2946 - val_accuracy: 0.8676\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.2209 - accuracy: 0.9070 - val_loss: 0.2939 - val_accuracy: 0.8676\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2203 - accuracy: 0.9080 - val_loss: 0.2934 - val_accuracy: 0.8676\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2200 - accuracy: 0.9080 - val_loss: 0.2927 - val_accuracy: 0.8676\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2196 - accuracy: 0.9090 - val_loss: 0.2921 - val_accuracy: 0.8721\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2192 - accuracy: 0.9090 - val_loss: 0.2917 - val_accuracy: 0.8721\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2188 - accuracy: 0.9100 - val_loss: 0.2910 - val_accuracy: 0.8721\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2184 - accuracy: 0.9080 - val_loss: 0.2906 - val_accuracy: 0.8721\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2180 - accuracy: 0.9119 - val_loss: 0.2899 - val_accuracy: 0.8721\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2178 - accuracy: 0.9080 - val_loss: 0.2893 - val_accuracy: 0.8721\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2172 - accuracy: 0.9110 - val_loss: 0.2887 - val_accuracy: 0.8721\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2169 - accuracy: 0.9080 - val_loss: 0.2882 - val_accuracy: 0.8721\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.2165 - accuracy: 0.9100 - val_loss: 0.2877 - val_accuracy: 0.8721\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.2161 - accuracy: 0.9100 - val_loss: 0.2873 - val_accuracy: 0.8721\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2157 - accuracy: 0.9100 - val_loss: 0.2867 - val_accuracy: 0.8721\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2153 - accuracy: 0.9129 - val_loss: 0.2862 - val_accuracy: 0.8767\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2151 - accuracy: 0.9119 - val_loss: 0.2858 - val_accuracy: 0.8721\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2148 - accuracy: 0.9100 - val_loss: 0.2853 - val_accuracy: 0.8767\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2142 - accuracy: 0.9119 - val_loss: 0.2848 - val_accuracy: 0.8767\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2139 - accuracy: 0.9139 - val_loss: 0.2844 - val_accuracy: 0.8721\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2136 - accuracy: 0.9139 - val_loss: 0.2840 - val_accuracy: 0.8721\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2131 - accuracy: 0.9149 - val_loss: 0.2835 - val_accuracy: 0.8721\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2128 - accuracy: 0.9149 - val_loss: 0.2831 - val_accuracy: 0.8767\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2124 - accuracy: 0.9139 - val_loss: 0.2826 - val_accuracy: 0.8767\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2121 - accuracy: 0.9149 - val_loss: 0.2823 - val_accuracy: 0.8721\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2117 - accuracy: 0.9149 - val_loss: 0.2819 - val_accuracy: 0.8721\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2113 - accuracy: 0.9149 - val_loss: 0.2815 - val_accuracy: 0.8721\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2111 - accuracy: 0.9149 - val_loss: 0.2811 - val_accuracy: 0.8721\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2107 - accuracy: 0.9168 - val_loss: 0.2807 - val_accuracy: 0.8721\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2104 - accuracy: 0.9149 - val_loss: 0.2804 - val_accuracy: 0.8721\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2100 - accuracy: 0.9159 - val_loss: 0.2800 - val_accuracy: 0.8721\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2097 - accuracy: 0.9149 - val_loss: 0.2796 - val_accuracy: 0.8721\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2093 - accuracy: 0.9159 - val_loss: 0.2791 - val_accuracy: 0.8721\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2090 - accuracy: 0.9149 - val_loss: 0.2789 - val_accuracy: 0.8721\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2087 - accuracy: 0.9149 - val_loss: 0.2786 - val_accuracy: 0.8721\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 798us/step - loss: 0.6606 - accuracy: 0.6419 - val_loss: 0.6528 - val_accuracy: 0.7032\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 179us/step - loss: 0.6192 - accuracy: 0.7524 - val_loss: 0.6171 - val_accuracy: 0.7717\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.5815 - accuracy: 0.8160 - val_loss: 0.5808 - val_accuracy: 0.8082\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 178us/step - loss: 0.5433 - accuracy: 0.8346 - val_loss: 0.5443 - val_accuracy: 0.8082\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.5063 - accuracy: 0.8493 - val_loss: 0.5103 - val_accuracy: 0.8356\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.4705 - accuracy: 0.8601 - val_loss: 0.4772 - val_accuracy: 0.8356\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.4367 - accuracy: 0.8659 - val_loss: 0.4462 - val_accuracy: 0.8493\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.4069 - accuracy: 0.8728 - val_loss: 0.4206 - val_accuracy: 0.8493\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.3815 - accuracy: 0.8757 - val_loss: 0.3996 - val_accuracy: 0.8447\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.3596 - accuracy: 0.8757 - val_loss: 0.3823 - val_accuracy: 0.8584\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.3408 - accuracy: 0.8787 - val_loss: 0.3682 - val_accuracy: 0.8584\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.3249 - accuracy: 0.8796 - val_loss: 0.3571 - val_accuracy: 0.8584\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.3119 - accuracy: 0.8826 - val_loss: 0.3481 - val_accuracy: 0.8584\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 164us/step - loss: 0.3013 - accuracy: 0.8826 - val_loss: 0.3409 - val_accuracy: 0.8584\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 160us/step - loss: 0.2922 - accuracy: 0.8855 - val_loss: 0.3348 - val_accuracy: 0.8493\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2847 - accuracy: 0.8855 - val_loss: 0.3298 - val_accuracy: 0.8493\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2781 - accuracy: 0.8914 - val_loss: 0.3258 - val_accuracy: 0.8493\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2725 - accuracy: 0.8933 - val_loss: 0.3224 - val_accuracy: 0.8493\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2676 - accuracy: 0.8924 - val_loss: 0.3195 - val_accuracy: 0.8447\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2634 - accuracy: 0.8933 - val_loss: 0.3169 - val_accuracy: 0.8493\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2597 - accuracy: 0.8963 - val_loss: 0.3144 - val_accuracy: 0.8493\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2564 - accuracy: 0.8953 - val_loss: 0.3121 - val_accuracy: 0.8493\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2534 - accuracy: 0.8933 - val_loss: 0.3101 - val_accuracy: 0.8539\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2507 - accuracy: 0.8943 - val_loss: 0.3082 - val_accuracy: 0.8539\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2483 - accuracy: 0.8953 - val_loss: 0.3064 - val_accuracy: 0.8539\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2462 - accuracy: 0.8953 - val_loss: 0.3047 - val_accuracy: 0.8539\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2442 - accuracy: 0.8973 - val_loss: 0.3030 - val_accuracy: 0.8539\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2424 - accuracy: 0.8982 - val_loss: 0.3014 - val_accuracy: 0.8584\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2406 - accuracy: 0.9012 - val_loss: 0.2998 - val_accuracy: 0.8584\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2391 - accuracy: 0.9022 - val_loss: 0.2984 - val_accuracy: 0.8584\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2376 - accuracy: 0.9022 - val_loss: 0.2971 - val_accuracy: 0.8539\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2363 - accuracy: 0.9022 - val_loss: 0.2958 - val_accuracy: 0.8539\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2351 - accuracy: 0.9022 - val_loss: 0.2946 - val_accuracy: 0.8539\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2339 - accuracy: 0.9051 - val_loss: 0.2935 - val_accuracy: 0.8539\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2328 - accuracy: 0.9061 - val_loss: 0.2924 - val_accuracy: 0.8493\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2318 - accuracy: 0.9061 - val_loss: 0.2913 - val_accuracy: 0.8493\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 168us/step - loss: 0.2309 - accuracy: 0.9070 - val_loss: 0.2903 - val_accuracy: 0.8493\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 167us/step - loss: 0.2300 - accuracy: 0.9080 - val_loss: 0.2893 - val_accuracy: 0.8539\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 181us/step - loss: 0.2291 - accuracy: 0.9061 - val_loss: 0.2883 - val_accuracy: 0.8539\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2283 - accuracy: 0.9061 - val_loss: 0.2875 - val_accuracy: 0.8539\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2276 - accuracy: 0.9070 - val_loss: 0.2866 - val_accuracy: 0.8539\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2268 - accuracy: 0.9070 - val_loss: 0.2858 - val_accuracy: 0.8539\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2261 - accuracy: 0.9070 - val_loss: 0.2851 - val_accuracy: 0.8539\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2254 - accuracy: 0.9061 - val_loss: 0.2843 - val_accuracy: 0.8539\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2249 - accuracy: 0.9080 - val_loss: 0.2836 - val_accuracy: 0.8539\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2242 - accuracy: 0.9080 - val_loss: 0.2830 - val_accuracy: 0.8539\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2235 - accuracy: 0.9090 - val_loss: 0.2823 - val_accuracy: 0.8539\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2230 - accuracy: 0.9090 - val_loss: 0.2817 - val_accuracy: 0.8539\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2225 - accuracy: 0.9070 - val_loss: 0.2810 - val_accuracy: 0.8539\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2219 - accuracy: 0.9070 - val_loss: 0.2803 - val_accuracy: 0.8539\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2214 - accuracy: 0.9061 - val_loss: 0.2797 - val_accuracy: 0.8584\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.2208 - accuracy: 0.9070 - val_loss: 0.2790 - val_accuracy: 0.8584\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2204 - accuracy: 0.9070 - val_loss: 0.2784 - val_accuracy: 0.8584\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.2198 - accuracy: 0.9070 - val_loss: 0.2779 - val_accuracy: 0.8584\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.2195 - accuracy: 0.9070 - val_loss: 0.2772 - val_accuracy: 0.8584\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 164us/step - loss: 0.2190 - accuracy: 0.9070 - val_loss: 0.2768 - val_accuracy: 0.8584\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.2185 - accuracy: 0.9070 - val_loss: 0.2763 - val_accuracy: 0.8584\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.2181 - accuracy: 0.9080 - val_loss: 0.2757 - val_accuracy: 0.8584\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2177 - accuracy: 0.9080 - val_loss: 0.2754 - val_accuracy: 0.8584\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2174 - accuracy: 0.9080 - val_loss: 0.2750 - val_accuracy: 0.8584\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2168 - accuracy: 0.9090 - val_loss: 0.2747 - val_accuracy: 0.8584\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2165 - accuracy: 0.9090 - val_loss: 0.2743 - val_accuracy: 0.8584\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2162 - accuracy: 0.9090 - val_loss: 0.2739 - val_accuracy: 0.8584\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2158 - accuracy: 0.9080 - val_loss: 0.2733 - val_accuracy: 0.8584\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.2154 - accuracy: 0.9090 - val_loss: 0.2730 - val_accuracy: 0.8584\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2150 - accuracy: 0.9090 - val_loss: 0.2726 - val_accuracy: 0.8584\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.2147 - accuracy: 0.9090 - val_loss: 0.2724 - val_accuracy: 0.8584\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - ETA: 0s - loss: 0.2357 - accuracy: 0.91 - 0s 152us/step - loss: 0.2143 - accuracy: 0.9090 - val_loss: 0.2719 - val_accuracy: 0.8584\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2140 - accuracy: 0.9090 - val_loss: 0.2715 - val_accuracy: 0.8584\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2138 - accuracy: 0.9090 - val_loss: 0.2714 - val_accuracy: 0.8584\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 198us/step - loss: 0.2133 - accuracy: 0.9090 - val_loss: 0.2711 - val_accuracy: 0.8584\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 222us/step - loss: 0.2130 - accuracy: 0.9090 - val_loss: 0.2708 - val_accuracy: 0.8584\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 186us/step - loss: 0.2127 - accuracy: 0.9090 - val_loss: 0.2705 - val_accuracy: 0.8584\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 175us/step - loss: 0.2124 - accuracy: 0.9090 - val_loss: 0.2703 - val_accuracy: 0.8584\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 201us/step - loss: 0.2121 - accuracy: 0.9100 - val_loss: 0.2701 - val_accuracy: 0.8584\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2118 - accuracy: 0.9100 - val_loss: 0.2697 - val_accuracy: 0.8630\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 182us/step - loss: 0.2115 - accuracy: 0.9090 - val_loss: 0.2693 - val_accuracy: 0.8630\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 164us/step - loss: 0.2111 - accuracy: 0.9119 - val_loss: 0.2689 - val_accuracy: 0.8630\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 191us/step - loss: 0.2109 - accuracy: 0.9110 - val_loss: 0.2684 - val_accuracy: 0.8630\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 197us/step - loss: 0.2106 - accuracy: 0.9129 - val_loss: 0.2680 - val_accuracy: 0.8721\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 168us/step - loss: 0.2103 - accuracy: 0.9110 - val_loss: 0.2680 - val_accuracy: 0.8767\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 193us/step - loss: 0.2100 - accuracy: 0.9100 - val_loss: 0.2677 - val_accuracy: 0.8676\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2097 - accuracy: 0.9110 - val_loss: 0.2675 - val_accuracy: 0.8767\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 227us/step - loss: 0.2094 - accuracy: 0.9100 - val_loss: 0.2674 - val_accuracy: 0.8721\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 197us/step - loss: 0.2092 - accuracy: 0.9129 - val_loss: 0.2670 - val_accuracy: 0.8767\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2088 - accuracy: 0.9119 - val_loss: 0.2668 - val_accuracy: 0.8767\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2086 - accuracy: 0.9129 - val_loss: 0.2665 - val_accuracy: 0.8767\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2083 - accuracy: 0.9110 - val_loss: 0.2665 - val_accuracy: 0.8767\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.2079 - accuracy: 0.9129 - val_loss: 0.2661 - val_accuracy: 0.8767\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.2078 - accuracy: 0.9129 - val_loss: 0.2660 - val_accuracy: 0.8767\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 203us/step - loss: 0.2074 - accuracy: 0.9129 - val_loss: 0.2657 - val_accuracy: 0.8767\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2071 - accuracy: 0.9129 - val_loss: 0.2656 - val_accuracy: 0.8767\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2069 - accuracy: 0.9129 - val_loss: 0.2655 - val_accuracy: 0.8767\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2066 - accuracy: 0.9129 - val_loss: 0.2650 - val_accuracy: 0.8813\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 205us/step - loss: 0.2064 - accuracy: 0.9129 - val_loss: 0.2649 - val_accuracy: 0.8813\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 275us/step - loss: 0.2060 - accuracy: 0.9129 - val_loss: 0.2645 - val_accuracy: 0.8813\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 191us/step - loss: 0.2058 - accuracy: 0.9129 - val_loss: 0.2643 - val_accuracy: 0.8813\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2055 - accuracy: 0.9129 - val_loss: 0.2642 - val_accuracy: 0.8813\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 173us/step - loss: 0.2052 - accuracy: 0.9129 - val_loss: 0.2639 - val_accuracy: 0.8813\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2049 - accuracy: 0.9139 - val_loss: 0.2638 - val_accuracy: 0.8813\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 881us/step - loss: 0.6482 - accuracy: 0.5851 - val_loss: 0.5856 - val_accuracy: 0.6758\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 184us/step - loss: 0.5143 - accuracy: 0.7417 - val_loss: 0.4987 - val_accuracy: 0.7808\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.4417 - accuracy: 0.8268 - val_loss: 0.4467 - val_accuracy: 0.8447\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 169us/step - loss: 0.3955 - accuracy: 0.8640 - val_loss: 0.4121 - val_accuracy: 0.8676\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.3634 - accuracy: 0.8777 - val_loss: 0.3874 - val_accuracy: 0.8676\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 170us/step - loss: 0.3394 - accuracy: 0.8845 - val_loss: 0.3688 - val_accuracy: 0.8676\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.3207 - accuracy: 0.8943 - val_loss: 0.3549 - val_accuracy: 0.8630\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.3061 - accuracy: 0.8992 - val_loss: 0.3442 - val_accuracy: 0.8630\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2944 - accuracy: 0.8982 - val_loss: 0.3355 - val_accuracy: 0.8630\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2846 - accuracy: 0.9002 - val_loss: 0.3288 - val_accuracy: 0.8676\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.2767 - accuracy: 0.9002 - val_loss: 0.3233 - val_accuracy: 0.8676\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 166us/step - loss: 0.2700 - accuracy: 0.9002 - val_loss: 0.3190 - val_accuracy: 0.8630\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 178us/step - loss: 0.2642 - accuracy: 0.9012 - val_loss: 0.3156 - val_accuracy: 0.8630\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2595 - accuracy: 0.9002 - val_loss: 0.3129 - val_accuracy: 0.8630\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2554 - accuracy: 0.9012 - val_loss: 0.3105 - val_accuracy: 0.8630\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2520 - accuracy: 0.9022 - val_loss: 0.3086 - val_accuracy: 0.8630\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 203us/step - loss: 0.2488 - accuracy: 0.9041 - val_loss: 0.3069 - val_accuracy: 0.8630\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 228us/step - loss: 0.2462 - accuracy: 0.9061 - val_loss: 0.3054 - val_accuracy: 0.8630\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 192us/step - loss: 0.2438 - accuracy: 0.9051 - val_loss: 0.3041 - val_accuracy: 0.8630\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 179us/step - loss: 0.2416 - accuracy: 0.9041 - val_loss: 0.3032 - val_accuracy: 0.8630\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2397 - accuracy: 0.9051 - val_loss: 0.3022 - val_accuracy: 0.8630\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 195us/step - loss: 0.2380 - accuracy: 0.9051 - val_loss: 0.3013 - val_accuracy: 0.8630\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.2364 - accuracy: 0.9080 - val_loss: 0.3006 - val_accuracy: 0.8630\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 166us/step - loss: 0.2350 - accuracy: 0.9080 - val_loss: 0.2997 - val_accuracy: 0.8630\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2337 - accuracy: 0.9090 - val_loss: 0.2989 - val_accuracy: 0.8630\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.2326 - accuracy: 0.9090 - val_loss: 0.2981 - val_accuracy: 0.8630\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2314 - accuracy: 0.9080 - val_loss: 0.2973 - val_accuracy: 0.8630\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.2303 - accuracy: 0.9090 - val_loss: 0.2966 - val_accuracy: 0.8630\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 181us/step - loss: 0.2293 - accuracy: 0.9080 - val_loss: 0.2959 - val_accuracy: 0.8676\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.2282 - accuracy: 0.9080 - val_loss: 0.2952 - val_accuracy: 0.8676\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 209us/step - loss: 0.2274 - accuracy: 0.9090 - val_loss: 0.2945 - val_accuracy: 0.8676\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2265 - accuracy: 0.9110 - val_loss: 0.2938 - val_accuracy: 0.8676\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 207us/step - loss: 0.2256 - accuracy: 0.9100 - val_loss: 0.2932 - val_accuracy: 0.8676\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 187us/step - loss: 0.2249 - accuracy: 0.9110 - val_loss: 0.2927 - val_accuracy: 0.8676\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2241 - accuracy: 0.9100 - val_loss: 0.2922 - val_accuracy: 0.8676\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2233 - accuracy: 0.9100 - val_loss: 0.2917 - val_accuracy: 0.8630\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2226 - accuracy: 0.9100 - val_loss: 0.2912 - val_accuracy: 0.8630\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2220 - accuracy: 0.9090 - val_loss: 0.2907 - val_accuracy: 0.8630\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2211 - accuracy: 0.9100 - val_loss: 0.2902 - val_accuracy: 0.8630\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2204 - accuracy: 0.9100 - val_loss: 0.2899 - val_accuracy: 0.8630\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2198 - accuracy: 0.9090 - val_loss: 0.2893 - val_accuracy: 0.8630\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2191 - accuracy: 0.9090 - val_loss: 0.2889 - val_accuracy: 0.8630\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2186 - accuracy: 0.9090 - val_loss: 0.2884 - val_accuracy: 0.8630\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2180 - accuracy: 0.9100 - val_loss: 0.2879 - val_accuracy: 0.8630\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2172 - accuracy: 0.9110 - val_loss: 0.2875 - val_accuracy: 0.8630\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2166 - accuracy: 0.9100 - val_loss: 0.2868 - val_accuracy: 0.8630\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2160 - accuracy: 0.9119 - val_loss: 0.2864 - val_accuracy: 0.8630\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2156 - accuracy: 0.9119 - val_loss: 0.2862 - val_accuracy: 0.8630\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2149 - accuracy: 0.9110 - val_loss: 0.2857 - val_accuracy: 0.8721\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2144 - accuracy: 0.9119 - val_loss: 0.2851 - val_accuracy: 0.8721\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2138 - accuracy: 0.9129 - val_loss: 0.2846 - val_accuracy: 0.8721\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 207us/step - loss: 0.2131 - accuracy: 0.9129 - val_loss: 0.2841 - val_accuracy: 0.8721\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2127 - accuracy: 0.9119 - val_loss: 0.2838 - val_accuracy: 0.8676\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2121 - accuracy: 0.9129 - val_loss: 0.2835 - val_accuracy: 0.8676\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2117 - accuracy: 0.9129 - val_loss: 0.2830 - val_accuracy: 0.8721\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2111 - accuracy: 0.9129 - val_loss: 0.2826 - val_accuracy: 0.8676\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.2105 - accuracy: 0.9129 - val_loss: 0.2821 - val_accuracy: 0.8721\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2101 - accuracy: 0.9129 - val_loss: 0.2818 - val_accuracy: 0.8721\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2097 - accuracy: 0.9129 - val_loss: 0.2815 - val_accuracy: 0.8676\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2092 - accuracy: 0.9119 - val_loss: 0.2812 - val_accuracy: 0.8676\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2086 - accuracy: 0.9119 - val_loss: 0.2808 - val_accuracy: 0.8676\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2081 - accuracy: 0.9129 - val_loss: 0.2804 - val_accuracy: 0.8676\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2077 - accuracy: 0.9119 - val_loss: 0.2798 - val_accuracy: 0.8721\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2073 - accuracy: 0.9119 - val_loss: 0.2795 - val_accuracy: 0.8721\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.2068 - accuracy: 0.9119 - val_loss: 0.2792 - val_accuracy: 0.8721\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.2064 - accuracy: 0.9129 - val_loss: 0.2789 - val_accuracy: 0.8676\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2060 - accuracy: 0.9119 - val_loss: 0.2785 - val_accuracy: 0.8676\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2057 - accuracy: 0.9129 - val_loss: 0.2782 - val_accuracy: 0.8676\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2052 - accuracy: 0.9149 - val_loss: 0.2779 - val_accuracy: 0.8676\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 168us/step - loss: 0.2048 - accuracy: 0.9129 - val_loss: 0.2776 - val_accuracy: 0.8676\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 206us/step - loss: 0.2042 - accuracy: 0.9139 - val_loss: 0.2772 - val_accuracy: 0.8676\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2039 - accuracy: 0.9129 - val_loss: 0.2768 - val_accuracy: 0.8721\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 164us/step - loss: 0.2035 - accuracy: 0.9139 - val_loss: 0.2765 - val_accuracy: 0.8721\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 190us/step - loss: 0.2031 - accuracy: 0.9149 - val_loss: 0.2762 - val_accuracy: 0.8721\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2026 - accuracy: 0.9149 - val_loss: 0.2760 - val_accuracy: 0.8721\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2024 - accuracy: 0.9149 - val_loss: 0.2757 - val_accuracy: 0.8721\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2021 - accuracy: 0.9149 - val_loss: 0.2754 - val_accuracy: 0.8721\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.2016 - accuracy: 0.9139 - val_loss: 0.2751 - val_accuracy: 0.8721\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2012 - accuracy: 0.9139 - val_loss: 0.2749 - val_accuracy: 0.8721\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2008 - accuracy: 0.9139 - val_loss: 0.2748 - val_accuracy: 0.8721\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2004 - accuracy: 0.9149 - val_loss: 0.2744 - val_accuracy: 0.8813\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2001 - accuracy: 0.9139 - val_loss: 0.2742 - val_accuracy: 0.8813\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.1999 - accuracy: 0.9149 - val_loss: 0.2739 - val_accuracy: 0.8813\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.1993 - accuracy: 0.9149 - val_loss: 0.2737 - val_accuracy: 0.8813\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.1989 - accuracy: 0.9139 - val_loss: 0.2734 - val_accuracy: 0.8813\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.1987 - accuracy: 0.9149 - val_loss: 0.2732 - val_accuracy: 0.8813\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.1981 - accuracy: 0.9149 - val_loss: 0.2727 - val_accuracy: 0.8813\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.1979 - accuracy: 0.9149 - val_loss: 0.2726 - val_accuracy: 0.8813\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.1974 - accuracy: 0.9168 - val_loss: 0.2724 - val_accuracy: 0.8767\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.1971 - accuracy: 0.9159 - val_loss: 0.2723 - val_accuracy: 0.8813\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.1967 - accuracy: 0.9149 - val_loss: 0.2718 - val_accuracy: 0.8813\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.1964 - accuracy: 0.9159 - val_loss: 0.2717 - val_accuracy: 0.8813\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.1961 - accuracy: 0.9139 - val_loss: 0.2712 - val_accuracy: 0.8813\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.1957 - accuracy: 0.9149 - val_loss: 0.2710 - val_accuracy: 0.8813\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.1955 - accuracy: 0.9139 - val_loss: 0.2708 - val_accuracy: 0.8813\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.1949 - accuracy: 0.9139 - val_loss: 0.2707 - val_accuracy: 0.8813\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.1946 - accuracy: 0.9129 - val_loss: 0.2705 - val_accuracy: 0.8813\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.1941 - accuracy: 0.9149 - val_loss: 0.2704 - val_accuracy: 0.8813\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.1938 - accuracy: 0.9139 - val_loss: 0.2701 - val_accuracy: 0.8813\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.1934 - accuracy: 0.9139 - val_loss: 0.2697 - val_accuracy: 0.8813\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 783us/step - loss: 0.6888 - accuracy: 0.5254 - val_loss: 0.6648 - val_accuracy: 0.6301\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.6428 - accuracy: 0.6879 - val_loss: 0.6283 - val_accuracy: 0.7123\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.6036 - accuracy: 0.7573 - val_loss: 0.5948 - val_accuracy: 0.7534\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.5672 - accuracy: 0.7886 - val_loss: 0.5632 - val_accuracy: 0.7945\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.5326 - accuracy: 0.8278 - val_loss: 0.5327 - val_accuracy: 0.8174\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.4993 - accuracy: 0.8503 - val_loss: 0.5037 - val_accuracy: 0.8356\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.4678 - accuracy: 0.8679 - val_loss: 0.4764 - val_accuracy: 0.8447\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.4382 - accuracy: 0.8748 - val_loss: 0.4512 - val_accuracy: 0.8539\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.4109 - accuracy: 0.8826 - val_loss: 0.4282 - val_accuracy: 0.8630\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.3864 - accuracy: 0.8885 - val_loss: 0.4080 - val_accuracy: 0.8721\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.3650 - accuracy: 0.8904 - val_loss: 0.3907 - val_accuracy: 0.8721\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.3465 - accuracy: 0.8914 - val_loss: 0.3758 - val_accuracy: 0.8630\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 170us/step - loss: 0.3306 - accuracy: 0.8904 - val_loss: 0.3635 - val_accuracy: 0.8539\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 157us/step - loss: 0.3170 - accuracy: 0.8953 - val_loss: 0.3531 - val_accuracy: 0.8493\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.3056 - accuracy: 0.8963 - val_loss: 0.3442 - val_accuracy: 0.8493\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2957 - accuracy: 0.8953 - val_loss: 0.3366 - val_accuracy: 0.8493\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2873 - accuracy: 0.8963 - val_loss: 0.3304 - val_accuracy: 0.8493\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 189us/step - loss: 0.2802 - accuracy: 0.8973 - val_loss: 0.3250 - val_accuracy: 0.8539\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 183us/step - loss: 0.2740 - accuracy: 0.8973 - val_loss: 0.3205 - val_accuracy: 0.8539\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 215us/step - loss: 0.2686 - accuracy: 0.8963 - val_loss: 0.3165 - val_accuracy: 0.8539\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2637 - accuracy: 0.9022 - val_loss: 0.3132 - val_accuracy: 0.8539\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2596 - accuracy: 0.9022 - val_loss: 0.3101 - val_accuracy: 0.8539\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2559 - accuracy: 0.9031 - val_loss: 0.3076 - val_accuracy: 0.8539\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2527 - accuracy: 0.9051 - val_loss: 0.3052 - val_accuracy: 0.8539\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 200us/step - loss: 0.2497 - accuracy: 0.9041 - val_loss: 0.3032 - val_accuracy: 0.8539\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2471 - accuracy: 0.9061 - val_loss: 0.3013 - val_accuracy: 0.8584\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.2447 - accuracy: 0.9080 - val_loss: 0.2998 - val_accuracy: 0.8584\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 214us/step - loss: 0.2426 - accuracy: 0.9080 - val_loss: 0.2984 - val_accuracy: 0.8584\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 178us/step - loss: 0.2406 - accuracy: 0.9070 - val_loss: 0.2970 - val_accuracy: 0.8584\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.2388 - accuracy: 0.9080 - val_loss: 0.2959 - val_accuracy: 0.8584\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2373 - accuracy: 0.9070 - val_loss: 0.2948 - val_accuracy: 0.8584\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2357 - accuracy: 0.9070 - val_loss: 0.2937 - val_accuracy: 0.8584\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2344 - accuracy: 0.9070 - val_loss: 0.2927 - val_accuracy: 0.8584\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2331 - accuracy: 0.9070 - val_loss: 0.2919 - val_accuracy: 0.8584\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2320 - accuracy: 0.9070 - val_loss: 0.2910 - val_accuracy: 0.8584\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.2310 - accuracy: 0.9070 - val_loss: 0.2902 - val_accuracy: 0.8584\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.2300 - accuracy: 0.9061 - val_loss: 0.2896 - val_accuracy: 0.8584\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2290 - accuracy: 0.9080 - val_loss: 0.2890 - val_accuracy: 0.8584\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2282 - accuracy: 0.9070 - val_loss: 0.2883 - val_accuracy: 0.8584\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2274 - accuracy: 0.9090 - val_loss: 0.2877 - val_accuracy: 0.8584\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2267 - accuracy: 0.9090 - val_loss: 0.2870 - val_accuracy: 0.8584\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2259 - accuracy: 0.9090 - val_loss: 0.2865 - val_accuracy: 0.8584\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2254 - accuracy: 0.9110 - val_loss: 0.2859 - val_accuracy: 0.8630\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2247 - accuracy: 0.9100 - val_loss: 0.2855 - val_accuracy: 0.8630\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2241 - accuracy: 0.9100 - val_loss: 0.2849 - val_accuracy: 0.8630\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2235 - accuracy: 0.9100 - val_loss: 0.2843 - val_accuracy: 0.8630\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2229 - accuracy: 0.9090 - val_loss: 0.2839 - val_accuracy: 0.8630\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2225 - accuracy: 0.9090 - val_loss: 0.2835 - val_accuracy: 0.8676\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2218 - accuracy: 0.9090 - val_loss: 0.2831 - val_accuracy: 0.8676\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2212 - accuracy: 0.9100 - val_loss: 0.2827 - val_accuracy: 0.8676\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2208 - accuracy: 0.9100 - val_loss: 0.2824 - val_accuracy: 0.8676\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2202 - accuracy: 0.9100 - val_loss: 0.2819 - val_accuracy: 0.8676\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.2197 - accuracy: 0.9100 - val_loss: 0.2815 - val_accuracy: 0.8676\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2193 - accuracy: 0.9110 - val_loss: 0.2810 - val_accuracy: 0.8676\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2189 - accuracy: 0.9100 - val_loss: 0.2805 - val_accuracy: 0.8676\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 0.2184 - accuracy: 0.9110 - val_loss: 0.2802 - val_accuracy: 0.8676\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2180 - accuracy: 0.9119 - val_loss: 0.2799 - val_accuracy: 0.8721\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2174 - accuracy: 0.9110 - val_loss: 0.2795 - val_accuracy: 0.8721\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2170 - accuracy: 0.9100 - val_loss: 0.2790 - val_accuracy: 0.8721\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2165 - accuracy: 0.9119 - val_loss: 0.2785 - val_accuracy: 0.8721\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2161 - accuracy: 0.9110 - val_loss: 0.2781 - val_accuracy: 0.8676\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 153us/step - loss: 0.2156 - accuracy: 0.9110 - val_loss: 0.2777 - val_accuracy: 0.8676\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2152 - accuracy: 0.9129 - val_loss: 0.2775 - val_accuracy: 0.8676\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2148 - accuracy: 0.9100 - val_loss: 0.2772 - val_accuracy: 0.8676\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2144 - accuracy: 0.9100 - val_loss: 0.2769 - val_accuracy: 0.8721\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 170us/step - loss: 0.2140 - accuracy: 0.9100 - val_loss: 0.2765 - val_accuracy: 0.8721\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2137 - accuracy: 0.9090 - val_loss: 0.2762 - val_accuracy: 0.8721\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2133 - accuracy: 0.9090 - val_loss: 0.2759 - val_accuracy: 0.8721\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2129 - accuracy: 0.9110 - val_loss: 0.2758 - val_accuracy: 0.8721\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2126 - accuracy: 0.9110 - val_loss: 0.2756 - val_accuracy: 0.8721\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2122 - accuracy: 0.9100 - val_loss: 0.2753 - val_accuracy: 0.8721\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2118 - accuracy: 0.9090 - val_loss: 0.2750 - val_accuracy: 0.8721\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2113 - accuracy: 0.9100 - val_loss: 0.2748 - val_accuracy: 0.8721\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2111 - accuracy: 0.9080 - val_loss: 0.2745 - val_accuracy: 0.8721\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.2107 - accuracy: 0.9090 - val_loss: 0.2742 - val_accuracy: 0.8676\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2103 - accuracy: 0.9090 - val_loss: 0.2738 - val_accuracy: 0.8721\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2101 - accuracy: 0.9110 - val_loss: 0.2736 - val_accuracy: 0.8721\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.2096 - accuracy: 0.9090 - val_loss: 0.2733 - val_accuracy: 0.8721\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2093 - accuracy: 0.9090 - val_loss: 0.2732 - val_accuracy: 0.8721\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.2090 - accuracy: 0.9090 - val_loss: 0.2732 - val_accuracy: 0.8721\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2087 - accuracy: 0.9110 - val_loss: 0.2730 - val_accuracy: 0.8721\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.2083 - accuracy: 0.9100 - val_loss: 0.2727 - val_accuracy: 0.8721\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2080 - accuracy: 0.9100 - val_loss: 0.2726 - val_accuracy: 0.8721\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 170us/step - loss: 0.2077 - accuracy: 0.9090 - val_loss: 0.2723 - val_accuracy: 0.8721\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 166us/step - loss: 0.2073 - accuracy: 0.9090 - val_loss: 0.2723 - val_accuracy: 0.8721\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 177us/step - loss: 0.2071 - accuracy: 0.9110 - val_loss: 0.2721 - val_accuracy: 0.8721\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 168us/step - loss: 0.2069 - accuracy: 0.9090 - val_loss: 0.2721 - val_accuracy: 0.8721\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 169us/step - loss: 0.2065 - accuracy: 0.9090 - val_loss: 0.2719 - val_accuracy: 0.8721\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 168us/step - loss: 0.2063 - accuracy: 0.9100 - val_loss: 0.2716 - val_accuracy: 0.8721\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 186us/step - loss: 0.2058 - accuracy: 0.9110 - val_loss: 0.2716 - val_accuracy: 0.8721\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2055 - accuracy: 0.9110 - val_loss: 0.2715 - val_accuracy: 0.8721\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 176us/step - loss: 0.2054 - accuracy: 0.9100 - val_loss: 0.2713 - val_accuracy: 0.8721\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2051 - accuracy: 0.9110 - val_loss: 0.2710 - val_accuracy: 0.8721\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2047 - accuracy: 0.9100 - val_loss: 0.2708 - val_accuracy: 0.8721\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 163us/step - loss: 0.2045 - accuracy: 0.9110 - val_loss: 0.2707 - val_accuracy: 0.8721\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2041 - accuracy: 0.9100 - val_loss: 0.2705 - val_accuracy: 0.8721\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2039 - accuracy: 0.9119 - val_loss: 0.2704 - val_accuracy: 0.8767\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2035 - accuracy: 0.9110 - val_loss: 0.2702 - val_accuracy: 0.8767\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2033 - accuracy: 0.9110 - val_loss: 0.2699 - val_accuracy: 0.8767\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2029 - accuracy: 0.9129 - val_loss: 0.2698 - val_accuracy: 0.8767\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 793us/step - loss: 0.7587 - accuracy: 0.3366 - val_loss: 0.7022 - val_accuracy: 0.4658\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.6688 - accuracy: 0.5323 - val_loss: 0.6333 - val_accuracy: 0.6575\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 166us/step - loss: 0.6033 - accuracy: 0.7055 - val_loss: 0.5788 - val_accuracy: 0.7763\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.5509 - accuracy: 0.8170 - val_loss: 0.5342 - val_accuracy: 0.8402\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.5056 - accuracy: 0.8601 - val_loss: 0.4948 - val_accuracy: 0.8311\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 174us/step - loss: 0.4645 - accuracy: 0.8728 - val_loss: 0.4606 - val_accuracy: 0.8356\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.4281 - accuracy: 0.8777 - val_loss: 0.4318 - val_accuracy: 0.8402\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.3968 - accuracy: 0.8757 - val_loss: 0.4077 - val_accuracy: 0.8402\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.3703 - accuracy: 0.8816 - val_loss: 0.3880 - val_accuracy: 0.8539\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.3484 - accuracy: 0.8826 - val_loss: 0.3720 - val_accuracy: 0.8447\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.3304 - accuracy: 0.8845 - val_loss: 0.3592 - val_accuracy: 0.8447\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.3157 - accuracy: 0.8885 - val_loss: 0.3492 - val_accuracy: 0.8447\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 167us/step - loss: 0.3037 - accuracy: 0.8914 - val_loss: 0.3413 - val_accuracy: 0.8493\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2939 - accuracy: 0.8953 - val_loss: 0.3346 - val_accuracy: 0.8584\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2858 - accuracy: 0.8982 - val_loss: 0.3293 - val_accuracy: 0.8584\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2789 - accuracy: 0.8982 - val_loss: 0.3250 - val_accuracy: 0.8539\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2731 - accuracy: 0.8982 - val_loss: 0.3213 - val_accuracy: 0.8584\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 183us/step - loss: 0.2683 - accuracy: 0.9012 - val_loss: 0.3182 - val_accuracy: 0.8584\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2642 - accuracy: 0.8992 - val_loss: 0.3154 - val_accuracy: 0.8584\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2605 - accuracy: 0.9002 - val_loss: 0.3129 - val_accuracy: 0.8584\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2574 - accuracy: 0.9022 - val_loss: 0.3107 - val_accuracy: 0.8584\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2547 - accuracy: 0.9051 - val_loss: 0.3088 - val_accuracy: 0.8584\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2522 - accuracy: 0.9051 - val_loss: 0.3070 - val_accuracy: 0.8584\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2499 - accuracy: 0.9031 - val_loss: 0.3053 - val_accuracy: 0.8584\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2479 - accuracy: 0.9070 - val_loss: 0.3037 - val_accuracy: 0.8539\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 169us/step - loss: 0.2460 - accuracy: 0.9080 - val_loss: 0.3022 - val_accuracy: 0.8539\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.2445 - accuracy: 0.9080 - val_loss: 0.3007 - val_accuracy: 0.8539\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2429 - accuracy: 0.9090 - val_loss: 0.2995 - val_accuracy: 0.8539\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2415 - accuracy: 0.9100 - val_loss: 0.2983 - val_accuracy: 0.8584\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.2403 - accuracy: 0.9100 - val_loss: 0.2972 - val_accuracy: 0.8584\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2391 - accuracy: 0.9100 - val_loss: 0.2961 - val_accuracy: 0.8584\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2380 - accuracy: 0.9100 - val_loss: 0.2950 - val_accuracy: 0.8584\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.2370 - accuracy: 0.9100 - val_loss: 0.2939 - val_accuracy: 0.8584\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2360 - accuracy: 0.9110 - val_loss: 0.2928 - val_accuracy: 0.8584\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2349 - accuracy: 0.9119 - val_loss: 0.2918 - val_accuracy: 0.8584\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2340 - accuracy: 0.9090 - val_loss: 0.2907 - val_accuracy: 0.8584\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2332 - accuracy: 0.9119 - val_loss: 0.2897 - val_accuracy: 0.8584\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.2324 - accuracy: 0.9090 - val_loss: 0.2888 - val_accuracy: 0.8584\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2316 - accuracy: 0.9110 - val_loss: 0.2880 - val_accuracy: 0.8584\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2309 - accuracy: 0.9100 - val_loss: 0.2871 - val_accuracy: 0.8584\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2302 - accuracy: 0.9100 - val_loss: 0.2863 - val_accuracy: 0.8584\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2294 - accuracy: 0.9100 - val_loss: 0.2856 - val_accuracy: 0.8584\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2287 - accuracy: 0.9100 - val_loss: 0.2848 - val_accuracy: 0.8584\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2283 - accuracy: 0.9090 - val_loss: 0.2841 - val_accuracy: 0.8584\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2275 - accuracy: 0.9090 - val_loss: 0.2832 - val_accuracy: 0.8584\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2269 - accuracy: 0.9100 - val_loss: 0.2826 - val_accuracy: 0.8584\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2265 - accuracy: 0.9100 - val_loss: 0.2820 - val_accuracy: 0.8584\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2257 - accuracy: 0.9110 - val_loss: 0.2815 - val_accuracy: 0.8584\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2252 - accuracy: 0.9100 - val_loss: 0.2810 - val_accuracy: 0.8584\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 158us/step - loss: 0.2247 - accuracy: 0.9119 - val_loss: 0.2803 - val_accuracy: 0.8584\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2241 - accuracy: 0.9110 - val_loss: 0.2794 - val_accuracy: 0.8584\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2237 - accuracy: 0.9110 - val_loss: 0.2788 - val_accuracy: 0.8584\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2230 - accuracy: 0.9100 - val_loss: 0.2784 - val_accuracy: 0.8584\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2226 - accuracy: 0.9110 - val_loss: 0.2778 - val_accuracy: 0.8630\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2221 - accuracy: 0.9100 - val_loss: 0.2774 - val_accuracy: 0.8630\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2217 - accuracy: 0.9100 - val_loss: 0.2769 - val_accuracy: 0.8630\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2213 - accuracy: 0.9100 - val_loss: 0.2764 - val_accuracy: 0.8630\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2208 - accuracy: 0.9100 - val_loss: 0.2760 - val_accuracy: 0.8630\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2204 - accuracy: 0.9100 - val_loss: 0.2758 - val_accuracy: 0.8630\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2200 - accuracy: 0.9110 - val_loss: 0.2753 - val_accuracy: 0.8630\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2195 - accuracy: 0.9119 - val_loss: 0.2748 - val_accuracy: 0.8630\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2192 - accuracy: 0.9100 - val_loss: 0.2745 - val_accuracy: 0.8630\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2187 - accuracy: 0.9129 - val_loss: 0.2739 - val_accuracy: 0.8630\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2183 - accuracy: 0.9129 - val_loss: 0.2735 - val_accuracy: 0.8630\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2179 - accuracy: 0.9119 - val_loss: 0.2732 - val_accuracy: 0.8630\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2176 - accuracy: 0.9139 - val_loss: 0.2729 - val_accuracy: 0.8630\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 186us/step - loss: 0.2172 - accuracy: 0.9129 - val_loss: 0.2726 - val_accuracy: 0.8630\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2168 - accuracy: 0.9129 - val_loss: 0.2722 - val_accuracy: 0.8630\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2164 - accuracy: 0.9129 - val_loss: 0.2719 - val_accuracy: 0.8630\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.2161 - accuracy: 0.9129 - val_loss: 0.2717 - val_accuracy: 0.8630\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 177us/step - loss: 0.2157 - accuracy: 0.9129 - val_loss: 0.2714 - val_accuracy: 0.8630\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 201us/step - loss: 0.2154 - accuracy: 0.9129 - val_loss: 0.2712 - val_accuracy: 0.8630\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2150 - accuracy: 0.9149 - val_loss: 0.2709 - val_accuracy: 0.8676\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2148 - accuracy: 0.9149 - val_loss: 0.2707 - val_accuracy: 0.8676\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2143 - accuracy: 0.9139 - val_loss: 0.2703 - val_accuracy: 0.8676\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2140 - accuracy: 0.9149 - val_loss: 0.2700 - val_accuracy: 0.8676\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 154us/step - loss: 0.2137 - accuracy: 0.9129 - val_loss: 0.2699 - val_accuracy: 0.8676\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2134 - accuracy: 0.9159 - val_loss: 0.2696 - val_accuracy: 0.8676\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.2131 - accuracy: 0.9149 - val_loss: 0.2695 - val_accuracy: 0.8676\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2128 - accuracy: 0.9139 - val_loss: 0.2695 - val_accuracy: 0.8676\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 149us/step - loss: 0.2124 - accuracy: 0.9139 - val_loss: 0.2692 - val_accuracy: 0.8676\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2121 - accuracy: 0.9149 - val_loss: 0.2688 - val_accuracy: 0.8676\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 466us/step - loss: 0.2118 - accuracy: 0.9159 - val_loss: 0.2687 - val_accuracy: 0.8676\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 176us/step - loss: 0.2114 - accuracy: 0.9149 - val_loss: 0.2687 - val_accuracy: 0.8676\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2110 - accuracy: 0.9168 - val_loss: 0.2683 - val_accuracy: 0.8676\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2109 - accuracy: 0.9129 - val_loss: 0.2684 - val_accuracy: 0.8676\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 159us/step - loss: 0.2106 - accuracy: 0.9129 - val_loss: 0.2684 - val_accuracy: 0.8676\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2103 - accuracy: 0.9149 - val_loss: 0.2681 - val_accuracy: 0.8721\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2099 - accuracy: 0.9149 - val_loss: 0.2679 - val_accuracy: 0.8721\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2096 - accuracy: 0.9129 - val_loss: 0.2677 - val_accuracy: 0.8721\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2092 - accuracy: 0.9139 - val_loss: 0.2675 - val_accuracy: 0.8721\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2089 - accuracy: 0.9139 - val_loss: 0.2674 - val_accuracy: 0.8721\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2086 - accuracy: 0.9139 - val_loss: 0.2671 - val_accuracy: 0.8721\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2083 - accuracy: 0.9149 - val_loss: 0.2670 - val_accuracy: 0.8721\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2080 - accuracy: 0.9149 - val_loss: 0.2668 - val_accuracy: 0.8721\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2077 - accuracy: 0.9139 - val_loss: 0.2668 - val_accuracy: 0.8721\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2073 - accuracy: 0.9139 - val_loss: 0.2667 - val_accuracy: 0.8721\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2070 - accuracy: 0.9119 - val_loss: 0.2663 - val_accuracy: 0.8721\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2067 - accuracy: 0.9139 - val_loss: 0.2661 - val_accuracy: 0.8721\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2064 - accuracy: 0.9149 - val_loss: 0.2660 - val_accuracy: 0.8721\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 907us/step - loss: 0.6776 - accuracy: 0.4491 - val_loss: 0.6405 - val_accuracy: 0.5708\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 192us/step - loss: 0.6192 - accuracy: 0.6301 - val_loss: 0.5951 - val_accuracy: 0.7260\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 185us/step - loss: 0.5729 - accuracy: 0.7691 - val_loss: 0.5578 - val_accuracy: 0.8219\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.5333 - accuracy: 0.8307 - val_loss: 0.5247 - val_accuracy: 0.8219\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 181us/step - loss: 0.4985 - accuracy: 0.8493 - val_loss: 0.4955 - val_accuracy: 0.8219\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.4672 - accuracy: 0.8542 - val_loss: 0.4691 - val_accuracy: 0.8356\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.4391 - accuracy: 0.8650 - val_loss: 0.4457 - val_accuracy: 0.8447\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.4140 - accuracy: 0.8669 - val_loss: 0.4253 - val_accuracy: 0.8493\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.3921 - accuracy: 0.8718 - val_loss: 0.4076 - val_accuracy: 0.8539\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.3727 - accuracy: 0.8738 - val_loss: 0.3924 - val_accuracy: 0.8539\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.3560 - accuracy: 0.8748 - val_loss: 0.3794 - val_accuracy: 0.8584\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.3414 - accuracy: 0.8787 - val_loss: 0.3682 - val_accuracy: 0.8630\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.3292 - accuracy: 0.8796 - val_loss: 0.3593 - val_accuracy: 0.8630\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.3186 - accuracy: 0.8816 - val_loss: 0.3517 - val_accuracy: 0.8676\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.3094 - accuracy: 0.8855 - val_loss: 0.3452 - val_accuracy: 0.8676\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.3015 - accuracy: 0.8894 - val_loss: 0.3397 - val_accuracy: 0.8676\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2945 - accuracy: 0.8933 - val_loss: 0.3349 - val_accuracy: 0.8630\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2883 - accuracy: 0.8943 - val_loss: 0.3308 - val_accuracy: 0.8630\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2830 - accuracy: 0.8953 - val_loss: 0.3273 - val_accuracy: 0.8630\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2782 - accuracy: 0.8953 - val_loss: 0.3243 - val_accuracy: 0.8630\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 171us/step - loss: 0.2740 - accuracy: 0.8992 - val_loss: 0.3214 - val_accuracy: 0.8584\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 161us/step - loss: 0.2701 - accuracy: 0.9012 - val_loss: 0.3189 - val_accuracy: 0.8630\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 164us/step - loss: 0.2667 - accuracy: 0.9022 - val_loss: 0.3165 - val_accuracy: 0.8630\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2637 - accuracy: 0.9061 - val_loss: 0.3147 - val_accuracy: 0.8630\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2609 - accuracy: 0.9070 - val_loss: 0.3128 - val_accuracy: 0.8539\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 156us/step - loss: 0.2585 - accuracy: 0.9051 - val_loss: 0.3110 - val_accuracy: 0.8539\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.2562 - accuracy: 0.9041 - val_loss: 0.3095 - val_accuracy: 0.8539\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2541 - accuracy: 0.9061 - val_loss: 0.3082 - val_accuracy: 0.8539\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 152us/step - loss: 0.2522 - accuracy: 0.9070 - val_loss: 0.3068 - val_accuracy: 0.8539\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2505 - accuracy: 0.9051 - val_loss: 0.3054 - val_accuracy: 0.8539\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2486 - accuracy: 0.9070 - val_loss: 0.3041 - val_accuracy: 0.8539\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.2471 - accuracy: 0.9051 - val_loss: 0.3032 - val_accuracy: 0.8539\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2458 - accuracy: 0.9061 - val_loss: 0.3021 - val_accuracy: 0.8539\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2444 - accuracy: 0.9070 - val_loss: 0.3011 - val_accuracy: 0.8539\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2431 - accuracy: 0.9090 - val_loss: 0.3002 - val_accuracy: 0.8539\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 165us/step - loss: 0.2419 - accuracy: 0.9100 - val_loss: 0.2994 - val_accuracy: 0.8539\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2408 - accuracy: 0.9090 - val_loss: 0.2987 - val_accuracy: 0.8584\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 183us/step - loss: 0.2398 - accuracy: 0.9090 - val_loss: 0.2979 - val_accuracy: 0.8584\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 197us/step - loss: 0.2388 - accuracy: 0.9100 - val_loss: 0.2972 - val_accuracy: 0.8584\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 185us/step - loss: 0.2377 - accuracy: 0.9090 - val_loss: 0.2964 - val_accuracy: 0.8630\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2368 - accuracy: 0.9090 - val_loss: 0.2957 - val_accuracy: 0.8630\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2359 - accuracy: 0.9100 - val_loss: 0.2951 - val_accuracy: 0.8630\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2351 - accuracy: 0.9110 - val_loss: 0.2945 - val_accuracy: 0.8721\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2341 - accuracy: 0.9090 - val_loss: 0.2938 - val_accuracy: 0.8721\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2333 - accuracy: 0.9119 - val_loss: 0.2932 - val_accuracy: 0.8721\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2325 - accuracy: 0.9129 - val_loss: 0.2928 - val_accuracy: 0.8721\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2318 - accuracy: 0.9110 - val_loss: 0.2923 - val_accuracy: 0.8721\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.2310 - accuracy: 0.9119 - val_loss: 0.2918 - val_accuracy: 0.8721\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2302 - accuracy: 0.9119 - val_loss: 0.2913 - val_accuracy: 0.8721\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.2296 - accuracy: 0.9119 - val_loss: 0.2908 - val_accuracy: 0.8721\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2290 - accuracy: 0.9119 - val_loss: 0.2903 - val_accuracy: 0.8721\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.2282 - accuracy: 0.9129 - val_loss: 0.2900 - val_accuracy: 0.8721\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2278 - accuracy: 0.9129 - val_loss: 0.2895 - val_accuracy: 0.8721\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2271 - accuracy: 0.9129 - val_loss: 0.2890 - val_accuracy: 0.8767\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2264 - accuracy: 0.9129 - val_loss: 0.2885 - val_accuracy: 0.8767\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2258 - accuracy: 0.9119 - val_loss: 0.2878 - val_accuracy: 0.8767\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2252 - accuracy: 0.9119 - val_loss: 0.2872 - val_accuracy: 0.8767\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2245 - accuracy: 0.9119 - val_loss: 0.2867 - val_accuracy: 0.8767\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2240 - accuracy: 0.9119 - val_loss: 0.2861 - val_accuracy: 0.8767\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2234 - accuracy: 0.9129 - val_loss: 0.2856 - val_accuracy: 0.8767\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2228 - accuracy: 0.9119 - val_loss: 0.2851 - val_accuracy: 0.8767\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2222 - accuracy: 0.9129 - val_loss: 0.2847 - val_accuracy: 0.8767\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 177us/step - loss: 0.2215 - accuracy: 0.9129 - val_loss: 0.2842 - val_accuracy: 0.8767\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 279us/step - loss: 0.2211 - accuracy: 0.9119 - val_loss: 0.2839 - val_accuracy: 0.8767\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 208us/step - loss: 0.2206 - accuracy: 0.9129 - val_loss: 0.2835 - val_accuracy: 0.8767\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 470us/step - loss: 0.2201 - accuracy: 0.9119 - val_loss: 0.2832 - val_accuracy: 0.8767\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.2195 - accuracy: 0.9129 - val_loss: 0.2826 - val_accuracy: 0.8767\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2192 - accuracy: 0.9139 - val_loss: 0.2822 - val_accuracy: 0.8767\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2186 - accuracy: 0.9149 - val_loss: 0.2818 - val_accuracy: 0.8767\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2180 - accuracy: 0.9129 - val_loss: 0.2814 - val_accuracy: 0.8767\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2175 - accuracy: 0.9139 - val_loss: 0.2811 - val_accuracy: 0.8767\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.2171 - accuracy: 0.9149 - val_loss: 0.2807 - val_accuracy: 0.8767\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2166 - accuracy: 0.9159 - val_loss: 0.2804 - val_accuracy: 0.8767\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.2162 - accuracy: 0.9129 - val_loss: 0.2800 - val_accuracy: 0.8767\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2157 - accuracy: 0.9159 - val_loss: 0.2799 - val_accuracy: 0.8813\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2153 - accuracy: 0.9139 - val_loss: 0.2795 - val_accuracy: 0.8813\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2149 - accuracy: 0.9129 - val_loss: 0.2790 - val_accuracy: 0.8813\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.2145 - accuracy: 0.9159 - val_loss: 0.2790 - val_accuracy: 0.8813\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2140 - accuracy: 0.9159 - val_loss: 0.2787 - val_accuracy: 0.8813\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2137 - accuracy: 0.9159 - val_loss: 0.2787 - val_accuracy: 0.8813\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2133 - accuracy: 0.9168 - val_loss: 0.2783 - val_accuracy: 0.8813\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2126 - accuracy: 0.9159 - val_loss: 0.2780 - val_accuracy: 0.8813\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2124 - accuracy: 0.9159 - val_loss: 0.2776 - val_accuracy: 0.8813\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2120 - accuracy: 0.9159 - val_loss: 0.2771 - val_accuracy: 0.8813\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2115 - accuracy: 0.9159 - val_loss: 0.2768 - val_accuracy: 0.8813\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.2111 - accuracy: 0.9168 - val_loss: 0.2766 - val_accuracy: 0.8813\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 162us/step - loss: 0.2108 - accuracy: 0.9149 - val_loss: 0.2763 - val_accuracy: 0.8813\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 173us/step - loss: 0.2103 - accuracy: 0.9159 - val_loss: 0.2762 - val_accuracy: 0.8813\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 173us/step - loss: 0.2099 - accuracy: 0.9149 - val_loss: 0.2761 - val_accuracy: 0.8767\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2095 - accuracy: 0.9159 - val_loss: 0.2759 - val_accuracy: 0.8767\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 209us/step - loss: 0.2092 - accuracy: 0.9159 - val_loss: 0.2755 - val_accuracy: 0.8767\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2088 - accuracy: 0.9159 - val_loss: 0.2751 - val_accuracy: 0.8767\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2085 - accuracy: 0.9168 - val_loss: 0.2748 - val_accuracy: 0.8767\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2079 - accuracy: 0.9149 - val_loss: 0.2747 - val_accuracy: 0.8767\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 101us/step - loss: 0.2075 - accuracy: 0.9149 - val_loss: 0.2745 - val_accuracy: 0.8767\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2073 - accuracy: 0.9149 - val_loss: 0.2741 - val_accuracy: 0.8767\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2067 - accuracy: 0.9149 - val_loss: 0.2740 - val_accuracy: 0.8767\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2064 - accuracy: 0.9159 - val_loss: 0.2736 - val_accuracy: 0.8767\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2060 - accuracy: 0.9159 - val_loss: 0.2734 - val_accuracy: 0.8767\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2057 - accuracy: 0.9139 - val_loss: 0.2731 - val_accuracy: 0.8767\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 767us/step - loss: 0.7080 - accuracy: 0.5685 - val_loss: 0.6478 - val_accuracy: 0.6758\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.5875 - accuracy: 0.7544 - val_loss: 0.5680 - val_accuracy: 0.7763\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.5169 - accuracy: 0.8239 - val_loss: 0.5148 - val_accuracy: 0.8128\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.4670 - accuracy: 0.8434 - val_loss: 0.4757 - val_accuracy: 0.8311\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.4292 - accuracy: 0.8552 - val_loss: 0.4452 - val_accuracy: 0.8402\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.3994 - accuracy: 0.8630 - val_loss: 0.4210 - val_accuracy: 0.8447\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.3755 - accuracy: 0.8708 - val_loss: 0.4015 - val_accuracy: 0.8493\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.3558 - accuracy: 0.8728 - val_loss: 0.3857 - val_accuracy: 0.8493\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.3396 - accuracy: 0.8738 - val_loss: 0.3729 - val_accuracy: 0.8447\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 164us/step - loss: 0.3262 - accuracy: 0.8757 - val_loss: 0.3625 - val_accuracy: 0.8539\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.3150 - accuracy: 0.8777 - val_loss: 0.3541 - val_accuracy: 0.8584\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.3056 - accuracy: 0.8826 - val_loss: 0.3473 - val_accuracy: 0.8539\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2977 - accuracy: 0.8836 - val_loss: 0.3418 - val_accuracy: 0.8539\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2909 - accuracy: 0.8865 - val_loss: 0.3371 - val_accuracy: 0.8539\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2852 - accuracy: 0.8865 - val_loss: 0.3333 - val_accuracy: 0.8539\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2801 - accuracy: 0.8875 - val_loss: 0.3299 - val_accuracy: 0.8539\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2758 - accuracy: 0.8894 - val_loss: 0.3267 - val_accuracy: 0.8539\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2718 - accuracy: 0.8894 - val_loss: 0.3243 - val_accuracy: 0.8539\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2683 - accuracy: 0.8885 - val_loss: 0.3221 - val_accuracy: 0.8539\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2652 - accuracy: 0.8904 - val_loss: 0.3197 - val_accuracy: 0.8539\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2623 - accuracy: 0.8924 - val_loss: 0.3179 - val_accuracy: 0.8539\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.2597 - accuracy: 0.8914 - val_loss: 0.3161 - val_accuracy: 0.8493\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.2574 - accuracy: 0.8933 - val_loss: 0.3143 - val_accuracy: 0.8493\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 155us/step - loss: 0.2554 - accuracy: 0.8943 - val_loss: 0.3128 - val_accuracy: 0.8493\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 146us/step - loss: 0.2534 - accuracy: 0.8953 - val_loss: 0.3116 - val_accuracy: 0.8493\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2515 - accuracy: 0.8973 - val_loss: 0.3105 - val_accuracy: 0.8493\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2499 - accuracy: 0.8963 - val_loss: 0.3093 - val_accuracy: 0.8447\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2481 - accuracy: 0.8973 - val_loss: 0.3081 - val_accuracy: 0.8447\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.2466 - accuracy: 0.8973 - val_loss: 0.3071 - val_accuracy: 0.8493\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2452 - accuracy: 0.8982 - val_loss: 0.3059 - val_accuracy: 0.8493\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2439 - accuracy: 0.8992 - val_loss: 0.3048 - val_accuracy: 0.8493\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2426 - accuracy: 0.8992 - val_loss: 0.3037 - val_accuracy: 0.8493\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2414 - accuracy: 0.8963 - val_loss: 0.3027 - val_accuracy: 0.8539\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2403 - accuracy: 0.8982 - val_loss: 0.3017 - val_accuracy: 0.8539\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.2392 - accuracy: 0.8982 - val_loss: 0.3008 - val_accuracy: 0.8539\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2381 - accuracy: 0.8982 - val_loss: 0.2999 - val_accuracy: 0.8539\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2371 - accuracy: 0.9002 - val_loss: 0.2989 - val_accuracy: 0.8539\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.2361 - accuracy: 0.9002 - val_loss: 0.2979 - val_accuracy: 0.8539\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.2352 - accuracy: 0.9012 - val_loss: 0.2971 - val_accuracy: 0.8539\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2343 - accuracy: 0.9022 - val_loss: 0.2963 - val_accuracy: 0.8584\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.2334 - accuracy: 0.9012 - val_loss: 0.2955 - val_accuracy: 0.8584\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2328 - accuracy: 0.9012 - val_loss: 0.2947 - val_accuracy: 0.8584\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2318 - accuracy: 0.9012 - val_loss: 0.2938 - val_accuracy: 0.8539\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2310 - accuracy: 0.9022 - val_loss: 0.2928 - val_accuracy: 0.8539\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2304 - accuracy: 0.9022 - val_loss: 0.2920 - val_accuracy: 0.8539\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 100us/step - loss: 0.2294 - accuracy: 0.9022 - val_loss: 0.2913 - val_accuracy: 0.8539\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2287 - accuracy: 0.9051 - val_loss: 0.2904 - val_accuracy: 0.8539\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2281 - accuracy: 0.9051 - val_loss: 0.2897 - val_accuracy: 0.8584\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 121us/step - loss: 0.2273 - accuracy: 0.9061 - val_loss: 0.2888 - val_accuracy: 0.8584\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 96us/step - loss: 0.2267 - accuracy: 0.9051 - val_loss: 0.2881 - val_accuracy: 0.8584\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2260 - accuracy: 0.9061 - val_loss: 0.2873 - val_accuracy: 0.8584\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2254 - accuracy: 0.9061 - val_loss: 0.2866 - val_accuracy: 0.8584\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.2247 - accuracy: 0.9051 - val_loss: 0.2860 - val_accuracy: 0.8630\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 100us/step - loss: 0.2241 - accuracy: 0.9051 - val_loss: 0.2853 - val_accuracy: 0.8676\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.2234 - accuracy: 0.9070 - val_loss: 0.2846 - val_accuracy: 0.8721\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 94us/step - loss: 0.2228 - accuracy: 0.9070 - val_loss: 0.2838 - val_accuracy: 0.8721\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.2223 - accuracy: 0.9080 - val_loss: 0.2831 - val_accuracy: 0.8721\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2216 - accuracy: 0.9080 - val_loss: 0.2824 - val_accuracy: 0.8721\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 143us/step - loss: 0.2210 - accuracy: 0.9110 - val_loss: 0.2818 - val_accuracy: 0.8767\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.2204 - accuracy: 0.9100 - val_loss: 0.2811 - val_accuracy: 0.8721\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2199 - accuracy: 0.9129 - val_loss: 0.2805 - val_accuracy: 0.8767\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2193 - accuracy: 0.9119 - val_loss: 0.2800 - val_accuracy: 0.8767\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2186 - accuracy: 0.9129 - val_loss: 0.2794 - val_accuracy: 0.8767\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2182 - accuracy: 0.9149 - val_loss: 0.2789 - val_accuracy: 0.8767\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2176 - accuracy: 0.9139 - val_loss: 0.2784 - val_accuracy: 0.8767\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 141us/step - loss: 0.2170 - accuracy: 0.9139 - val_loss: 0.2778 - val_accuracy: 0.8767\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.2165 - accuracy: 0.9139 - val_loss: 0.2773 - val_accuracy: 0.8767\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2162 - accuracy: 0.9139 - val_loss: 0.2769 - val_accuracy: 0.8767\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.2157 - accuracy: 0.9139 - val_loss: 0.2765 - val_accuracy: 0.8767\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2150 - accuracy: 0.9139 - val_loss: 0.2759 - val_accuracy: 0.8767\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2145 - accuracy: 0.9149 - val_loss: 0.2755 - val_accuracy: 0.8767\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2142 - accuracy: 0.9139 - val_loss: 0.2750 - val_accuracy: 0.8767\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2136 - accuracy: 0.9139 - val_loss: 0.2747 - val_accuracy: 0.8767\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2131 - accuracy: 0.9149 - val_loss: 0.2744 - val_accuracy: 0.8767\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2128 - accuracy: 0.9139 - val_loss: 0.2738 - val_accuracy: 0.8767\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 117us/step - loss: 0.2123 - accuracy: 0.9149 - val_loss: 0.2736 - val_accuracy: 0.8767\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.2119 - accuracy: 0.9149 - val_loss: 0.2731 - val_accuracy: 0.8767\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2115 - accuracy: 0.9159 - val_loss: 0.2726 - val_accuracy: 0.8767\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2110 - accuracy: 0.9139 - val_loss: 0.2722 - val_accuracy: 0.8767\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2107 - accuracy: 0.9149 - val_loss: 0.2719 - val_accuracy: 0.8767\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2101 - accuracy: 0.9149 - val_loss: 0.2715 - val_accuracy: 0.8767\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 123us/step - loss: 0.2098 - accuracy: 0.9149 - val_loss: 0.2713 - val_accuracy: 0.8767\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2094 - accuracy: 0.9129 - val_loss: 0.2707 - val_accuracy: 0.8767\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2090 - accuracy: 0.9139 - val_loss: 0.2704 - val_accuracy: 0.8767\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2087 - accuracy: 0.9149 - val_loss: 0.2701 - val_accuracy: 0.8767\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2082 - accuracy: 0.9139 - val_loss: 0.2697 - val_accuracy: 0.8767\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2078 - accuracy: 0.9139 - val_loss: 0.2695 - val_accuracy: 0.8767\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2076 - accuracy: 0.9139 - val_loss: 0.2691 - val_accuracy: 0.8767\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2071 - accuracy: 0.9129 - val_loss: 0.2687 - val_accuracy: 0.8767\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2066 - accuracy: 0.9139 - val_loss: 0.2686 - val_accuracy: 0.8767\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2063 - accuracy: 0.9129 - val_loss: 0.2682 - val_accuracy: 0.8767\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2059 - accuracy: 0.9139 - val_loss: 0.2679 - val_accuracy: 0.8721\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2056 - accuracy: 0.9139 - val_loss: 0.2677 - val_accuracy: 0.8721\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2053 - accuracy: 0.9129 - val_loss: 0.2674 - val_accuracy: 0.8721\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2049 - accuracy: 0.9149 - val_loss: 0.2671 - val_accuracy: 0.8767\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2045 - accuracy: 0.9149 - val_loss: 0.2667 - val_accuracy: 0.8767\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2044 - accuracy: 0.9139 - val_loss: 0.2663 - val_accuracy: 0.8767\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.2038 - accuracy: 0.9149 - val_loss: 0.2660 - val_accuracy: 0.8767\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.2035 - accuracy: 0.9149 - val_loss: 0.2658 - val_accuracy: 0.8767\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.2032 - accuracy: 0.9159 - val_loss: 0.2655 - val_accuracy: 0.8767\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 772us/step - loss: 0.6199 - accuracy: 0.7750 - val_loss: 0.5972 - val_accuracy: 0.7900\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.5600 - accuracy: 0.8444 - val_loss: 0.5509 - val_accuracy: 0.8128\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 99us/step - loss: 0.5098 - accuracy: 0.8562 - val_loss: 0.5114 - val_accuracy: 0.8219\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.4670 - accuracy: 0.8640 - val_loss: 0.4774 - val_accuracy: 0.8219\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.4307 - accuracy: 0.8689 - val_loss: 0.4484 - val_accuracy: 0.8219\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.4002 - accuracy: 0.8689 - val_loss: 0.4241 - val_accuracy: 0.8265\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 189us/step - loss: 0.3746 - accuracy: 0.8748 - val_loss: 0.4042 - val_accuracy: 0.8311\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.3536 - accuracy: 0.8777 - val_loss: 0.3884 - val_accuracy: 0.8311\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 140us/step - loss: 0.3361 - accuracy: 0.8836 - val_loss: 0.3753 - val_accuracy: 0.8311\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.3215 - accuracy: 0.8836 - val_loss: 0.3649 - val_accuracy: 0.8356\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 151us/step - loss: 0.3094 - accuracy: 0.8855 - val_loss: 0.3565 - val_accuracy: 0.8356\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2992 - accuracy: 0.8875 - val_loss: 0.3493 - val_accuracy: 0.8356\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 148us/step - loss: 0.2905 - accuracy: 0.8875 - val_loss: 0.3435 - val_accuracy: 0.8356\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2833 - accuracy: 0.8904 - val_loss: 0.3384 - val_accuracy: 0.8356\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 131us/step - loss: 0.2768 - accuracy: 0.8914 - val_loss: 0.3341 - val_accuracy: 0.8356\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2713 - accuracy: 0.8914 - val_loss: 0.3304 - val_accuracy: 0.8402\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2664 - accuracy: 0.8924 - val_loss: 0.3271 - val_accuracy: 0.8402\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2619 - accuracy: 0.8933 - val_loss: 0.3243 - val_accuracy: 0.8447\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2581 - accuracy: 0.8963 - val_loss: 0.3215 - val_accuracy: 0.8447\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.2547 - accuracy: 0.8943 - val_loss: 0.3191 - val_accuracy: 0.8447\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2517 - accuracy: 0.8982 - val_loss: 0.3172 - val_accuracy: 0.8447\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2490 - accuracy: 0.8973 - val_loss: 0.3155 - val_accuracy: 0.8493\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2464 - accuracy: 0.8992 - val_loss: 0.3138 - val_accuracy: 0.8493\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2442 - accuracy: 0.9012 - val_loss: 0.3120 - val_accuracy: 0.8493\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2421 - accuracy: 0.9012 - val_loss: 0.3103 - val_accuracy: 0.8493\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 136us/step - loss: 0.2404 - accuracy: 0.9012 - val_loss: 0.3091 - val_accuracy: 0.8493\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 86us/step - loss: 0.2386 - accuracy: 0.9012 - val_loss: 0.3079 - val_accuracy: 0.8493\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 96us/step - loss: 0.2370 - accuracy: 0.9002 - val_loss: 0.3065 - val_accuracy: 0.8493\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 94us/step - loss: 0.2355 - accuracy: 0.9022 - val_loss: 0.3055 - val_accuracy: 0.8493\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.2342 - accuracy: 0.9031 - val_loss: 0.3043 - val_accuracy: 0.8493\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 122us/step - loss: 0.2330 - accuracy: 0.9031 - val_loss: 0.3034 - val_accuracy: 0.8493\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 93us/step - loss: 0.2318 - accuracy: 0.9041 - val_loss: 0.3024 - val_accuracy: 0.8493\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 89us/step - loss: 0.2308 - accuracy: 0.9051 - val_loss: 0.3015 - val_accuracy: 0.8493\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 86us/step - loss: 0.2298 - accuracy: 0.9041 - val_loss: 0.3006 - val_accuracy: 0.8447\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 91us/step - loss: 0.2287 - accuracy: 0.9051 - val_loss: 0.2996 - val_accuracy: 0.8447\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 93us/step - loss: 0.2279 - accuracy: 0.9041 - val_loss: 0.2988 - val_accuracy: 0.8447\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 93us/step - loss: 0.2270 - accuracy: 0.9061 - val_loss: 0.2980 - val_accuracy: 0.8447\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 87us/step - loss: 0.2261 - accuracy: 0.9051 - val_loss: 0.2973 - val_accuracy: 0.8447\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.2252 - accuracy: 0.9070 - val_loss: 0.2963 - val_accuracy: 0.8447\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 0.2245 - accuracy: 0.9080 - val_loss: 0.2958 - val_accuracy: 0.8447\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 87us/step - loss: 0.2237 - accuracy: 0.9080 - val_loss: 0.2951 - val_accuracy: 0.8447\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 93us/step - loss: 0.2231 - accuracy: 0.9080 - val_loss: 0.2946 - val_accuracy: 0.8447\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 89us/step - loss: 0.2224 - accuracy: 0.9090 - val_loss: 0.2937 - val_accuracy: 0.8447\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 90us/step - loss: 0.2216 - accuracy: 0.9100 - val_loss: 0.2930 - val_accuracy: 0.8447\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 90us/step - loss: 0.2210 - accuracy: 0.9080 - val_loss: 0.2924 - val_accuracy: 0.8447\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 95us/step - loss: 0.2204 - accuracy: 0.9110 - val_loss: 0.2919 - val_accuracy: 0.8447\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 95us/step - loss: 0.2198 - accuracy: 0.9119 - val_loss: 0.2913 - val_accuracy: 0.8447\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 91us/step - loss: 0.2193 - accuracy: 0.9110 - val_loss: 0.2906 - val_accuracy: 0.8447\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 101us/step - loss: 0.2185 - accuracy: 0.9119 - val_loss: 0.2902 - val_accuracy: 0.8447\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2180 - accuracy: 0.9129 - val_loss: 0.2897 - val_accuracy: 0.8447\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 147us/step - loss: 0.2175 - accuracy: 0.9129 - val_loss: 0.2892 - val_accuracy: 0.8447\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.2169 - accuracy: 0.9129 - val_loss: 0.2886 - val_accuracy: 0.8493\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2165 - accuracy: 0.9129 - val_loss: 0.2881 - val_accuracy: 0.8493\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2159 - accuracy: 0.9129 - val_loss: 0.2877 - val_accuracy: 0.8493\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2154 - accuracy: 0.9129 - val_loss: 0.2873 - val_accuracy: 0.8493\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 0.2152 - accuracy: 0.9129 - val_loss: 0.2868 - val_accuracy: 0.8493\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2147 - accuracy: 0.9139 - val_loss: 0.2863 - val_accuracy: 0.8493\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 150us/step - loss: 0.2142 - accuracy: 0.9129 - val_loss: 0.2857 - val_accuracy: 0.8539\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.2137 - accuracy: 0.9139 - val_loss: 0.2854 - val_accuracy: 0.8539\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 128us/step - loss: 0.2132 - accuracy: 0.9129 - val_loss: 0.2850 - val_accuracy: 0.8539\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2128 - accuracy: 0.9139 - val_loss: 0.2846 - val_accuracy: 0.8539\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2124 - accuracy: 0.9139 - val_loss: 0.2841 - val_accuracy: 0.8584\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 0.2121 - accuracy: 0.9129 - val_loss: 0.2838 - val_accuracy: 0.8584\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 101us/step - loss: 0.2116 - accuracy: 0.9139 - val_loss: 0.2835 - val_accuracy: 0.8584\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.2113 - accuracy: 0.9149 - val_loss: 0.2830 - val_accuracy: 0.8584\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2108 - accuracy: 0.9139 - val_loss: 0.2825 - val_accuracy: 0.8584\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2104 - accuracy: 0.9149 - val_loss: 0.2823 - val_accuracy: 0.8584\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2100 - accuracy: 0.9149 - val_loss: 0.2820 - val_accuracy: 0.8584\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2097 - accuracy: 0.9139 - val_loss: 0.2817 - val_accuracy: 0.8630\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 139us/step - loss: 0.2093 - accuracy: 0.9159 - val_loss: 0.2814 - val_accuracy: 0.8630\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2089 - accuracy: 0.9159 - val_loss: 0.2809 - val_accuracy: 0.8630\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2085 - accuracy: 0.9159 - val_loss: 0.2805 - val_accuracy: 0.8630\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 145us/step - loss: 0.2081 - accuracy: 0.9159 - val_loss: 0.2802 - val_accuracy: 0.8676\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 138us/step - loss: 0.2078 - accuracy: 0.9168 - val_loss: 0.2799 - val_accuracy: 0.8676\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2074 - accuracy: 0.9159 - val_loss: 0.2797 - val_accuracy: 0.8676\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.2072 - accuracy: 0.9168 - val_loss: 0.2794 - val_accuracy: 0.8676\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2068 - accuracy: 0.9168 - val_loss: 0.2792 - val_accuracy: 0.8676\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 180us/step - loss: 0.2065 - accuracy: 0.9159 - val_loss: 0.2789 - val_accuracy: 0.8721\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.2061 - accuracy: 0.9159 - val_loss: 0.2786 - val_accuracy: 0.8721\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 142us/step - loss: 0.2058 - accuracy: 0.9159 - val_loss: 0.2783 - val_accuracy: 0.8721\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 99us/step - loss: 0.2054 - accuracy: 0.9159 - val_loss: 0.2783 - val_accuracy: 0.8721\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.2051 - accuracy: 0.9168 - val_loss: 0.2781 - val_accuracy: 0.8721\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2049 - accuracy: 0.9168 - val_loss: 0.2777 - val_accuracy: 0.8721\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2046 - accuracy: 0.9168 - val_loss: 0.2774 - val_accuracy: 0.8721\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2042 - accuracy: 0.9149 - val_loss: 0.2771 - val_accuracy: 0.8721\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2038 - accuracy: 0.9178 - val_loss: 0.2770 - val_accuracy: 0.8721\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2036 - accuracy: 0.9168 - val_loss: 0.2767 - val_accuracy: 0.8721\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 133us/step - loss: 0.2032 - accuracy: 0.9178 - val_loss: 0.2764 - val_accuracy: 0.8721\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2029 - accuracy: 0.9178 - val_loss: 0.2763 - val_accuracy: 0.8721\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 137us/step - loss: 0.2027 - accuracy: 0.9168 - val_loss: 0.2761 - val_accuracy: 0.8721\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 135us/step - loss: 0.2025 - accuracy: 0.9168 - val_loss: 0.2759 - val_accuracy: 0.8721\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 144us/step - loss: 0.2020 - accuracy: 0.9168 - val_loss: 0.2757 - val_accuracy: 0.8767\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 0.2017 - accuracy: 0.9159 - val_loss: 0.2756 - val_accuracy: 0.8767\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2014 - accuracy: 0.9159 - val_loss: 0.2755 - val_accuracy: 0.8767\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 113us/step - loss: 0.2011 - accuracy: 0.9178 - val_loss: 0.2753 - val_accuracy: 0.8767\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.2009 - accuracy: 0.9159 - val_loss: 0.2752 - val_accuracy: 0.8767\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.2006 - accuracy: 0.9178 - val_loss: 0.2751 - val_accuracy: 0.8767\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.2004 - accuracy: 0.9149 - val_loss: 0.2747 - val_accuracy: 0.8767\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.2000 - accuracy: 0.9168 - val_loss: 0.2748 - val_accuracy: 0.8767\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.1998 - accuracy: 0.9168 - val_loss: 0.2745 - val_accuracy: 0.8767\n"
     ]
    }
   ],
   "source": [
    "results = grid_search(X_train, Y_train, X_val, Y_val, param_grid, get_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tryout</th>\n",
       "      <th>k1</th>\n",
       "      <th>k2</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.894977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.890411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.890411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.890411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.885845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.858447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.853881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.853881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.849315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.849315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Tryout    k1    k2  accuracy\n",
       "32    32.0  20.0   2.0  0.894977\n",
       "34    34.0  20.0  10.0  0.890411\n",
       "27    27.0  15.0  15.0  0.890411\n",
       "26    26.0  15.0  10.0  0.890411\n",
       "47    47.0  30.0  50.0  0.885845\n",
       "..     ...   ...   ...       ...\n",
       "29    29.0  15.0  30.0  0.858447\n",
       "10    10.0   6.0  10.0  0.853881\n",
       "22    22.0  10.0  40.0  0.853881\n",
       "12    12.0   6.0  20.0  0.849315\n",
       "24    24.0  15.0   2.0  0.849315\n",
       "\n",
       "[64 rows x 4 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values(by='accuracy',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tryout</th>\n",
       "      <th>k1</th>\n",
       "      <th>k2</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Tryout, k1, k2, accuracy]\n",
       "Index: []"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.loc[results.k1==16.0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
